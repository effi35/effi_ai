#!/bin/bash

# ×¡×§×¨×™×¤×˜ ×”×ª×§× ×” ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
echo "ğŸš€ ×”×ª×§× ×ª ×××—×“ ×§×•×“ ×—×›× Pro 2.0 ××ª×—×™×œ×”..."
echo "============================================="

# ×™×¦×™×¨×ª ×ª×™×§×™×•×ª
echo "ğŸ“ ×™×•×¦×¨ ××‘× ×” ×ª×™×§×™×•×ª..."

# ×ª×™×§×™×™×ª ×‘×¡×™×¡
BASE_DIR="$(pwd)/smart_code_merger_pro"
mkdir -p "$BASE_DIR"

# ×ª×™×§×™×•×ª ×œ×™×‘×”
mkdir -p "$BASE_DIR/core"
mkdir -p "$BASE_DIR/utils"
mkdir -p "$BASE_DIR/ui"
mkdir -p "$BASE_DIR/ui/templates"
mkdir -p "$BASE_DIR/assets/css"
mkdir -p "$BASE_DIR/assets/js"
mkdir -p "$BASE_DIR/assets/images"
mkdir -p "$BASE_DIR/pwa"
mkdir -p "$BASE_DIR/logs"
mkdir -p "$BASE_DIR/uploads"
mkdir -p "$BASE_DIR/temp"
mkdir -p "$BASE_DIR/versions"
mkdir -p "$BASE_DIR/security_reports"
mkdir -p "$BASE_DIR/remote_cache"

echo "âœ… ××‘× ×” ×ª×™×§×™×•×ª × ×•×¦×¨ ×‘×”×¦×œ×—×”!"

# ×™×¦×™×¨×ª ×§×•×‘×¥ module.py
echo "ğŸ“ ×™×•×¦×¨ ×§×‘×¦×™ ××•×“×•×œ ×¨××©×™..."
cat > "$BASE_DIR/module.py" << 'MODULE_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
×××—×“ ×§×•×“ ×—×›× Pro 2.0
××•×“×•×œ ××¨×›×–×™ ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP

××—×‘×¨: Claude AI
×’×¨×¡×”: 2.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import sys
import json
import zipfile
import logging
import shutil
import tempfile
import hashlib
import importlib
import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×•×™×“×•× ×©××¢×¨×›×ª ×”×¡×¤×¨×™×•×ª × ×’×™×©×”
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# ×”×’×“×¨×ª ×œ×•×’×™×
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(current_dir, 'logs', 'smart_code_merger.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ×˜×¢×™× ×ª ×”×’×“×¨×•×ª
try:
    with open(os.path.join(current_dir, 'config.json'), 'r', encoding='utf-8') as f:
        CONFIG = json.load(f)
    with open(os.path.join(current_dir, 'metadata.json'), 'r', encoding='utf-8') as f:
        METADATA = json.load(f)
    with open(os.path.join(current_dir, 'languages_config.json'), 'r', encoding='utf-8') as f:
        LANGUAGES_CONFIG = json.load(f)
    logger.info(f"×˜×¢×™× ×ª ×”×’×“×¨×•×ª ×”×•×©×œ××”, ×’×¨×¡×ª ××•×“×•×œ: {METADATA['version']}")
except Exception as e:
    logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ×”×’×“×¨×•×ª: {str(e)}")
    sys.exit(1)

# ×™×™×‘×•× ××•×“×•×œ×™× ××§×•××™×™×
try:
    from core.project_detector import ProjectDetector
    from core.file_analyzer import FileAnalyzer
    from core.code_merger import CodeMerger
    from core.version_manager import VersionManager
    from core.security_scanner import SecurityScanner
    from core.code_runner import CodeRunner
    from core.code_completion import CodeCompletion
    from core.remote_storage import RemoteStorageManager
    from utils.helpers import create_directory_if_not_exists, get_file_extension, get_file_hash
    logger.info("×™×™×‘×•× ××•×“×•×œ×™× ××§×•××™×™× ×”×•×©×œ×")
except ImportError as e:
    logger.warning(f"×—×œ×§ ××”××•×“×•×œ×™× ×œ× × ×˜×¢× ×•: {str(e)}. ×™×¦×™×¨×ª ×§×™×©×•×¨×™× ×©×‘×•×¨×™×.")
    
    # ×™×¦×™×¨×ª ××—×œ×§×•×ª ×“××” ×œ×§×™×©×•×¨×™× ×©×‘×•×¨×™×
    class DummyClass:
        def __init__(self, *args, **kwargs):
            logger.warning(f"×©×™××•×© ×‘××—×œ×§×ª ×“××”: {self.__class__.__name__}")
        
        def __getattr__(self, name):
            return lambda *args, **kwargs: None
    
    class ProjectDetector(DummyClass): pass
    class FileAnalyzer(DummyClass): pass
    class CodeMerger(DummyClass): pass
    class VersionManager(DummyClass): pass
    class SecurityScanner(DummyClass): pass
    class CodeRunner(DummyClass): pass
    class CodeCompletion(DummyClass): pass
    class RemoteStorageManager(DummyClass): pass
    
    def create_directory_if_not_exists(directory: str) -> bool:
        """×™×•×¦×¨ ×ª×™×§×™×™×” ×× ×”×™× ×œ× ×§×™×™××ª"""
        try:
            os.makedirs(directory, exist_ok=True)
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×™×¦×™×¨×ª ×ª×™×§×™×™×” {directory}: {str(e)}")
            return False
    
    def get_file_extension(file_path: str) -> str:
        """××—×–×™×¨ ××ª ×”×¡×™×•××ª ×©×œ ×”×§×•×‘×¥"""
        return os.path.splitext(file_path)[1].lower()
    
    def get_file_hash(file_path: str) -> str:
        """××—×–×™×¨ ××ª ×”×—×ª×™××” ×©×œ ×”×§×•×‘×¥"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.sha256(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×©×•×‘ ×—×ª×™××ª ×§×•×‘×¥: {str(e)}")
            return ""


class SmartCodeMerger:
    """
    ××—×œ×§×” ××¨×›×–×™×ª ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
    ××—×¨××™×ª ×¢×œ × ×™×”×•×œ ×ª×”×œ×™×š ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP
    """
    
    def __init__(self, config: dict = None):
        """××ª×—×•×œ ×”××¢×¨×›×ª ×¢× ×”×’×“×¨×•×ª ××•×¤×¦×™×•× ×œ×™×•×ª"""
        logger.info("×××ª×—×œ ×××—×“ ×§×•×“ ×—×›× Pro 2.0")
        self.config = config or CONFIG
        self.metadata = METADATA
        self.version = self.metadata["version"]
        self.zip_files = []
        self.target_directory = None
        self.temp_dir = None
        self.detected_projects = []
        self.project_files = {}
        self.merged_projects = {}
        
        # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª × ×“×¨×©×•×ª
        for directory in ['logs', 'versions', 'security_reports', 'temp', 'remote_cache']:
            create_directory_if_not_exists(os.path.join(current_dir, directory))
        
        # ××ª×—×•×œ ××•×“×•×œ×™×
        self.project_detector = ProjectDetector(self.config["project_detection"])
        self.file_analyzer = FileAnalyzer()
        self.code_merger = CodeMerger(self.config["merger"])
        self.version_manager = VersionManager(self.config["version_management"])
        self.security_scanner = SecurityScanner(self.config["security_scanning"])
        self.code_runner = CodeRunner(self.config["code_running"], LANGUAGES_CONFIG)
        self.code_completion = CodeCompletion(self.config["code_completion"])
        self.remote_storage = RemoteStorageManager(self.config["remote_storage"])
        
        logger.info(f"×××—×“ ×§×•×“ ×—×›× Pro {self.version} ××•×ª×—×œ ×‘×”×¦×œ×—×”")
    
    def select_zip_files(self, zip_file_paths: List[str]) -> bool:
        """×‘×—×™×¨×ª ×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—"""
        logger.info(f"×‘×—×™×¨×ª {len(zip_file_paths)} ×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—")
        valid_files = []
        
        for zip_path in zip_file_paths:
            if not os.path.exists(zip_path):
                logger.error(f"×§×•×‘×¥ ZIP ×œ× ×§×™×™×: {zip_path}")
                continue
            
            if not zipfile.is_zipfile(zip_path):
                logger.error(f"×§×•×‘×¥ ××™× ×• ×‘×¤×•×¨××˜ ZIP ×ª×§×™×Ÿ: {zip_path}")
                continue
            
            valid_files.append(zip_path)
            logger.info(f"×§×•×‘×¥ ZIP ×ª×§×™×Ÿ × ×‘×—×¨: {zip_path}")
        
        self.zip_files = valid_files
        return len(valid_files) > 0
    
    def set_target_directory(self, directory: str) -> bool:
        """×”×’×“×¨×ª ×ª×™×§×™×™×ª ×”×™×¢×“ ×œ××™×–×•×’"""
        try:
            abs_path = os.path.abspath(directory)
            create_directory_if_not_exists(abs_path)
            self.target_directory = abs_path
            logger.info(f"×ª×™×§×™×™×ª ×™×¢×“ ×”×•×’×“×¨×”: {abs_path}")
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×’×“×¨×ª ×ª×™×§×™×™×ª ×™×¢×“: {str(e)}")
            return False
    
    def _extract_zip_files(self) -> bool:
        """×—×™×œ×•×¥ ×§×‘×¦×™ ZIP ×œ×ª×™×§×™×™×” ×–×× ×™×ª"""
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×–×× ×™×ª
            self.temp_dir = tempfile.mkdtemp(prefix="smart_code_merger_")
            logger.info(f"× ×•×¦×¨×” ×ª×™×§×™×™×” ×–×× ×™×ª: {self.temp_dir}")
            
            # ×—×™×œ×•×¥ ×›×œ ×§×‘×¦×™ ×”-ZIP
            for idx, zip_path in enumerate(self.zip_files):
                zip_extract_dir = os.path.join(self.temp_dir, f"source_{idx}")
                os.makedirs(zip_extract_dir, exist_ok=True)
                
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    # ×§×™×“×•× ××—×•×– ×”×”×ª×§×“××•×ª ×‘×”×ª×× ×œ××¡×¤×¨ ×”×§×‘×¦×™×
                    total_files = len(zip_ref.namelist())
                    logger.info(f"××—×œ×¥ {total_files} ×§×‘×¦×™× ×-{zip_path}")
                    
                    for i, file in enumerate(zip_ref.namelist()):
                        zip_ref.extract(file, zip_extract_dir)
                        if i % max(1, total_files // 10) == 0:  # ×¢×“×›×•×Ÿ ×›×œ 10%
                            progress = int((i / total_files) * 100)
                            logger.info(f"×”×ª×§×“××•×ª ×—×™×œ×•×¥ {zip_path}: {progress}%")
                
                logger.info(f"×—×™×œ×•×¥ {zip_path} ×”×•×©×œ×")
            
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×œ×•×¥ ×§×‘×¦×™ ZIP: {str(e)}")
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
            self.temp_dir = None
            return False
    
    def analyze_projects(self) -> Dict[str, Any]:
        """
        × ×™×ª×•×— ×”×¤×¨×•×™×§×˜×™× ×‘×§×‘×¦×™ ×”-ZIP
        ××—×–×™×¨ ××™×œ×•×Ÿ ×¢× ×ª×•×¦××•×ª ×”× ×™×ª×•×—
        """
        logger.info("××ª×—×™×œ × ×™×ª×•×— ×¤×¨×•×™×§×˜×™×")
        
        if not self.zip_files:
            logger.error("×œ× × ×‘×—×¨×• ×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—")
            return {"error": "×œ× × ×‘×—×¨×• ×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—"}
        
        # ×—×™×œ×•×¥ ×§×‘×¦×™ ZIP
        if not self._extract_zip_files():
            return {"error": "×©×’×™××” ×‘×—×™×œ×•×¥ ×§×‘×¦×™ ZIP"}
        
        try:
            # ××™×¡×•×£ ×›×œ ×”×§×‘×¦×™× ×”×–××™× ×™×
            all_files = []
            for root, _, files in os.walk(self.temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    all_files.append(file_path)
            
            logger.info(f"× ××¦××• {len(all_files)} ×§×‘×¦×™× ×œ× ×™×ª×•×—")
            
            # ×¡×™× ×•×Ÿ ×§×‘×¦×™× ×¢×œ ×¤×™ ×”×’×“×¨×•×ª
            if self.config["file_handling"]["excluded_extensions"]:
                excluded_exts = set(self.config["file_handling"]["excluded_extensions"])
                filtered_files = [f for f in all_files if get_file_extension(f) not in excluded_exts]
                logger.info(f"×œ××—×¨ ×¡×™× ×•×Ÿ ×¡×™×•××•×ª: {len(filtered_files)} ×§×‘×¦×™×")
                all_files = filtered_files
            
            # ×”×’×‘×œ×ª ×’×•×“×œ ×§×•×‘×¥
            max_size = self.config["file_handling"]["max_file_size_mb"] * 1024 * 1024
            if max_size > 0:
                filtered_files = []
                for file_path in all_files:
                    file_size = os.path.getsize(file_path)
                    if file_size <= max_size:
                        filtered_files.append(file_path)
                    else:
                        logger.warning(f"×§×•×‘×¥ {file_path} × ×¤×¡×œ ×‘×’×œ×œ ×’×•×“×œ: {file_size / (1024*1024):.2f} MB")
                
                logger.info(f"×œ××—×¨ ×¡×™× ×•×Ÿ ×’×•×“×œ: {len(filtered_files)} ×§×‘×¦×™×")
                all_files = filtered_files
            
            # × ×™×ª×•×— ×§×‘×¦×™× ×•×–×™×”×•×™ ×¤×¨×•×™×§×˜×™×
            logger.info("××ª×—×™×œ ×–×™×”×•×™ ×¤×¨×•×™×§×˜×™×")
            projects = self.project_detector.detect_projects(all_files)
            logger.info(f"×–×•×”×• {len(projects)} ×¤×¨×•×™×§×˜×™×")
            
            # × ×™×ª×•×— ×§×©×¨×™× ×‘×™×Ÿ ×§×‘×¦×™×
            for project in projects:
                project_id = project["id"]
                project_files = project["files"]
                
                logger.info(f"×× ×ª×— ×§×©×¨×™× ×‘×¤×¨×•×™×§×˜ {project_id} ({len(project_files)} ×§×‘×¦×™×)")
                file_relationships = self.file_analyzer.analyze_relationships(project_files)
                
                project["file_relationships"] = file_relationships
                project["statistics"] = self.file_analyzer.calculate_project_statistics(project_files)
                
                # ×¡×¨×™×§×ª ××‘×˜×—×” ×¨××©×•× ×™×ª
                if self.config["security_scanning"]["enabled"]:
                    project["security_scan"] = self.security_scanner.quick_scan(project_files)
            
            self.detected_projects = projects
            
            # ××™×¡×•×£ ×ª×•×¦××•×ª
            result = {
                "detected_projects": projects,
                "total_files": len(all_files),
                "timestamp": datetime.datetime.now().isoformat()
            }
            
            logger.info("× ×™×ª×•×— ×¤×¨×•×™×§×˜×™× ×”×•×©×œ× ×‘×”×¦×œ×—×”")
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘× ×™×ª×•×— ×¤×¨×•×™×§×˜×™×: {str(e)}")
            return {"error": f"×©×’×™××” ×‘× ×™×ª×•×— ×¤×¨×•×™×§×˜×™×: {str(e)}"}
        finally:
            # ×‘××§×¨×” ×©×œ ×©×’×™××”, × ×©××•×¨ ××ª ×”×ª×™×§×™×™×” ×”×–×× ×™×ª ×œ×¦×•×¨×š × ×™×¤×•×™ ×‘××’×™×
            # ×‘×¡×‘×™×‘×ª ×™×™×¦×•×¨, ×™×© ×œ×©×§×•×œ ×œ××—×•×§ ××•×ª×” ×›××Ÿ
            pass
    
    def merge_project(self, project_id: str) -> Dict[str, Any]:
        """
        ××™×–×•×’ ×¤×¨×•×™×§×˜ ×©×–×•×”×” ×œ×ª×™×§×™×™×ª ×”×™×¢×“
        """
        logger.info(f"××ª×—×™×œ ××™×–×•×’ ×¤×¨×•×™×§×˜ {project_id}")
        
        # ×‘×“×™×§×ª ×ª×§×™× ×•×ª
        if not self.detected_projects:
            logger.error("×œ× ×‘×•×¦×¢ × ×™×ª×•×— ×¤×¨×•×™×§×˜×™×")
            return {"error": "×œ× ×‘×•×¦×¢ × ×™×ª×•×— ×¤×¨×•×™×§×˜×™×"}
        
        if not self.target_directory:
            logger.error("×œ× ×”×•×’×“×¨×” ×ª×™×§×™×™×ª ×™×¢×“")
            return {"error": "×œ× ×”×•×’×“×¨×” ×ª×™×§×™×™×ª ×™×¢×“"}
        
        # ×—×™×¤×•×© ×”×¤×¨×•×™×§×˜ ×”××‘×•×§×©
        project = None
        for p in self.detected_projects:
            if p["id"] == project_id:
                project = p
                break
        
        if not project:
            logger.error(f"×¤×¨×•×™×§×˜ {project_id} ×œ× × ××¦×")
            return {"error": f"×¤×¨×•×™×§×˜ {project_id} ×œ× × ××¦×"}
        
        try:
            project_files = project["files"]
            project_name = project["name"]
            
            # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
            project_dir = os.path.join(self.target_directory, project_name)
            create_directory_if_not_exists(project_dir)
            
            logger.info(f"×××–×’ {len(project_files)} ×§×‘×¦×™× ×œ×ª×™×§×™×™×” {project_dir}")
            
            # ××™×–×•×’ ×”×§×‘×¦×™×
            merged_files = self.code_merger.merge_project_files(project_files, project_dir)
            
            # × ×™×”×•×œ ×’×¨×¡××•×ª
            if self.config["version_management"]["enabled"]:
                version_id = self.version_manager.save_version(project_dir)
                logger.info(f"×’×¨×¡×” × ×©××¨×” ×‘×”×¦×œ×—×”, ××–×”×”: {version_id}")
            
            # ×¡×¨×™×§×ª ××‘×˜×—×” ××œ××”
            security_report = None
            if self.config["security_scanning"]["enabled"]:
                security_report = self.security_scanner.full_scan(project_dir)
                report_path = os.path.join(self.config["security_scanning"]["report_path"], 
                                          f"{project_name}_security_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    json.dump(security_report, f, ensure_ascii=False, indent=2)
                
                logger.info(f"×“×•×— ××‘×˜×—×” × ×©××¨: {report_path}")
            
            # ×™×¦×™×¨×ª ×§×•×‘×¥ ZIP ×× ××•×’×“×¨
            zip_path = None
            if self.config["merger"]["create_zip"]:
                zip_path = os.path.join(self.target_directory, f"{project_name}.zip")
                shutil.make_archive(os.path.splitext(zip_path)[0], 'zip', project_dir)
                logger.info(f"×§×•×‘×¥ ZIP × ×•×¦×¨: {zip_path}")
            
            # ×ª×•×¦××•×ª ×”××™×–×•×’
            result = {
                "project_id": project_id,
                "project_name": project_name,
                "merged_files": len(merged_files),
                "output_directory": project_dir,
                "zip_file": zip_path,
                "version_id": version_id if self.config["version_management"]["enabled"] else None,
                "security_report": security_report,
                "timestamp": datetime.datetime.now().isoformat()
            }
            
            # ×©××™×¨×ª ×ª×•×¦××•×ª ×”××™×–×•×’
            self.merged_projects[project_id] = result
            
            logger.info(f"××™×–×•×’ ×¤×¨×•×™×§×˜ {project_id} ×”×•×©×œ× ×‘×”×¦×œ×—×”")
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘××™×–×•×’ ×¤×¨×•×™×§×˜ {project_id}: {str(e)}")
            return {"error": f"×©×’×™××” ×‘××™×–×•×’ ×¤×¨×•×™×§×˜: {str(e)}"}
    
    def cleanup(self) -> bool:
        """× ×™×§×•×™ ××©××‘×™× ×–×× ×™×™×"""
        try:
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
                logger.info(f"×ª×™×§×™×™×” ×–×× ×™×ª × ××—×§×”: {self.temp_dir}")
                self.temp_dir = None
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘× ×™×§×•×™ ××©××‘×™× ×–×× ×™×™×: {str(e)}")
            return False
    
    def get_version_history(self, project_name: str) -> List[Dict[str, Any]]:
        """×§×‘×œ×ª ×”×™×¡×˜×•×¨×™×™×ª ×’×¨×¡××•×ª ×©×œ ×¤×¨×•×™×§×˜"""
        if not self.config["version_management"]["enabled"]:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ×œ× ××•×¤×¢×œ")
            return []
        
        return self.version_manager.get_project_versions(project_name)
    
    def compare_versions(self, version1: str, version2: str) -> Dict[str, Any]:
        """×”×©×•×•××” ×‘×™×Ÿ ×©×ª×™ ×’×¨×¡××•×ª"""
        if not self.config["version_management"]["enabled"]:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ×œ× ××•×¤×¢×œ")
            return {"error": "× ×™×”×•×œ ×’×¨×¡××•×ª ×œ× ××•×¤×¢×œ"}
        
        return self.version_manager.compare_versions(version1, version2)
    
    def restore_version(self, version_id: str, target_dir: str = None) -> Dict[str, Any]:
        """×©×—×–×•×¨ ×’×¨×¡×” ×§×•×“××ª"""
        if not self.config["version_management"]["enabled"]:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ×œ× ××•×¤×¢×œ")
            return {"error": "× ×™×”×•×œ ×’×¨×¡××•×ª ×œ× ××•×¤×¢×œ"}
        
        if target_dir is None:
            target_dir = self.target_directory
        
        return self.version_manager.restore_version(version_id, target_dir)
    
    def run_code(self, file_path: str, params: Dict[str, Any] = None) -> Dict[str, Any]:
        """×”×¨×¦×ª ×§×•×‘×¥ ×§×•×“ ×‘×¡×‘×™×‘×” ××‘×•×“×“×ª"""
        if not self.config["code_running"]["enabled"]:
            logger.warning("×”×¨×¦×ª ×§×•×“ ×œ× ××•×¤×¢×œ×ª")
            return {"error": "×”×¨×¦×ª ×§×•×“ ×œ× ××•×¤×¢×œ×ª"}
        
        return self.code_runner.run_file(file_path, params or {})
    
    def complete_code(self, file_path: str, context_lines: int = None) -> Dict[str, Any]:
        """×”×©×œ××ª ×§×•×“ ×—×¡×¨"""
        if not self.config["code_completion"]["enabled"]:
            logger.warning("×”×©×œ××ª ×§×•×“ ×œ× ××•×¤×¢×œ×ª")
            return {"error": "×”×©×œ××ª ×§×•×“ ×œ× ××•×¤×¢×œ×ª"}
        
        if context_lines is None:
            context_lines = self.config["code_completion"]["context_lines"]
        
        return self.code_completion.complete_file(file_path, context_lines)
    
    def connect_remote_storage(self, storage_type: str, connection_params: Dict[str, Any]) -> Dict[str, Any]:
        """×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ ××¨×•×—×§"""
        if not self.config["remote_storage"]["enabled"]:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª")
            return {"error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª"}
        
        if storage_type not in self.config["remote_storage"]["types"]:
            logger.error(f"×¡×•×’ ××—×¡×•×Ÿ ×œ× × ×ª××š: {storage_type}")
            return {"error": f"×¡×•×’ ××—×¡×•×Ÿ ×œ× × ×ª××š: {storage_type}"}
        
        return self.remote_storage.connect(storage_type, connection_params)
    
    def sync_from_remote(self, remote_id: str, remote_path: str, local_path: str) -> Dict[str, Any]:
        """×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ ××¨×•×—×§"""
        if not self.config["remote_storage"]["enabled"]:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª")
            return {"error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª"}
        
        return self.remote_storage.sync_from_remote(remote_id, remote_path, local_path)
    
    def sync_to_remote(self, remote_id: str, local_path: str, remote_path: str) -> Dict[str, Any]:
        """×¡× ×›×¨×•×Ÿ ×œ××—×¡×•×Ÿ ××¨×•×—×§"""
        if not self.config["remote_storage"]["enabled"]:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª")
            return {"error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ× ××•×¤×¢×œ×ª"}
        
        return self.remote_storage.sync_to_remote(remote_id, local_path, remote_path)


# ×¤×•× ×§×¦×™×” ×œ×©×™××•×© ×™×©×™×¨ ××”×¤×§×•×“×”
def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª ×œ×”×¤×¢×œ×” ×™×©×™×¨×”"""
    import argparse
    
    parser = argparse.ArgumentParser(description='×××—×“ ×§×•×“ ×—×›× Pro 2.0')
    parser.add_argument('zip_files', nargs='+', help='×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—')
    parser.add_argument('-o', '--output', required=True, help='×ª×™×§×™×™×ª ×¤×œ×˜')
    parser.add_argument('-p', '--project', help='××–×”×” ×¤×¨×•×™×§×˜ ×œ××™×–×•×’ (××•×¤×¦×™×•× ×œ×™)')
    parser.add_argument('--no-cleanup', action='store_true', help='×œ× ×œ× ×§×•×ª ×§×‘×¦×™× ×–×× ×™×™×')
    parser.add_argument('--version', action='store_true', help='×”×¦×’×ª ×’×¨×¡×”')
    
    args = parser.parse_args()
    
    if args.version:
        try:
            with open(os.path.join(current_dir, 'metadata.json'), 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            print(f"×××—×“ ×§×•×“ ×—×›× Pro ×’×¨×¡×” {metadata['version']}")
            return 0
        except Exception as e:
            print(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××™×“×¢ ×’×¨×¡×”: {str(e)}")
            return 1
    
    merger = SmartCodeMerger()
    
    print(f"××©×ª××© ×‘×§×‘×¦×™ ZIP: {', '.join(args.zip_files)}")
    print(f"×ª×™×§×™×™×ª ×¤×œ×˜: {args.output}")
    
    merger.select_zip_files(args.zip_files)
    merger.set_target_directory(args.output)
    
    results = merger.analyze_projects()
    
    if "error" in results:
        print(f"×©×’×™××”: {results['error']}")
        return 1
    
    print(f"×–×•×”×• {len(results['detected_projects'])} ×¤×¨×•×™×§×˜×™×:")
    for idx, project in enumerate(results['detected_projects']):
        print(f"{idx+1}. {project['name']} ({len(project['files'])} ×§×‘×¦×™×)")
    
    if args.project:
        project_id = args.project
    else:
        # ×× ×™×© ×¨×§ ×¤×¨×•×™×§×˜ ××—×“, ××©×ª××©×™× ×‘×• ××•×˜×•××˜×™×ª
        if len(results['detected_projects']) == 1:
            project_id = results['detected_projects'][0]['id']
            print(f"××©×ª××© ×‘×¤×¨×•×™×§×˜ ×™×—×™×“: {results['detected_projects'][0]['name']}")
        else:
            # ×‘×—×™×¨×ª ×¤×¨×•×™×§×˜
            try:
                selection = int(input("×‘×—×¨ ××¡×¤×¨ ×¤×¨×•×™×§×˜ ×œ××™×–×•×’: "))
                if selection < 1 or selection > len(results['detected_projects']):
                    print("×‘×—×™×¨×” ×œ× ×—×•×§×™×ª")
                    return 1
                project_id = results['detected_projects'][selection - 1]['id']
            except ValueError:
                print("×‘×—×™×¨×” ×œ× ×—×•×§×™×ª")
                return 1
    
    merge_result = merger.merge_project(project_id)
    
    if "error" in merge_result:
        print(f"×©×’×™××” ×‘××™×–×•×’: {merge_result['error']}")
        return 1
    
    print(f"××™×–×•×’ ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
    print(f"×ª×™×§×™×™×ª ×¤×œ×˜: {merge_result['output_directory']}")
    
    if merge_result.get('zip_file'):
        print(f"×§×•×‘×¥ ZIP: {merge_result['zip_file']}")
    
    if not args.no_cleanup:
        merger.cleanup()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
MODULE_PY

# ×™×¦×™×¨×ª ××•×“×•×œ × ×™×”×•×œ ×’×¨×¡××•×ª
echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ×™ ×œ×™×‘×”..."
mkdir -p "$BASE_DIR/core"

echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ × ×™×”×•×œ ×’×¨×¡××•×ª..."
cat > "$BASE_DIR/core/version_manager.py" << 'VERSION_MANAGER_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
××•×“×•×œ × ×™×”×•×œ ×’×¨×¡××•×ª ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
×××¤×©×¨ ×©××™×¨×”, ×©×—×–×•×¨ ×•×”×©×•×•××” ×©×œ ×’×¨×¡××•×ª ×§×•×“

××—×‘×¨: Claude AI
×’×¨×¡×”: 1.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import sys
import json
import shutil
import logging
import datetime
import hashlib
import tarfile
import difflib
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×”×’×“×¨×ª ×œ×•×’×™×
logger = logging.getLogger(__name__)

class VersionManager:
    """
    ×× ×”×œ ×’×¨×¡××•×ª ×œ×©××™×¨×”, ×©×—×–×•×¨ ×•×”×©×•×•××” ×©×œ ×§×‘×¦×™ ×§×•×“
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        ××ª×—×•×œ ×× ×”×œ ×”×’×¨×¡××•×ª
        
        Args:
            config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×ª×¦×•×¨×”
        """
        self.config = config
        self.enabled = config.get("enabled", True)
        self.max_versions = config.get("max_versions", 10)
        self.compression = config.get("compression", "gzip")
        self.storage_path = config.get("storage_path", "versions")
        self.include_metadata = config.get("include_metadata", True)
        self.branch_tracking = config.get("branch_tracking", True)
        
        # ×•×™×“×•× ×©×ª×™×§×™×™×ª ×”×’×¨×¡××•×ª ×§×™×™××ª
        os.makedirs(self.storage_path, exist_ok=True)
        
        # ×§×•×‘×¥ ××¢×§×‘ ×’×¨×¡××•×ª
        self.versions_index_path = os.path.join(self.storage_path, "versions_index.json")
        self.versions_index = self._load_versions_index()
        
        logger.info(f"×× ×”×œ ×’×¨×¡××•×ª ××•×ª×—×œ ×¢× ×”×’×“×¨×•×ª: max_versions={self.max_versions}, "
                   f"compression={self.compression}, storage_path={self.storage_path}")
    
    def _load_versions_index(self) -> Dict[str, Any]:
        """
        ×˜×¢×™× ×ª ××™× ×“×§×¡ ×”×’×¨×¡××•×ª
        
        Returns:
            ××™×œ×•×Ÿ ××™× ×“×§×¡ ×”×’×¨×¡××•×ª
        """
        if os.path.exists(self.versions_index_path):
            try:
                with open(self.versions_index_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××™× ×“×§×¡ ×’×¨×¡××•×ª: {str(e)}")
                return {"projects": {}, "versions": {}}
        else:
            return {"projects": {}, "versions": {}}
    
    def _save_versions_index(self) -> bool:
        """
        ×©××™×¨×ª ××™× ×“×§×¡ ×”×’×¨×¡××•×ª
        
        Returns:
            ×”×× ×”×©××™×¨×” ×”×¦×œ×™×—×”
        """
        try:
            with open(self.versions_index_path, 'w', encoding='utf-8') as f:
                json.dump(self.versions_index, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×©××™×¨×ª ××™× ×“×§×¡ ×’×¨×¡××•×ª: {str(e)}")
            return False
    
    def _create_version_id(self, project_dir: str, timestamp: str) -> str:
        """
        ×™×¦×™×¨×ª ××–×”×” ×’×¨×¡×” ×™×™×—×•×“×™
        
        Args:
            project_dir: × ×ª×™×‘ ×”×¤×¨×•×™×§×˜
            timestamp: ×—×•×ª××ª ×–××Ÿ
            
        Returns:
            ××–×”×” ×’×¨×¡×” ×™×™×—×•×“×™
        """
        project_name = os.path.basename(project_dir)
        unique_id = hashlib.md5(f"{project_name}_{timestamp}".encode()).hexdigest()[:10]
        return f"{project_name}_{timestamp.replace(':', '-').replace(' ', '_')}_{unique_id}"
    
    def _get_file_hash(self, file_path: str) -> str:
        """
        ×—×™×©×•×‘ ×—×ª×™××ª MD5 ×©×œ ×§×•×‘×¥
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×—×ª×™××ª MD5 ×©×œ ×ª×•×›×Ÿ ×”×§×•×‘×¥
        """
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×©×•×‘ ×—×ª×™××ª ×§×•×‘×¥ {file_path}: {str(e)}")
            return ""
    
    def _get_project_files_info(self, project_dir: str) -> Dict[str, Dict[str, Any]]:
        """
        ××™×¡×•×£ ××™×“×¢ ×¢×œ ×§×‘×¦×™ ×”×¤×¨×•×™×§×˜
        
        Args:
            project_dir: × ×ª×™×‘ ×”×¤×¨×•×™×§×˜
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ××™×“×¢ ×¢×œ ×›×œ ×”×§×‘×¦×™× ×‘×¤×¨×•×™×§×˜
        """
        files_info = {}
        
        # ×¨×©×™××ª ×¡×™×•××•×ª ×©×œ× ×œ×©××•×¨ ×‘×’×¨×¡×”
        excluded_extensions = [".pyc", ".pyo", ".pyd", "__pycache__", ".git"]
        
        for root, _, files in os.walk(project_dir):
            # ×“×™×œ×•×’ ×¢×œ ×ª×™×§×™×•×ª ××•×—×¨×’×•×ª
            if any(excluded in root for excluded in excluded_extensions):
                continue
            
            for file in files:
                if any(file.endswith(ext) for ext in excluded_extensions):
                    continue
                
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, project_dir)
                
                # ××™×“×¢ ×¢×œ ×”×§×•×‘×¥
                file_info = {
                    "path": rel_path,
                    "size": os.path.getsize(file_path),
                    "modified": datetime.datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                    "hash": self._get_file_hash(file_path)
                }
                
                files_info[rel_path] = file_info
        
        return files_info
    
    def save_version(self, project_dir: str) -> Dict[str, Any]:
        """
        ×©××™×¨×ª ×’×¨×¡×” ×©×œ ×¤×¨×•×™×§×˜
        
        Args:
            project_dir: × ×ª×™×‘ ×”×¤×¨×•×™×§×˜ ×œ×©××™×¨×”
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×’×¨×¡×” ×©× ×©××¨×”
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return {"status": "error", "error": "× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ"}
        
        try:
            project_name = os.path.basename(project_dir)
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            version_id = self._create_version_id(project_dir, timestamp)
            
            # ×™×¦×™×¨×ª ××¨×›×™×•×Ÿ
            version_path = os.path.join(self.storage_path, f"{version_id}.tar.gz")
            
            # ××™×¡×•×£ ××™×“×¢ ×¢×œ ×”×¤×¨×•×™×§×˜
            files_info = self._get_project_files_info(project_dir)
            
            # ×™×¦×™×¨×ª ××¨×›×™×•×Ÿ
            with tarfile.open(version_path, f"w:gz") as tar:
                # ×”×•×¡×¤×ª ×§×‘×¦×™× ×œ××¨×›×™×•×Ÿ
                for rel_path, file_info in files_info.items():
                    file_path = os.path.join(project_dir, rel_path)
                    tar.add(file_path, arcname=rel_path)
                
                # ×”×•×¡×¤×ª ××˜×-×“××˜×”
                if self.include_metadata:
                    metadata = {
                        "version_id": version_id,
                        "project_name": project_name,
                        "timestamp": timestamp,
                        "files_count": len(files_info),
                        "files": files_info
                    }
                    
                    # ×›×ª×™×‘×ª ×”××˜×-×“××˜×” ×œ×§×•×‘×¥ ×–×× ×™
                    with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
                        json.dump(metadata, tmp, ensure_ascii=False, indent=2)
                        tmp_path = tmp.name
                    
                    # ×”×•×¡×¤×ª ×§×•×‘×¥ ×”××˜×-×“××˜×” ×œ××¨×›×™×•×Ÿ
                    tar.add(tmp_path, arcname="metadata.json")
                    
                    # ××—×™×§×ª ×”×§×•×‘×¥ ×”×–×× ×™
                    os.unlink(tmp_path)
            
            # ×¢×“×›×•×Ÿ ××™× ×“×§×¡ ×”×’×¨×¡××•×ª
            if project_name not in self.versions_index["projects"]:
                self.versions_index["projects"][project_name] = []
            
            # ×”×•×¡×¤×ª ×”×’×¨×¡×” ×”×—×“×©×” ×œ×¤×¨×•×™×§×˜
            self.versions_index["projects"][project_name].append(version_id)
            
            # ×©××™×¨×ª ××™×“×¢ ×¢×œ ×”×’×¨×¡×”
            self.versions_index["versions"][version_id] = {
                "project_name": project_name,
                "timestamp": timestamp,
                "path": version_path,
                "files_count": len(files_info)
            }
            
            # ×©××™×¨×ª ×”××™× ×“×§×¡
            self._save_versions_index()
            
            # ×‘×“×™×§×” ×× ×™×© ×¦×•×¨×š ×œ××—×•×§ ×’×¨×¡××•×ª ×™×©× ×•×ª
            self._cleanup_old_versions(project_name)
            
            logger.info(f"× ×©××¨×” ×’×¨×¡×” ×—×“×©×”: {version_id} ×œ×¤×¨×•×™×§×˜ {project_name}")
            return {
                "status": "success",
                "version_id": version_id,
                "project_name": project_name,
                "timestamp": timestamp,
                "files_count": len(files_info)
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×©××™×¨×ª ×’×¨×¡×”: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _cleanup_old_versions(self, project_name: str) -> None:
        """
        × ×™×§×•×™ ×’×¨×¡××•×ª ×™×©× ×•×ª ××¢×‘×¨ ×œ××¡×¤×¨ ×”××§×¡×™××œ×™
        
        Args:
            project_name: ×©× ×”×¤×¨×•×™×§×˜ ×œ× ×™×§×•×™
        """
        if project_name not in self.versions_index["projects"]:
            return
        
        versions = self.versions_index["projects"][project_name]
        
        # ×× ××¡×¤×¨ ×”×’×¨×¡××•×ª ×¢×•×œ×” ×¢×œ ×”××§×¡×™××•×, ××—×§ ××ª ×”×™×©× ×•×ª ×‘×™×•×ª×¨
        if len(versions) > self.max_versions:
            # ××™×•×Ÿ ×œ×¤×™ ×–××Ÿ ×™×¦×™×¨×” (××”×™×©×Ÿ ×œ×—×“×©)
            versions.sort(key=lambda v: self.versions_index["versions"][v]["timestamp"])
            
            # ××—×™×§×ª ×”×’×¨×¡××•×ª ×”×™×©× ×•×ª
            versions_to_delete = versions[:-self.max_versions]
            
            for version_id in versions_to_delete:
                self._delete_version(version_id)
            
            # ×¢×“×›×•×Ÿ ×¨×©×™××ª ×”×’×¨×¡××•×ª
            self.versions_index["projects"][project_name] = versions[-self.max_versions:]
            self._save_versions_index()
    
    def _delete_version(self, version_id: str) -> bool:
        """
        ××—×™×§×ª ×’×¨×¡×”
        
        Args:
            version_id: ××–×”×” ×”×’×¨×¡×” ×œ××—×™×§×”
            
        Returns:
            ×”×× ×”××—×™×§×” ×”×¦×œ×™×—×”
        """
        if version_id not in self.versions_index["versions"]:
            logger.warning(f"×’×¨×¡×” {version_id} ×œ× × ××¦××”")
            return False
        
        try:
            # ××—×™×§×ª ×§×•×‘×¥ ×”××¨×›×™×•×Ÿ
            version_path = self.versions_index["versions"][version_id]["path"]
            if os.path.exists(version_path):
                os.remove(version_path)
            
            # ××—×™×§×” ××”××™× ×“×§×¡
            project_name = self.versions_index["versions"][version_id]["project_name"]
            if project_name in self.versions_index["projects"]:
                if version_id in self.versions_index["projects"][project_name]:
                    self.versions_index["projects"][project_name].remove(version_id)
            
            del self.versions_index["versions"][version_id]
            
            logger.info(f"×’×¨×¡×” {version_id} × ××—×§×”")
            return True
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘××—×™×§×ª ×’×¨×¡×” {version_id}: {str(e)}")
            return False
    
    def get_project_versions(self, project_name: str) -> List[Dict[str, Any]]:
        """
        ×§×‘×œ×ª ×¨×©×™××ª ×”×’×¨×¡××•×ª ×©×œ ×¤×¨×•×™×§×˜
        
        Args:
            project_name: ×©× ×”×¤×¨×•×™×§×˜
            
        Returns:
            ×¨×©×™××ª ×’×¨×¡××•×ª ×”×¤×¨×•×™×§×˜
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return []
        
        if project_name not in self.versions_index["projects"]:
            logger.warning(f"×¤×¨×•×™×§×˜ {project_name} ×œ× × ××¦×")
            return []
        
        versions = []
        for version_id in self.versions_index["projects"][project_name]:
            if version_id in self.versions_index["versions"]:
                version_info = self.versions_index["versions"][version_id].copy()
                version_info["version_id"] = version_id
                versions.append(version_info)
        
        # ××™×•×Ÿ ×œ×¤×™ ×–××Ÿ ×™×¦×™×¨×” (××”×—×“×© ×œ×™×©×Ÿ)
        versions.sort(key=lambda v: v["timestamp"], reverse=True)
        
        return versions
    
    def get_version_info(self, version_id: str) -> Dict[str, Any]:
        """
        ×§×‘×œ×ª ××™×“×¢ ×¢×œ ×’×¨×¡×”
        
        Args:
            version_id: ××–×”×” ×”×’×¨×¡×”
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×’×¨×¡×”
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return {"status": "error", "error": "× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ"}
        
        if version_id not in self.versions_index["versions"]:
            logger.warning(f"×’×¨×¡×” {version_id} ×œ× × ××¦××”")
            return {"status": "error", "error": f"×’×¨×¡×” {version_id} ×œ× × ××¦××”"}
        
        try:
            version_path = self.versions_index["versions"][version_id]["path"]
            
            if not os.path.exists(version_path):
                logger.error(f"×§×•×‘×¥ ×’×¨×¡×” {version_path} ×œ× × ××¦×")
                return {"status": "error", "error": f"×§×•×‘×¥ ×’×¨×¡×” ×œ× × ××¦×"}
            
            # ×—×™×œ×•×¥ ××˜×-×“××˜×” ××”××¨×›×™×•×Ÿ
            with tempfile.TemporaryDirectory() as temp_dir:
                with tarfile.open(version_path, "r:gz") as tar:
                    # ×—×™×¤×•×© ×§×•×‘×¥ ××˜×-×“××˜×”
                    metadata_info = None
                    for member in tar.getmembers():
                        if member.name == "metadata.json":
                            metadata_info = member
                            break
                    
                    if metadata_info:
                        # ×—×™×œ×•×¥ ×§×•×‘×¥ ×”××˜×-×“××˜×”
                        tar.extract(metadata_info, temp_dir)
                        metadata_path = os.path.join(temp_dir, "metadata.json")
                        
                        # ×§×¨×™××ª ×”××˜×-×“××˜×”
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            
                            # ×”×•×¡×¤×ª ××™×“×¢ ××”××™× ×“×§×¡
                            metadata.update(self.versions_index["versions"][version_id])
                            metadata["version_id"] = version_id
                            metadata["status"] = "success"
                            
                            return metadata
                    
                    # ×× ××™×Ÿ ××˜×-×“××˜×”, ×”×—×–×¨ ××™×“×¢ ×‘×¡×™×¡×™ ××”××™× ×“×§×¡
                    version_info = self.versions_index["versions"][version_id].copy()
                    version_info["version_id"] = version_id
                    version_info["status"] = "success"
                    
                    # ×¡×¤×™×¨×ª ×§×‘×¦×™× ×‘××¨×›×™×•×Ÿ
                    file_count = sum(1 for member in tar.getmembers() if member.isfile() and member.name != "metadata.json")
                    version_info["files_count"] = file_count
                    
                    return version_info
        
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×§×‘×œ×ª ××™×“×¢ ×¢×œ ×’×¨×¡×” {version_id}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def restore_version(self, version_id: str, target_dir: str) -> Dict[str, Any]:
        """
        ×©×—×–×•×¨ ×’×¨×¡×” ×œ×™×¢×“ ××¡×•×™×
        
        Args:
            version_id: ××–×”×” ×”×’×¨×¡×” ×œ×©×—×–×•×¨
            target_dir: × ×ª×™×‘ ×”×™×¢×“ ×œ×©×—×–×•×¨
            
        Returns:
            ×ª×•×¦××ª ×”×©×—×–×•×¨
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return {"status": "error", "error": "× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ"}
        
        if version_id not in self.versions_index["versions"]:
            logger.warning(f"×’×¨×¡×” {version_id} ×œ× × ××¦××”")
            return {"status": "error", "error": f"×’×¨×¡×” {version_id} ×œ× × ××¦××”"}
        
        try:
            version_path = self.versions_index["versions"][version_id]["path"]
            
            if not os.path.exists(version_path):
                logger.error(f"×§×•×‘×¥ ×’×¨×¡×” {version_path} ×œ× × ××¦×")
                return {"status": "error", "error": f"×§×•×‘×¥ ×’×¨×¡×” ×œ× × ××¦×"}
            
            # ×•×™×“×•× ×©×ª×™×§×™×™×ª ×”×™×¢×“ ×§×™×™××ª
            os.makedirs(target_dir, exist_ok=True)
            
            # ×©×—×–×•×¨ ×”×§×‘×¦×™× ××”××¨×›×™×•×Ÿ
            with tarfile.open(version_path, "r:gz") as tar:
                # ×¡×™× ×•×Ÿ ×§×‘×¦×™ ××˜×-×“××˜×”
                members = [m for m in tar.getmembers() if m.name != "metadata.json"]
                
                # ×©×—×–×•×¨ ×”×§×‘×¦×™×
                tar.extractall(path=target_dir, members=members)
            
            logger.info(f"×’×¨×¡×” {version_id} ×©×•×—×–×¨×” ×‘×”×¦×œ×—×” ×œ×™×¢×“ {target_dir}")
            
            # ×”×—×–×¨ ××™×“×¢ ×¢×œ ×”×©×—×–×•×¨
            return {
                "status": "success",
                "version_id": version_id,
                "project_name": self.versions_index["versions"][version_id]["project_name"],
                "timestamp": self.versions_index["versions"][version_id]["timestamp"],
                "files_count": self.versions_index["versions"][version_id]["files_count"],
                "target_dir": target_dir
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×©×—×–×•×¨ ×’×¨×¡×” {version_id}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def compare_versions(self, version_id1: str, version_id2: str) -> Dict[str, Any]:
        """
        ×”×©×•×•××” ×‘×™×Ÿ ×©×ª×™ ×’×¨×¡××•×ª
        
        Args:
            version_id1: ××–×”×” ×”×’×¨×¡×” ×”×¨××©×•× ×”
            version_id2: ××–×”×” ×”×’×¨×¡×” ×”×©× ×™×™×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×©×•×•××”
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return {"status": "error", "error": "× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ"}
        
        if version_id1 not in self.versions_index["versions"]:
            logger.warning(f"×’×¨×¡×” {version_id1} ×œ× × ××¦××”")
            return {"status": "error", "error": f"×’×¨×¡×” {version_id1} ×œ× × ××¦××”"}
        
        if version_id2 not in self.versions_index["versions"]:
            logger.warning(f"×’×¨×¡×” {version_id2} ×œ× × ××¦××”")
            return {"status": "error", "error": f"×’×¨×¡×” {version_id2} ×œ× × ××¦××”"}
        
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                # ×—×™×œ×•×¥ ×”×’×¨×¡×” ×”×¨××©×•× ×”
                version1_dir = os.path.join(temp_dir, "version1")
                os.makedirs(version1_dir)
                self.restore_version(version_id1, version1_dir)
                
                # ×—×™×œ×•×¥ ×”×’×¨×¡×” ×”×©× ×™×™×”
                version2_dir = os.path.join(temp_dir, "version2")
                os.makedirs(version2_dir)
                self.restore_version(version_id2, version2_dir)
                
                # ×”×©×•×•××” ×‘×™×Ÿ ×”×’×¨×¡××•×ª
                comparison_result = self._compare_directories(version1_dir, version2_dir)
                
                # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×”×’×¨×¡××•×ª
                result = {
                    "status": "success",
                    "version1": {
                        "version_id": version_id1,
                        "project_name": self.versions_index["versions"][version_id1]["project_name"],
                        "timestamp": self.versions_index["versions"][version_id1]["timestamp"]
                    },
                    "version2": {
                        "version_id": version_id2,
                        "project_name": self.versions_index["versions"][version_id2]["project_name"],
                        "timestamp": self.versions_index["versions"][version_id2]["timestamp"]
                    },
                    "comparison": comparison_result
                }
                
                return result
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×©×•×•××ª ×’×¨×¡××•×ª {version_id1} ×•-{version_id2}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _compare_directories(self, dir1: str, dir2: str) -> Dict[str, Any]:
        """
        ×”×©×•×•××” ×‘×™×Ÿ ×©×ª×™ ×ª×™×§×™×•×ª
        
        Args:
            dir1: × ×ª×™×‘ ×”×ª×™×§×™×™×” ×”×¨××©×•× ×”
            dir2: × ×ª×™×‘ ×”×ª×™×§×™×™×” ×”×©× ×™×™×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×©×•×•××”
        """
        # ×¨×©×™××ª ×§×‘×¦×™× ×‘×›×œ ×ª×™×§×™×™×”
        files1 = self._get_directory_files(dir1)
        files2 = self._get_directory_files(dir2)
        
        # ×§×‘×¦×™× ××©×•×ª×¤×™×
        common_files = set(files1.keys()) & set(files2.keys())
        
        # ×§×‘×¦×™× ×™×™×—×•×“×™×™× ×œ×›×œ ×ª×™×§×™×™×”
        only_in_dir1 = set(files1.keys()) - set(files2.keys())
        only_in_dir2 = set(files2.keys()) - set(files1.keys())
        
        # ×”×©×•×•××ª ×§×‘×¦×™× ××©×•×ª×¤×™×
        changed_files = []
        unchanged_files = []
        
        for file_path in common_files:
            if files1[file_path]["hash"] != files2[file_path]["hash"]:
                # ×™×¦×™×¨×ª ×”×©×•×•××” ×‘×™×Ÿ ×ª×›× ×™ ×”×§×‘×¦×™×
                file1_path = os.path.join(dir1, file_path)
                file2_path = os.path.join(dir2, file_path)
                
                try:
                    with open(file1_path, 'r', encoding='utf-8', errors='ignore') as f1, \
                         open(file2_path, 'r', encoding='utf-8', errors='ignore') as f2:
                        file1_lines = f1.readlines()
                        file2_lines = f2.readlines()
                    
                    # ×™×¦×™×¨×ª ×”×©×•×•××”
                    diff = list(difflib.unified_diff(
                        file1_lines, file2_lines,
                        fromfile=f"version1/{file_path}",
                        tofile=f"version2/{file_path}",
                        n=3
                    ))
                    
                    changed_files.append({
                        "path": file_path,
                        "diff": "".join(diff),
                        "size1": files1[file_path]["size"],
                        "size2": files2[file_path]["size"],
                        "modified1": files1[file_path]["modified"],
                        "modified2": files2[file_path]["modified"]
                    })
                    
                except Exception as e:
                    # ×‘××§×¨×” ×©×œ ×§×•×‘×¥ ×‘×™× ××¨×™ ××• ×©×’×™××” ××—×¨×ª
                    changed_files.append({
                        "path": file_path,
                        "diff": "×‘×™× ××¨×™ ××• ×©×’×™××” ×‘×”×©×•×•××”: " + str(e),
                        "size1": files1[file_path]["size"],
                        "size2": files2[file_path]["size"],
                        "modified1": files1[file_path]["modified"],
                        "modified2": files2[file_path]["modified"]
                    })
            else:
                unchanged_files.append(file_path)
        
        # ×¡×™×›×•× ×”×ª×•×¦××•×ª
        return {
            "files_only_in_version1": sorted(list(only_in_dir1)),
            "files_only_in_version2": sorted(list(only_in_dir2)),
            "changed_files": changed_files,
            "unchanged_files": unchanged_files,
            "total_files_version1": len(files1),
            "total_files_version2": len(files2),
            "total_changed_files": len(changed_files),
            "total_unchanged_files": len(unchanged_files)
        }
    
    def _get_directory_files(self, directory: str) -> Dict[str, Dict[str, Any]]:
        """
        ×§×‘×œ×ª ×¨×©×™××ª ×§×‘×¦×™× ×‘×ª×™×§×™×™×”
        
        Args:
            directory: × ×ª×™×‘ ×”×ª×™×§×™×™×”
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ××™×“×¢ ×¢×œ ×›×œ ×”×§×‘×¦×™× ×‘×ª×™×§×™×™×”
        """
        files_info = {}
        
        for root, _, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, directory)
                
                # ××™×“×¢ ×¢×œ ×”×§×•×‘×¥
                files_info[rel_path] = {
                    "path": rel_path,
                    "size": os.path.getsize(file_path),
                    "modified": datetime.datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat(),
                    "hash": self._get_file_hash(file_path)
                }
        
        return files_info
    
    def compare_file_versions(self, version_id1: str, version_id2: str, file_path: str) -> Dict[str, Any]:
        """
        ×”×©×•×•××” ×‘×™×Ÿ ×©×ª×™ ×’×¨×¡××•×ª ×©×œ ×§×•×‘×¥ ×¡×¤×¦×™×¤×™
        
        Args:
            version_id1: ××–×”×” ×”×’×¨×¡×” ×”×¨××©×•× ×”
            version_id2: ××–×”×” ×”×’×¨×¡×” ×”×©× ×™×™×”
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥ ×œ×”×©×•×•××”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×©×•×•××”
        """
        if not self.enabled:
            logger.warning("× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ")
            return {"status": "error", "error": "× ×™×”×•×œ ×’×¨×¡××•×ª ××™× ×• ××•×¤×¢×œ"}
        
        try:
            with tempfile.TemporaryDirectory() as temp_dir:
                # ×—×™×œ×•×¥ ×”×§×•×‘×¥ ××”×’×¨×¡×” ×”×¨××©×•× ×”
                version1_dir = os.path.join(temp_dir, "version1")
                os.makedirs(version1_dir)
                
                # ×©×—×–×•×¨ ×”×’×¨×¡×” ×”×¨××©×•× ×”
                restore_result1 = self.restore_version(version_id1, version1_dir)
                if restore_result1["status"] != "success":
                    return restore_result1
                
                # ×—×™×œ×•×¥ ×”×§×•×‘×¥ ××”×’×¨×¡×” ×”×©× ×™×™×”
                version2_dir = os.path.join(temp_dir, "version2")
                os.makedirs(version2_dir)
                
                # ×©×—×–×•×¨ ×”×’×¨×¡×” ×”×©× ×™×™×”
                restore_result2 = self.restore_version(version_id2, version2_dir)
                if restore_result2["status"] != "success":
                    return restore_result2
                
                # × ×ª×™×‘×™ ×”×§×‘×¦×™×
                file1_path = os.path.join(version1_dir, file_path)
                file2_path = os.path.join(version2_dir, file_path)
                
                # ×‘×“×™×§×” ×©×”×§×‘×¦×™× ×§×™×™××™×
                file1_exists = os.path.exists(file1_path)
                file2_exists = os.path.exists(file2_path)
                
                # ×”×©×•×•××” ×‘×™×Ÿ ×”×§×‘×¦×™×
                if file1_exists and file2_exists:
                    try:
                        with open(file1_path, 'r', encoding='utf-8', errors='ignore') as f1, \
                             open(file2_path, 'r', encoding='utf-8', errors='ignore') as f2:
                            file1_lines = f1.readlines()
                            file2_lines = f2.readlines()
                        
                        # ×™×¦×™×¨×ª ×”×©×•×•××”
                        diff = list(difflib.unified_diff(
                            file1_lines, file2_lines,
                            fromfile=f"version1/{file_path}",
                            tofile=f"version2/{file_path}",
                            n=3
                        ))
                        
                        return {
                            "status": "success",
                            "file_path": file_path,
                            "exists_in_version1": True,
                            "exists_in_version2": True,
                            "diff": "".join(diff),
                            "size1": os.path.getsize(file1_path),
                            "size2": os.path.getsize(file2_path),
                            "modified1": datetime.datetime.fromtimestamp(os.path.getmtime(file1_path)).isoformat(),
                            "modified2": datetime.datetime.fromtimestamp(os.path.getmtime(file2_path)).isoformat(),
                            "version1": {
                                "version_id": version_id1,
                                "project_name": self.versions_index["versions"][version_id1]["project_name"],
                                "timestamp": self.versions_index["versions"][version_id1]["timestamp"]
                            },
                            "version2": {
                                "version_id": version_id2,
                                "project_name": self.versions_index["versions"][version_id2]["project_name"],
                                "timestamp": self.versions_index["versions"][version_id2]["timestamp"]
                            }
                        }
                    except Exception as e:
                        # ×‘××§×¨×” ×©×œ ×§×•×‘×¥ ×‘×™× ××¨×™ ××• ×©×’×™××” ××—×¨×ª
                        return {
                            "status": "error",
                            "error": f"×©×’×™××” ×‘×”×©×•×•××ª ×”×§×‘×¦×™×: {str(e)}",
                            "file_path": file_path,
                            "exists_in_version1": True,
                            "exists_in_version2": True,
                            "size1": os.path.getsize(file1_path) if file1_exists else 0,
                            "size2": os.path.getsize(file2_path) if file2_exists else 0
                        }
                else:
                    return {
                        "status": "warning",
                        "warning": "×”×§×•×‘×¥ ×œ× ×§×™×™× ×‘××—×ª ×”×’×¨×¡××•×ª ××• ×‘×©×ª×™×”×Ÿ",
                        "file_path": file_path,
                        "exists_in_version1": file1_exists,
                        "exists_in_version2": file2_exists
                    }
                    
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×©×•×•××ª ×’×¨×¡××•×ª ×§×•×‘×¥ {file_path}: {str(e)}")
            return {"status": "error", "error": str(e)}
VERSION_MANAGER_PY

# ×™×¦×™×¨×ª ××•×“×•×œ ×¡×¨×™×§×•×ª ××‘×˜×—×”
echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ ×¡×¨×™×§×•×ª ××‘×˜×—×”..."
cat > "$BASE_DIR/core/security_scanner.py" << 'SECURITY_SCANNER_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
××•×“×•×œ ×¡×¨×™×§×•×ª ××‘×˜×—×” ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
×–×™×”×•×™ ×¤×’×™×¢×•×™×•×ª ××‘×˜×—×” ×•×¡×•×“×•×ª ×‘×§×•×“

××—×‘×¨: Claude AI
×’×¨×¡×”: 1.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import re
import sys
import json
import logging
import datetime
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×”×’×“×¨×ª ×œ×•×’×™×
logger = logging.getLogger(__name__)

class SecurityScanner:
    """
    ×¡×•×¨×§ ××‘×˜×—×” ×œ×–×™×”×•×™ ×¤×’×™×¢×•×™×•×ª ×•×¡×•×“×•×ª ×‘×§×•×“
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        ××ª×—×•×œ ×¡×•×¨×§ ×”××‘×˜×—×”
        
        Args:
            config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×ª×¦×•×¨×”
        """
        self.config = config
        self.enabled = config.get("enabled", True)
        self.scan_level = config.get("scan_level", "medium")
        self.excluded_patterns = config.get("excluded_patterns", ["node_modules", "venv", "__pycache__", ".git"])
        self.vulnerability_db_update = config.get("vulnerability_db_update", True)
        self.report_path = config.get("report_path", "security_reports")
        
        # ×•×™×“×•× ×©×ª×™×§×™×™×ª ×“×•×—×•×ª ××‘×˜×—×” ×§×™×™××ª
        os.makedirs(self.report_path, exist_ok=True)
        
        # ×‘×“×™×§×ª ×”×ª×œ×•×™×•×ª ×”× ×“×¨×©×•×ª
        self._check_dependencies()
        
        logger.info(f"×¡×•×¨×§ ××‘×˜×—×” ××•×ª×—×œ ×¢× ×”×’×“×¨×•×ª: scan_level={self.scan_level}, "
                   f"excluded_patterns={self.excluded_patterns}")
    
    def _check_dependencies(self) -> None:
        """
        ×‘×“×™×§×ª ×”×ª×œ×•×™×•×ª ×”× ×“×¨×©×•×ª ×œ×¡×¨×™×§×ª ××‘×˜×—×”
        """
        try:
            # ×‘×“×™×§×ª bandit (×œ×¡×¨×™×§×ª ×§×•×“ Python)
            try:
                subprocess.run(["bandit", "--version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                logger.info("bandit × ××¦× ×‘××¢×¨×›×ª")
            except (subprocess.SubprocessError, FileNotFoundError):
                logger.warning("bandit ×œ× × ××¦× ×‘××¢×¨×›×ª. ××ª×§×™×Ÿ...")
                subprocess.run([sys.executable, "-m", "pip", "install", "bandit"], check=True)
            
            # ×‘×“×™×§×ª safety (×œ×¡×¨×™×§×ª ×ª×œ×•×™×•×ª Python)
            try:
                subprocess.run(["safety", "--version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
                logger.info("safety × ××¦× ×‘××¢×¨×›×ª")
            except (subprocess.SubprocessError, FileNotFoundError):
                logger.warning("safety ×œ× × ××¦× ×‘××¢×¨×›×ª. ××ª×§×™×Ÿ...")
                subprocess.run([sys.executable, "-m", "pip", "install", "safety"], check=True)
            
            # ×¢×“×›×•×Ÿ ××¡×“ × ×ª×•× ×™ ×¤×’×™×¢×•×™×•×ª
            if self.vulnerability_db_update:
                try:
                    logger.info("××¢×“×›×Ÿ ××¡×“ × ×ª×•× ×™ ×¤×’×™×¢×•×™×•×ª...")
                    subprocess.run(["safety", "check", "--update"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                except Exception as e:
                    logger.warning(f"×©×’×™××” ×‘×¢×“×›×•×Ÿ ××¡×“ × ×ª×•× ×™ ×¤×’×™×¢×•×™×•×ª: {str(e)}")
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×‘×“×™×§×ª ×ª×œ×•×™×•×ª: {str(e)}")
    
    def quick_scan(self, files: List[str]) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ××‘×˜×—×” ××”×™×¨×” ×œ×§×‘×¦×™×
        
        Args:
            files: ×¨×©×™××ª × ×ª×™×‘×™ ×§×‘×¦×™× ×œ×¡×¨×™×§×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        if not self.enabled:
            logger.warning("×¡×¨×™×§×ª ××‘×˜×—×” ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "warning", "warning": "×¡×¨×™×§×ª ××‘×˜×—×” ××™× ×” ××•×¤×¢×œ×ª"}
        
        try:
            # ×¡×™× ×•×Ÿ ×§×‘×¦×™×
            filtered_files = self._filter_files(files)
            
            if not filtered_files:
                logger.warning("×œ× × ××¦××• ×§×‘×¦×™× ×œ×¡×¨×™×§×”")
                return {"status": "warning", "warning": "×œ× × ××¦××• ×§×‘×¦×™× ×œ×¡×¨×™×§×”"}
            
            # ××™×•×Ÿ ×§×‘×¦×™× ×œ×¤×™ ×¡×•×’
            file_types = self._categorize_files(filtered_files)
            
            # ×¡×¨×™×§×” ××”×™×¨×”
            secrets_results = self._scan_for_secrets(filtered_files)
            
            # ×—×™×¤×•×© ×¡×™×¡×××•×ª ×§×©×™×—×•×ª
            hardcoded_credentials = self._find_hardcoded_credentials(filtered_files)
            
            # ×¡×™×›×•× ×”×¡×¨×™×§×”
            total_issues = len(secrets_results["findings"]) + len(hardcoded_credentials)
            
            return {
                "status": "success",
                "scan_time": datetime.datetime.now().isoformat(),
                "scan_type": "quick",
                "files_scanned": len(filtered_files),
                "file_types": file_types,
                "total_issues": total_issues,
                "severity_summary": {
                    "high": sum(1 for item in secrets_results["findings"] if item.get("severity") == "high"),
                    "medium": sum(1 for item in secrets_results["findings"] if item.get("severity") == "medium"),
                    "low": sum(1 for item in secrets_results["findings"] if item.get("severity") == "low")
                },
                "secrets": secrets_results["findings"],
                "hardcoded_credentials": hardcoded_credentials
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡×¨×™×§×ª ××‘×˜×—×” ××”×™×¨×”: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def full_scan(self, project_dir: str) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ××‘×˜×—×” ××œ××” ×œ×¤×¨×•×™×§×˜
        
        Args:
            project_dir: × ×ª×™×‘ ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        if not self.enabled:
            logger.warning("×¡×¨×™×§×ª ××‘×˜×—×” ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "warning", "warning": "×¡×¨×™×§×ª ××‘×˜×—×” ××™× ×” ××•×¤×¢×œ×ª"}
        
        try:
            logger.info(f"××ª×—×™×œ ×¡×¨×™×§×ª ××‘×˜×—×” ××œ××” ×œ×¤×¨×•×™×§×˜: {project_dir}")
            
            # ×‘×“×™×§×” ×©×”×ª×™×§×™×™×” ×§×™×™××ª
            if not os.path.exists(project_dir) or not os.path.isdir(project_dir):
                logger.error(f"×ª×™×§×™×™×ª ×¤×¨×•×™×§×˜ ×œ× ×§×™×™××ª: {project_dir}")
                return {"status": "error", "error": f"×ª×™×§×™×™×ª ×¤×¨×•×™×§×˜ ×œ× ×§×™×™××ª: {project_dir}"}
            
            # ××™×¡×•×£ ×›×œ ×”×§×‘×¦×™× ×‘×¤×¨×•×™×§×˜
            all_files = []
            for root, dirs, files in os.walk(project_dir):
                # ×¡×™× ×•×Ÿ ×ª×™×§×™×•×ª ××•×—×¨×’×•×ª
                dirs[:] = [d for d in dirs if not any(pattern in d for pattern in self.excluded_patterns)]
                
                for file in files:
                    file_path = os.path.join(root, file)
                    all_files.append(file_path)
            
            # ×¡×™× ×•×Ÿ ×§×‘×¦×™×
            filtered_files = self._filter_files(all_files)
            
            if not filtered_files:
                logger.warning(f"×œ× × ××¦××• ×§×‘×¦×™× ×œ×¡×¨×™×§×” ×‘×¤×¨×•×™×§×˜: {project_dir}")
                return {"status": "warning", "warning": "×œ× × ××¦××• ×§×‘×¦×™× ×œ×¡×¨×™×§×”"}
            
            # ××™×•×Ÿ ×§×‘×¦×™× ×œ×¤×™ ×¡×•×’
            file_types = self._categorize_files(filtered_files)
            
            # ×™×¦×™×¨×ª ×©× ×œ×“×•×—
            project_name = os.path.basename(os.path.normpath(project_dir))
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            report_name = f"{project_name}_security_{timestamp}"
            
            # ×¡×¨×™×§×•×ª ×©×•× ×•×ª
            results = {}
            
            # ×¡×¨×™×§×ª ×¡×•×“×•×ª ×•×¡×™×¡×××•×ª
            results["secrets"] = self._scan_for_secrets(filtered_files)
            
            # ×¡×¨×™×§×ª ×¤×’×™×¢×•×™×•×ª ×‘×§×•×“ Python
            results["python_vulnerabilities"] = self._scan_python_code(project_dir)
            
            # ×¡×¨×™×§×ª ×ª×œ×•×™×•×ª Python
            requirements_files = [f for f in filtered_files if os.path.basename(f) == "requirements.txt"]
            if requirements_files:
                results["dependency_vulnerabilities"] = self._scan_python_dependencies(requirements_files)
            
            # ×¡×¨×™×§×ª JavaScript
            js_files = [f for f in filtered_files if f.endswith(".js") or f.endswith(".jsx")]
            if js_files:
                results["javascript_issues"] = self._scan_javascript_code(js_files)
            
            # ×¡×¨×™×§×ª ×—×•×œ×©×•×ª ××‘×˜×—×” × ×¤×•×¦×•×ª
            results["common_vulnerabilities"] = self._scan_common_vulnerabilities(filtered_files)
            
            # ×¡×™×›×•× ×ª×•×¦××•×ª
            total_issues = sum([
                len(results["secrets"]["findings"]),
                len(results.get("python_vulnerabilities", {}).get("findings", [])),
                len(results.get("dependency_vulnerabilities", {}).get("findings", [])),
                len(results.get("javascript_issues", {}).get("findings", [])),
                len(results.get("common_vulnerabilities", {}).get("findings", []))
            ])
            
            # ×™×¦×™×¨×ª ×¡×™×›×•× ×—×•××¨×”
            severity_summary = {"high": 0, "medium": 0, "low": 0}
            
            # ×¢×“×›×•×Ÿ ×¡×™×›×•× ×—×•××¨×” ××›×œ ×”×¡×¨×™×§×•×ª
            for scan_results in results.values():
                findings = scan_results.get("findings", [])
                for finding in findings:
                    severity = finding.get("severity", "low").lower()
                    if severity in severity_summary:
                        severity_summary[severity] += 1
            
            # ×™×¦×™×¨×ª ×“×•×— ××¡×›×
            report = {
                "status": "success",
                "report_name": report_name,
                "project_name": project_name,
                "scan_time": datetime.datetime.now().isoformat(),
                "scan_type": "full",
                "scan_level": self.scan_level,
                "files_scanned": len(filtered_files),
                "file_types": file_types,
                "total_issues": total_issues,
                "severity_summary": severity_summary,
                "results": results
            }
            
            # ×©××™×¨×ª ×”×“×•×— ×œ×§×•×‘×¥
            report_path = os.path.join(self.report_path, f"{report_name}.json")
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"×¡×¨×™×§×ª ××‘×˜×—×” ××œ××” ×”×•×©×œ××”, × ××¦××• {total_issues} ×‘×¢×™×•×ª")
            logger.info(f"×“×•×— ××‘×˜×—×” × ×©××¨: {report_path}")
            
            return report
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡×¨×™×§×ª ××‘×˜×—×” ××œ××”: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _filter_files(self, files: List[str]) -> List[str]:
        """
        ×¡×™× ×•×Ÿ ×§×‘×¦×™× ×œ×¡×¨×™×§×”
        
        Args:
            files: ×¨×©×™××ª ×§×‘×¦×™× ×œ×¡×™× ×•×Ÿ
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ××¡×•× × ×ª
        """
        # ×¡×™×•××•×ª ×§×‘×¦×™× ×‘×™× ××¨×™×™× ×©×™×© ×œ×”×ª×¢×œ× ××”×
        binary_extensions = ['.exe', '.dll', '.so', '.pyc', '.pyo', '.pyd', '.obj', '.o', '.class', 
                             '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.svg', '.zip', '.tar',
                             '.gz', '.7z', '.rar', '.jar', '.war', '.ear', '.pdf', '.doc', '.docx',
                             '.xls', '.xlsx', '.ppt', '.pptx', '.bin', '.dat', '.db', '.sqlite']
        
        # ×¡×™× ×•×Ÿ ×§×‘×¦×™×
        filtered_files = []
        for file_path in files:
            # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×§×™×™× ×•×œ× ×ª×™×§×™×™×”
            if not os.path.exists(file_path) or os.path.isdir(file_path):
                continue
            
            # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×©×™×™×š ×œ×ª×‘× ×™×ª ××•×—×¨×’×ª
            if any(pattern in file_path for pattern in self.excluded_patterns):
                continue
            
            # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×‘×™× ××¨×™
            ext = os.path.splitext(file_path)[1].lower()
            if ext in binary_extensions:
                continue
            
            # ×‘×“×™×§×” ×©×–×” ×§×•×‘×¥ ×˜×§×¡×˜
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    # ×§×¨×™××ª ××“×’× ×§×˜×Ÿ
                    sample = f.read(1024)
                    if not sample:  # ×§×•×‘×¥ ×¨×™×§
                        continue
                    
                    # ×‘×“×™×§×” ×©×–×” ×§×•×‘×¥ ×˜×§×¡×˜ (×œ×¤×™ ××“×’×)
                    if b'\0' in sample.encode('utf-8'):  # × ×•×›×—×•×ª ×ª×• NULL ××¦×™×™× ×ª ×§×•×‘×¥ ×‘×™× ××¨×™
                        continue
            except Exception:
                # ×‘××§×¨×” ×©×œ ×©×’×™××”, ×“×œ×’ ×¢×œ ×”×§×•×‘×¥
                continue
            
            # ×”×•×¡×¤×ª ×”×§×•×‘×¥ ×œ×¨×©×™××” ×”××¡×•× × ×ª
            filtered_files.append(file_path)
        
        return filtered_files
    
    def _categorize_files(self, files: List[str]) -> Dict[str, int]:
        """
        ××™×•×Ÿ ×§×‘×¦×™× ×œ×¤×™ ×¡×•×’
        
        Args:
            files: ×¨×©×™××ª ×§×‘×¦×™× ×œ××™×•×Ÿ
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ××¡×¤×¨ ×”×§×‘×¦×™× ×œ×¤×™ ×¡×•×’
        """
        file_types = {}
        
        for file_path in files:
            ext = os.path.splitext(file_path)[1].lower()
            if not ext:
                ext = "(no extension)"
            
            if ext in file_types:
                file_types[ext] += 1
            else:
                file_types[ext] = 1
        
        return file_types
    
    def _scan_for_secrets(self, files: List[str]) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ×¡×•×“×•×ª ×•×¡×™×¡×××•×ª
        
        Args:
            files: ×¨×©×™××ª ×§×‘×¦×™× ×œ×¡×¨×™×§×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        # ×ª×‘× ×™×•×ª ×œ×–×™×”×•×™ ×¡×•×“×•×ª
        secret_patterns = {
            "AWS_ACCESS_KEY": (r"(?<![A-Za-z0-9/+])AKIA[0-9A-Z]{16}(?![A-Za-z0-9/+])", "high"),
            "AWS_SECRET_KEY": (r"(?<![A-Za-z0-9/+])[0-9a-zA-Z/+]{40}(?![A-Za-z0-9/+])", "high"),
            "PRIVATE_KEY": (r"-----BEGIN (RSA )?PRIVATE KEY-----", "high"),
            "JWT_TOKEN": (r"eyJ[A-Za-z0-9-_=]+\.[A-Za-z0-9-_=]+\.?[A-Za-z0-9-_.+/=]*", "medium"),
            "API_KEY": (r"[Aa][Pp][Ii]_?[Kk][Ee][Yy].*?['\"](.*?)['\"]", "medium"),
            "GENERIC_SECRET": (r"[Ss][Ee][Cc][Rr][Ee][Tt].*?['\"](.*?)['\"]", "medium"),
            "TOKEN": (r"[Tt][Oo][Kk][Ee][Nn].*?['\"](.*?)['\"]", "medium"),
            "PASSWORD": (r"[Pp][Aa][Ss][Ss][Ww][Oo][Rr][Dd].*?['\"](.*?)['\"]", "medium"),
            "BEARER_TOKEN": (r"[Bb][Ee][Aa][Rr][Ee][Rr].*?['\"](.*?)['\"]", "medium"),
        }
        
        findings = []
        
        # ×¡×¨×™×§×ª ×›×œ ×”×§×‘×¦×™×
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # ×‘×“×™×§×ª ×›×œ ×”×ª×‘× ×™×•×ª
                    for pattern_name, (pattern, severity) in secret_patterns.items():
                        for match in re.finditer(pattern, content):
                            # ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××™×§×•× ×‘×§×•×‘×¥
                            line_num = content[:match.start()].count('\n') + 1
                            start_pos = max(0, match.start() - 20)
                            end_pos = min(len(content), match.end() + 20)
                            context = content[start_pos:end_pos].replace('\n', ' ')
                            
                            # ×”×•×¡×¤×ª ×××¦×
                            findings.append({
                                "type": "secret",
                                "pattern_name": pattern_name,
                                "file": file_path,
                                "line": line_num,
                                "severity": severity,
                                "context": f"...{context}...",
                                "description": f"× ××¦× {pattern_name} ××¤×©×¨×™ ×‘×§×•×‘×¥"
                            })
            except Exception as e:
                logger.warning(f"×©×’×™××” ×‘×¡×¨×™×§×ª ×¡×•×“×•×ª ×‘×§×•×‘×¥ {file_path}: {str(e)}")
        
        return {
            "scan_type": "secrets",
            "files_scanned": len(files),
            "findings_count": len(findings),
            "findings": findings
        }
    
    def _find_hardcoded_credentials(self, files: List[str]) -> List[Dict[str, Any]]:
        """
        ×—×™×¤×•×© ×¡×™×¡×××•×ª ×§×©×™×—×•×ª ×‘×§×•×“
        
        Args:
            files: ×¨×©×™××ª ×§×‘×¦×™× ×œ×¡×¨×™×§×”
            
        Returns:
            ×¨×©×™××ª ×××¦××™×
        """
        # ×ª×‘× ×™×•×ª ×œ×–×™×”×•×™ ×¡×™×¡×××•×ª
        credential_patterns = [
            (r"password\s*=\s*['\"]([^'\"]{4,})['\"]", "×¡×™×¡××” ×§×©×™×—×”"),
            (r"passwd\s*=\s*['\"]([^'\"]{4,})['\"]", "×¡×™×¡××” ×§×©×™×—×”"),
            (r"pwd\s*=\s*['\"]([^'\"]{4,})['\"]", "×¡×™×¡××” ×§×©×™×—×”"),
            (r"username\s*=\s*['\"]([^'\"]+)['\"].*?password\s*=\s*['\"]([^'\"]{4,})['\"]", "×©× ××©×ª××© ×•×¡×™×¡××”"),
            (r"user\s*=\s*['\"]([^'\"]+)['\"].*?pass\s*=\s*['\"]([^'\"]{4,})['\"]", "×©× ××©×ª××© ×•×¡×™×¡××”"),
            (r"connection_string\s*=\s*['\"].*?password=([^;'\"]*).*?['\"]", "××—×¨×•×–×ª ×”×ª×—×‘×¨×•×ª ×¢× ×¡×™×¡××”"),
            (r"const\s+password\s*=\s*['\"]([^'\"]{4,})['\"]", "×§×‘×•×¢ ×¡×™×¡××”"),
            (r"var\s+password\s*=\s*['\"]([^'\"]{4,})['\"]", "××©×ª× ×” ×¡×™×¡××”"),
            (r"let\s+password\s*=\s*['\"]([^'\"]{4,})['\"]", "××©×ª× ×” ×¡×™×¡××”")
        ]
        
        findings = []
        
        # ×¡×¨×™×§×ª ×›×œ ×”×§×‘×¦×™×
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # ×—×™×¤×•×© ×§×•×•×™ ×”×§×•×“
                    lines = content.split('\n')
                    
                    # ×‘×“×™×§×ª ×›×œ ×”×ª×‘× ×™×•×ª
                    for pattern, desc in credential_patterns:
                        for match in re.finditer(pattern, content):
                            # ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××™×§×•× ×‘×§×•×‘×¥
                            line_num = content[:match.start()].count('\n') + 1
                            line = lines[line_num - 1] if line_num <= len(lines) else ""
                            
                            # ×”×•×¡×¤×ª ×××¦×
                            findings.append({
                                "type": "hardcoded_credential",
                                "file": file_path,
                                "line": line_num,
                                "severity": "high",
                                "context": line.strip(),
                                "description": f"× ××¦××• {desc} ×‘×§×•×‘×¥"
                            })
            except Exception as e:
                logger.warning(f"×©×’×™××” ×‘×—×™×¤×•×© ×¡×™×¡×××•×ª ×‘×§×•×‘×¥ {file_path}: {str(e)}")
        
        return findings
    
    def _scan_python_code(self, project_dir: str) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ×§×•×“ Python ×‘×××¦×¢×•×ª bandit
        
        Args:
            project_dir: × ×ª×™×‘ ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        try:
            # ×”×’×“×¨×ª ×¨××ª ×”×—×•××¨×” ×œ×¤×™ ×”×’×“×¨×•×ª
            severity_level = {
                "low": "-i",
                "medium": "-ii",
                "high": "-iii"
            }.get(self.scan_level, "-ii")
            
            # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×œ×ª×•×¦××•×ª
            with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as tmp:
                tmp_path = tmp.name
            
            # ×”×¨×¦×ª bandit
            cmd = [
                "bandit",
                "-r", project_dir,
                "-f", "json",
                "-o", tmp_path,
                severity_level
            ]
            
            # ×”×•×¡×¤×ª ×ª×‘× ×™×•×ª ×œ×”×ª×¢×œ××•×ª
            for pattern in self.excluded_patterns:
                cmd.extend(["-x", pattern])
            
            # ×”×¨×¦×ª ×”×¤×§×•×“×”
            process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            # ×§×¨×™××ª ×ª×•×¦××•×ª
            with open(tmp_path, 'r', encoding='utf-8') as f:
                try:
                    bandit_results = json.load(f)
                except json.JSONDecodeError:
                    # ×‘××§×¨×” ×©×œ ×©×’×™××”, × ×™×¦×•×¨ ×ª×•×¦××•×ª ×¨×™×§×•×ª
                    bandit_results = {"results": []}
            
            # ××—×™×§×ª ×”×§×•×‘×¥ ×”×–×× ×™
            os.unlink(tmp_path)
            
            # ×”××¨×ª ×ª×•×¦××•×ª ×œ×¤×•×¨××˜ ××—×™×“
            findings = []
            for result in bandit_results.get("results", []):
                findings.append({
                    "type": "python_vulnerability",
                    "file": result.get("filename"),
                    "line": result.get("line_number"),
                    "severity": result.get("issue_severity", "medium").lower(),
                    "confidence": result.get("issue_confidence", "medium"),
                    "issue_text": result.get("issue_text"),
                    "issue_code": result.get("test_id"),
                    "description": result.get("test_name")
                })
            
            return {
                "scan_type": "python_code",
                "findings_count": len(findings),
                "findings": findings
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡×¨×™×§×ª ×§×•×“ Python: {str(e)}")
            return {"scan_type": "python_code", "findings_count": 0, "findings": [], "error": str(e)}
    
    def _scan_python_dependencies(self, requirements_files: List[str]) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ×ª×œ×•×™×•×ª Python
        
        Args:
            requirements_files: ×¨×©×™××ª ×§×‘×¦×™ requirements.txt
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        try:
            findings = []
            
            for req_file in requirements_files:
                # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×œ×ª×•×¦××•×ª
                with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as tmp:
                    tmp_path = tmp.name
                
                # ×”×¨×¦×ª safety
                cmd = [
                    "safety",
                    "check",
                    "-r", req_file,
                    "--json",
                    "-o", tmp_path
                ]
                
                # ×”×¨×¦×ª ×”×¤×§×•×“×”
                process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                
                # ×§×¨×™××ª ×ª×•×¦××•×ª
                try:
                    with open(tmp_path, 'r', encoding='utf-8') as f:
                        try:
                            safety_results = json.load(f)
                        except json.JSONDecodeError:
                            safety_results = {"vulnerabilities": []}
                    
                    # ×”××¨×ª ×ª×•×¦××•×ª ×œ×¤×•×¨××˜ ××—×™×“
                    for vuln in safety_results.get("vulnerabilities", []):
                        findings.append({
                            "type": "dependency_vulnerability",
                            "file": req_file,
                            "package": vuln.get("package_name"),
                            "installed_version": vuln.get("installed_version"),
                            "vulnerable_version": vuln.get("vulnerable_spec"),
                            "severity": "high" if vuln.get("severity") == "high" else "medium",
                            "advisory_id": vuln.get("vulnerability_id"),
                            "description": vuln.get("advisory")
                        })
                
                except Exception as e:
                    logger.warning(f"×©×’×™××” ×‘×§×¨×™××ª ×ª×•×¦××•×ª safety: {str(e)}")
                
                # ××—×™×§×ª ×”×§×•×‘×¥ ×”×–×× ×™
                try:
                    os.unlink(tmp_path)
                except:
                    pass
            
            return {
                "scan_type": "python_dependencies",
                "files_scanned": len(requirements_files),
                "findings_count": len(findings),
                "findings": findings
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡×¨×™×§×ª ×ª×œ×•×™×•×ª Python: {str(e)}")
            return {"scan_type": "python_dependencies", "findings_count": 0, "findings": [], "error": str(e)}
    
    def _scan_javascript_code(self, js_files: List[str]) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ×§×•×“ JavaScript
        
        Args:
            js_files: ×¨×©×™××ª ×§×‘×¦×™ JavaScript
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        # ×ª×‘× ×™×•×ª ×œ×–×™×”×•×™ ×‘×¢×™×•×ª ××‘×˜×—×” ×‘×§×•×“ JavaScript
        js_patterns = [
            (r"eval\s*\(", "×©×™××•×© ×‘-eval", "high"),
            (r"document\.write\s*\(", "×©×™××•×© ×‘-document.write", "medium"),
            (r"innerHTML\s*=", "×©×™××•×© ×‘-innerHTML", "medium"),
            (r"localStorage\s*\.", "×©×™××•×© ×‘-localStorage", "low"),
            (r"sessionStorage\s*\.", "×©×™××•×© ×‘-sessionStorage", "low"),
            (r"Math\.random\s*\(", "×©×™××•×© ×‘-Math.random ×œ××‘×˜×—×”", "medium"),
            (r"new Function\s*\(", "×©×™××•×© ×‘-Function", "high"),
            (r"setTimeout\s*\(\s*['\"]", "×©×™××•×© ×‘××—×¨×•×–×ª ×‘-setTimeout", "medium"),
            (r"setInterval\s*\(\s*['\"]", "×©×™××•×© ×‘××—×¨×•×–×ª ×‘-setInterval", "medium"),
            (r"\.html\s*\(", "×©×™××•×© ×‘-jQuery.html", "medium"),
            (r"\.attr\s*\(\s*['\"]on", "×©×™××•×© ×‘×××–×™× ×™ ××™×¨×•×¢×™× ×¢× jQuery", "medium"),
            (r"process\.env", "×’×™×©×” ×œ××©×ª× ×™ ×¡×‘×™×‘×”", "low")
        ]
        
        findings = []
        
        # ×¡×¨×™×§×ª ×›×œ ×”×§×‘×¦×™×
        for file_path in js_files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # ×—×™×¤×•×© ×§×•×•×™ ×”×§×•×“
                    lines = content.split('\n')
                    
                    # ×‘×“×™×§×ª ×›×œ ×”×ª×‘× ×™×•×ª
                    for pattern, desc, severity in js_patterns:
                        for match in re.finditer(pattern, content):
                            # ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××™×§×•× ×‘×§×•×‘×¥
                            line_num = content[:match.start()].count('\n') + 1
                            line = lines[line_num - 1] if line_num <= len(lines) else ""
                            
                            # ×”×•×¡×¤×ª ×××¦×
                            findings.append({
                                "type": "javascript_issue",
                                "file": file_path,
                                "line": line_num,
                                "severity": severity,
                                "context": line.strip(),
                                "description": f"{desc} ×¢×œ×•×œ ×œ×”×•×•×ª ×¡×™×›×•×Ÿ ××‘×˜×—×”"
                            })
            except Exception as e:
                logger.warning(f"×©×’×™××” ×‘×¡×¨×™×§×ª ×§×•×“ JavaScript ×‘×§×•×‘×¥ {file_path}: {str(e)}")
        
        return {
            "scan_type": "javascript_code",
            "files_scanned": len(js_files),
            "findings_count": len(findings),
            "findings": findings
        }
    
    def _scan_common_vulnerabilities(self, files: List[str]) -> Dict[str, Any]:
        """
        ×¡×¨×™×§×ª ×—×•×œ×©×•×ª ××‘×˜×—×” × ×¤×•×¦×•×ª
        
        Args:
            files: ×¨×©×™××ª ×§×‘×¦×™× ×œ×¡×¨×™×§×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×¡×¨×™×§×”
        """
        # ×ª×‘× ×™×•×ª ×œ×–×™×”×•×™ ×—×•×œ×©×•×ª × ×¤×•×¦×•×ª
        vulnerability_patterns = [
            (r"(?i)SELECT\s+.*\s+FROM\s+.*\s+WHERE\s+.*=\s*['\"]\s*\+", "SQL injection", "high"),
            (r"(?i)SELECT\s+.*\s+FROM\s+.*\s+WHERE\s+.*=\s*\$", "SQL injection", "high"),
            (r"(?i)exec\s*\([^)]*concat", "Command injection", "high"),
            (r"(?i)system\s*\([^)]*concat", "Command injection", "high"),
            (r"(?i)shell_exec\s*\([^)]*concat", "Command injection", "high"),
            (r"(?i)\.execute\s*\([^)]*\+", "Command injection", "high"),
            (r"ALLOW_ALL_ORIGINS", "CORS ×—×•×œ×©×ª", "medium"),
            (r"(?i)Access-Control-Allow-Origin:\s*\*", "CORS ×—×•×œ×©×ª", "medium"),
            (r"(?i)Debug\s*=\s*True", "Debug mode", "medium"),
            (r"(?i)CSRF_ENABLED\s*=\s*False", "CSRF ×”×’× ×ª", "high"),
            (r"\.md5\s*\(", "MD5 ×”×¦×¤× ×” ×—×œ×©×”", "medium"),
            (r"\.sha1\s*\(", "SHA1 ×”×¦×¤× ×” ×—×œ×©×”", "medium"),
            (r"DISABLE_CERT_VERIFICATION", "××™××•×ª SSL ××•×©×‘×ª", "high"),
            (r"verify\s*=\s*False", "××™××•×ª SSL ××•×©×‘×ª", "high"),
            (r"X-Frame-Options", "×”×’× ×ª clickjacking", "medium"),
            (r"SECURE_COOKIES\s*=\s*False", "×¢×•×’×™×•×ª ×œ× ×××•×‘×˜×—×•×ª", "medium")
        ]
        
        findings = []
        
        # ×¡×¨×™×§×ª ×›×œ ×”×§×‘×¦×™×
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # ×—×™×¤×•×© ×§×•×•×™ ×”×§×•×“
                    lines = content.split('\n')
                    
                    # ×‘×“×™×§×ª ×›×œ ×”×ª×‘× ×™×•×ª
                    for pattern, desc, severity in vulnerability_patterns:
                        for match in re.finditer(pattern, content):
                            # ×—×™×œ×•×¥ ××™×“×¢ ×¢×œ ×”××™×§×•× ×‘×§×•×‘×¥
                            line_num = content[:match.start()].count('\n') + 1
                            line = lines[line_num - 1] if line_num <= len(lines) else ""
                            
                            # ×”×•×¡×¤×ª ×××¦×
                            findings.append({
                                "type": "common_vulnerability",
                                "file": file_path,
                                "line": line_num,
                                "severity": severity,
                                "context": line.strip(),
                                "description": f"××¤×©×¨×•×ª ×œ-{desc}"
                            })
            except Exception as e:
                logger.warning(f"×©×’×™××” ×‘×¡×¨×™×§×ª ×—×•×œ×©×•×ª × ×¤×•×¦×•×ª ×‘×§×•×‘×¥ {file_path}: {str(e)}")
        
        return {
            "scan_type": "common_vulnerabilities",
            "files_scanned": len(files),
            "findings_count": len(findings),
            "findings": findings
        }
SECURITY_SCANNER_PY

# ×™×¦×™×¨×ª ××•×“×•×œ ×”×¨×¦×ª ×§×•×“
echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ ×”×¨×¦×ª ×§×•×“..."
cat > "$BASE_DIR/core/code_runner.py" << 'CODE_RUNNER_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
××•×“×•×œ ×”×¨×¦×ª ×§×•×“ ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
×××¤×©×¨ ×”×¨×¦×ª ×§×•×“ ×‘×¡×‘×™×‘×” ××‘×•×“×“×ª

××—×‘×¨: Claude AI
×’×¨×¡×”: 1.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import re
import sys
import json
import time
import uuid
import signal
import logging
import tempfile
import subprocess
import threading
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×”×’×“×¨×ª ×œ×•×’×™×
logger = logging.getLogger(__name__)

class TimeoutException(Exception):
    """×—×¨×™×’×” ×©××•×¨××ª ×›××©×¨ ×–××Ÿ ×”×”×¨×¦×” ×¢×•×‘×¨ ××ª ×”××§×¡×™××•× ×”××•×’×“×¨"""
    pass

class MemoryException(Exception):
    """×—×¨×™×’×” ×©××•×¨××ª ×›××©×¨ ×¦×¨×™×›×ª ×”×–×™×›×¨×•×Ÿ ×¢×•×‘×¨×ª ××ª ×”××§×¡×™××•× ×”××•×’×“×¨"""
    pass

class CodeRunner:
    """
    ×× ×”×œ ×”×¨×¦×ª ×§×•×“ ×‘×¡×‘×™×‘×” ××‘×•×“×“×ª
    """
    
    def __init__(self, config: Dict[str, Any], languages_config: Dict[str, Dict[str, Any]]):
        """
        ××ª×—×•×œ ×× ×”×œ ×”×¨×¦×ª ×”×§×•×“
        
        Args:
            config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×ª×¦×•×¨×”
            languages_config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×©×¤×•×ª ×ª×›× ×•×ª
        """
        self.config = config
        self.languages_config = languages_config
        self.enabled = config.get("enabled", True)
        self.sandbox_enabled = config.get("sandbox_enabled", True)
        self.timeout_seconds = config.get("timeout_seconds", 30)
        self.memory_limit_mb = config.get("memory_limit_mb", 512)
        self.supported_languages = config.get("supported_languages", ["python", "javascript", "bash"])
        
        # ×ª×™×§×™×™×ª ×¡×‘×™×‘×•×ª ×”×¨×¦×” ××‘×•×“×“×•×ª
        self.sandboxes_dir = config.get("sandboxes_dir", "sandboxes")
        os.makedirs(self.sandboxes_dir, exist_ok=True)
        
        # ××¢×§×‘ ××—×¨ ×”×¨×¦×•×ª
        self.runs = {}
        
        logger.info(f"×× ×”×œ ×”×¨×¦×ª ×§×•×“ ××•×ª×—×œ ×¢× ×”×’×“×¨×•×ª: timeout={self.timeout_seconds}s, "
                   f"memory_limit={self.memory_limit_mb}MB, sandbox={self.sandbox_enabled}")
        
        # ×‘×“×™×§×ª ×–××™× ×•×ª ×©×¤×•×ª
        self._check_language_availability()
    
    def _check_language_availability(self) -> None:
        """
        ×‘×“×™×§×ª ×–××™× ×•×ª ×©×¤×•×ª ×ª×›× ×•×ª ×‘××¢×¨×›×ª
        """
        for lang in self.supported_languages:
            if lang not in self.languages_config:
                logger.warning(f"×”×’×“×¨×•×ª ×©×¤×” ×—×¡×¨×•×ª ×¢×‘×•×¨ {lang}")
                continue
            
            lang_config = self.languages_config[lang]
            cmd = lang_config.get("version_command", [])
            
            if not cmd:
                logger.warning(f"×¤×§×•×“×ª ×’×¨×¡×” ×œ× ××•×’×“×¨×ª ×¢×‘×•×¨ {lang}")
                continue
            
            try:
                result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                if result.returncode == 0:
                    logger.info(f"×©×¤×” {lang} ×–××™× ×” ×‘××¢×¨×›×ª")
                else:
                    logger.warning(f"×©×¤×” {lang} ×œ× ×–××™× ×” ×‘××¢×¨×›×ª")
            except Exception as e:
                logger.warning(f"×©×’×™××” ×‘×‘×“×™×§×ª ×–××™× ×•×ª ×©×¤×” {lang}: {str(e)}")
    
    def _detect_language(self, file_path: str) -> Optional[str]:
        """
        ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª ×œ×¤×™ ×¡×™×•××ª ×”×§×•×‘×¥
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×©× ×”×©×¤×” ××• None ×× ×œ× ×–×•×”×ª×”
        """
        # ×”×•×¦××ª ×¡×™×•××ª ×”×§×•×‘×¥
        ext = os.path.splitext(file_path)[1].lower()
        
        # ×—×™×¤×•×© ×”×©×¤×” ×”××ª××™××” ×œ×¡×™×•××ª
        for lang, config in self.languages_config.items():
            if ext == config.get("extension"):
                return lang
        
        return None
    
    def _timeout_handler(self, signum, frame):
        """
        ××˜×¤×œ ×‘×—×¨×™×’×ª ×–××Ÿ
        """
        raise TimeoutException("×–××Ÿ ×”×¨×¦×” ×¢×‘×¨ ××ª ×”××§×¡×™××•× ×”××•×’×“×¨")
    
    def _monitor_memory(self, process, max_memory_mb: int, stop_event: threading.Event) -> None:
        """
        × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ ×©×œ ×ª×”×œ×™×š
        
        Args:
            process: ×”×ª×”×œ×™×š ×œ× ×™×˜×•×¨
            max_memory_mb: ×’×‘×•×œ ×–×™×›×¨×•×Ÿ ×‘××’×”-×‘×™×™×˜×™×
            stop_event: ××™×¨×•×¢ ×œ×¡×™××•×Ÿ ×¢×¦×™×¨×ª ×”× ×™×˜×•×¨
        """
        try:
            import psutil
        except ImportError:
            logger.warning("×œ× × ×™×ª×Ÿ ×œ×˜×¢×•×Ÿ ××ª psutil, × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ ×œ× ×–××™×Ÿ")
            return
        
        try:
            proc = psutil.Process(process.pid)
            max_memory_bytes = max_memory_mb * 1024 * 1024
            
            while not stop_event.is_set() and process.poll() is None:
                try:
                    memory_info = proc.memory_info()
                    if memory_info.rss > max_memory_bytes:
                        logger.warning(f"×ª×”×œ×™×š {process.pid} ×¢×‘×¨ ××ª ××’×‘×œ×ª ×”×–×™×›×¨×•×Ÿ: {memory_info.rss / (1024*1024):.2f}MB")
                        process.kill()
                        break
                except Exception as e:
                    logger.error(f"×©×’×™××” ×‘× ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ: {str(e)}")
                    break
                
                # ×‘×“×™×§×” ×›×œ 0.1 ×©× ×™×•×ª
                time.sleep(0.1)
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×™×¦×™×¨×ª × ×•×˜×¨ ×–×™×›×¨×•×Ÿ: {str(e)}")
    
    def _create_sandbox(self, language: str) -> str:
        """
        ×™×¦×™×¨×ª ×¡×‘×™×‘×ª ×”×¨×¦×” ××‘×•×“×“×ª ×œ×©×¤×”
        
        Args:
            language: ×©× ×”×©×¤×”
            
        Returns:
            × ×ª×™×‘ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
        """
        # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×™×™×—×•×“×™×ª
        sandbox_id = f"{language}_{uuid.uuid4().hex[:8]}"
        sandbox_path = os.path.join(self.sandboxes_dir, sandbox_id)
        os.makedirs(sandbox_path, exist_ok=True)
        
        logger.info(f"× ×•×¦×¨×” ×¡×‘×™×‘×ª ×”×¨×¦×” {sandbox_id} ×œ×©×¤×” {language}")
        
        return sandbox_path
    
    def _prepare_file_for_execution(self, file_path: str, language: str, sandbox_path: str) -> str:
        """
        ×”×›× ×ª ×”×§×•×‘×¥ ×œ×”×¨×¦×”
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥ ×”××§×•×¨×™
            language: ×©× ×”×©×¤×”
            sandbox_path: × ×ª×™×‘ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
            
        Returns:
            × ×ª×™×‘ ×”×§×•×‘×¥ ×”××•×›×Ÿ ×œ×”×¨×¦×”
        """
        # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×§×™×™×
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"×”×§×•×‘×¥ {file_path} ×œ× × ××¦×")
        
        # ×”×¢×ª×§×ª ×”×§×•×‘×¥ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
        filename = os.path.basename(file_path)
        dest_path = os.path.join(sandbox_path, filename)
        
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as src_file:
            file_content = src_file.read()
            
        # ×”×•×¡×¤×ª ×× ×’× ×•× ×™ ×”×’× ×” ×œ×¤×™ ×©×¤×”
        if language == "python":
            # ×× ×™×¢×ª ×™×™×‘×•× ××•×“×•×œ×™× ××¡×•×›× ×™× ×•×¤×¢×•×œ×•×ª ××¡×•×›× ×•×ª
            dangerous_modules = ["os", "sys", "subprocess", "shutil"]
            for module in dangerous_modules:
                if re.search(rf"(?:^|\n)\s*import\s+{module}\b", file_content) or \
                   re.search(rf"(?:^|\n)\s*from\s+{module}\s+import", file_content):
                    logger.warning(f"×”×§×•×‘×¥ ×× ×¡×” ×œ×™×™×‘× ××•×“×•×œ ××¡×•×›×Ÿ: {module}")
            
            # ×”×•×¡×¤×ª ×”×’×‘×œ×•×ª ×–××Ÿ ×¨×™×¦×”
            safe_content = f"""
# ×§×•×“ ×‘×˜×™×—×•×ª ××•×¡×£
import signal
import sys
import time

def timeout_handler(signum, frame):
    print("Error: Script execution timed out")
    sys.exit(1)

signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm({self.timeout_seconds})

# ×§×•×“ ××§×•×¨×™
{file_content}
"""
            
            with open(dest_path, 'w', encoding='utf-8') as dest_file:
                dest_file.write(safe_content)
        
        elif language == "javascript":
            # ×–××Ÿ ×¨×™×¦×” ××•×’×‘×œ ×‘-Node.js
            safe_content = f"""
// ×§×•×“ ×‘×˜×™×—×•×ª ××•×¡×£
setTimeout(() => {{
    console.error("Error: Script execution timed out");
    process.exit(1);
}}, {self.timeout_seconds * 1000});

// ×§×•×“ ××§×•×¨×™
{file_content}
"""
            
            with open(dest_path, 'w', encoding='utf-8') as dest_file:
                dest_file.write(safe_content)
        
        else:
            # ×©×¤×•×ª ××—×¨×•×ª - ×¤×©×•×˜ ×œ×”×¢×ª×™×§ ××ª ×”×§×•×‘×¥
            with open(dest_path, 'w', encoding='utf-8') as dest_file:
                dest_file.write(file_content)
        
        # ×”×’×“×¨×ª ×”×¨×©××•×ª ×”×¨×¦×” ×œ×§×•×‘×¥
        os.chmod(dest_path, 0o755)
        
        return dest_path
    
    def _compile_if_needed(self, file_path: str, language: str, sandbox_path: str) -> Optional[Dict[str, Any]]:
        """
        ×”×™×“×•×¨ ×”×§×•×‘×¥ ×× × ×“×¨×©
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            language: ×©× ×”×©×¤×”
            sandbox_path: × ×ª×™×‘ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ×ª×•×¦××•×ª ×”×”×™×“×•×¨ ××• None ×× ×œ× × ×“×¨×© ×”×™×“×•×¨
        """
        lang_config = self.languages_config.get(language, {})
        compile_command = lang_config.get("compile_command")
        
        if not compile_command:
            return None  # ××™×Ÿ ×¦×•×¨×š ×‘×”×™×“×•×¨
        
        logger.info(f"××”×“×¨ ××ª ×”×§×•×‘×¥ {file_path} ×¢× {compile_command}")
        
        # ×‘× ×™×™×ª ×¤×§×•×“×ª ×”×”×™×“×•×¨
        compile_args = lang_config.get("compile_args", [])
        filename = os.path.basename(file_path)
        
        # ×”×—×œ×¤×ª ×¤×¨××˜×¨×™×
        full_compile_args = []
        for arg in compile_args:
            if arg == "{file}":
                full_compile_args.append(filename)
            else:
                full_compile_args.append(arg)
        
        # ×”×•×¡×¤×ª ×”×§×•×‘×¥ ×‘×¡×•×£ ×× ×œ× ×”×•×—×œ×£
        if "{file}" not in compile_args:
            full_compile_args.append(filename)
        
        cmd = [compile_command] + full_compile_args
        
        # ×”×¨×¦×ª ×¤×§×•×“×ª ×”×”×™×“×•×¨
        start_time = time.time()
        try:
            process = subprocess.run(
                cmd,
                cwd=sandbox_path,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=self.timeout_seconds
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            # ×‘×“×™×§×ª ×”×¦×œ×—×ª ×”×”×™×“×•×¨
            success = process.returncode == 0
            
            if not success:
        logger.warning(f"×”×™×“×•×¨ {file_path} × ×›×©×œ ×¢× ×§×•×“ ×”×—×–×¨×” {process.returncode}")
            
            return {
                "success": success,
                "stdout": process.stdout.decode('utf-8', errors='ignore'),
                "stderr": process.stderr.decode('utf-8', errors='ignore'),
                "return_code": process.returncode,
                "duration": duration
            }
            
        except subprocess.TimeoutExpired:
            logger.error(f"×”×™×“×•×¨ {file_path} × ×¢×¦×¨ ×¢×§×‘ ×—×¨×™×’×ª ×–××Ÿ")
            return {
                "success": False,
                "stdout": "",
                "stderr": "Error: Compilation timed out",
                "return_code": -1,
                "duration": self.timeout_seconds
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×™×“×•×¨ {file_path}: {str(e)}")
            return {
                "success": False,
                "stdout": "",
                "stderr": f"Error: {str(e)}",
                "return_code": -1,
                "duration": time.time() - start_time
            }
    
    def _execute_file(self, file_path: str, language: str, sandbox_path: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×¨×¦×ª ×§×•×‘×¥
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            language: ×©× ×”×©×¤×”
            sandbox_path: × ×ª×™×‘ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
            params: ×¤×¨××˜×¨×™× ×œ×”×¨×¦×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×¨×¦×”
        """
        lang_config = self.languages_config.get(language, {})
        command = lang_config.get("command")
        
        if not command:
            return {
                "success": False,
                "stdout": "",
                "stderr": f"Error: No command defined for language {language}",
                "return_code": -1,
                "duration": 0
            }
        
        logger.info(f"××¨×™×¥ ××ª ×”×§×•×‘×¥ {file_path} ×‘×©×¤×” {language}")
        
        # ×‘× ×™×™×ª ×¤×§×•×“×ª ×”×”×¨×¦×”
        args = lang_config.get("args", [])
        filename = os.path.basename(file_path)
        
        # ×”×—×œ×¤×ª ×¤×¨××˜×¨×™×
        full_args = []
        for arg in args:
            if arg == "{file}":
                full_args.append(filename)
            else:
                full_args.append(arg)
        
        # ×”×•×¡×¤×ª ×”×§×•×‘×¥ ×‘×¡×•×£ ×× ×œ× ×”×•×—×œ×£ ×•×œ× ×‘×¤×§×•×“×”
        file_position = lang_config.get("file_position", "{file}")
        if file_position == "{file}" and "{file}" not in args and command != filename:
            full_args.append(filename)
        
        # ×”×•×¡×¤×ª ×¤×¨××˜×¨×™× ××”××©×ª××©
        user_args = params.get("args", [])
        full_args.extend(user_args)
        
        cmd = [command] + full_args
        
        # ×¡×‘×™×‘×ª ×”×¨×¦×”
        env = os.environ.copy()
        
        # ×”×•×¡×¤×ª ××©×ª× ×™ ×¡×‘×™×‘×” ××”×’×“×¨×•×ª ×”×©×¤×”
        lang_env = lang_config.get("env", {})
        env.update(lang_env)
        
        # ×”×•×¡×¤×ª ××©×ª× ×™ ×¡×‘×™×‘×” ××”××©×ª××©
        user_env = params.get("env", {})
        env.update(user_env)
        
        # ×”×’×‘×œ×ª ×–××Ÿ ×”×¨×¦×”
        timeout = params.get("timeout", self.timeout_seconds)
        
        # ×”×’×‘×œ×ª ×–×™×›×¨×•×Ÿ
        memory_limit = params.get("memory_limit", self.memory_limit_mb)
        
        # ×”×¨×¦×ª ×”×ª×•×›× ×™×ª
        start_time = time.time()
        try:
            # ×”×’×“×¨×ª ×¡×™××•×Ÿ ×¢×¦×™×¨×” ×œ× ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ
            stop_event = threading.Event()
            
            # ×”×¤×¢×œ×ª ×”×ª×•×›× ×™×ª
            process = subprocess.Popen(
                cmd,
                cwd=sandbox_path,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                env=env,
                text=True,
                universal_newlines=True
            )
            
            # ×”×ª×—×œ×ª × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ
            memory_thread = threading.Thread(
                target=self._monitor_memory,
                args=(process, memory_limit, stop_event)
            )
            memory_thread.daemon = True
            memory_thread.start()
            
            # ×”×’×‘×œ×ª ×–××Ÿ ×”×¨×¦×”
            stdout, stderr = process.communicate(timeout=timeout)
            
            # ×¢×¦×™×¨×ª × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ
            stop_event.set()
            memory_thread.join(timeout=1.0)
            
            end_time = time.time()
            duration = end_time - start_time
            
            return {
                "success": process.returncode == 0,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": process.returncode,
                "duration": duration
            }
            
        except subprocess.TimeoutExpired:
            # × ×™×¡×™×•×Ÿ ×œ×¡×™×™× ××ª ×”×ª×”×œ×™×š
            try:
                process.kill()
                stdout, stderr = process.communicate()
            except:
                stdout, stderr = "", "Error: Could not get output"
            
            # ×¢×¦×™×¨×ª × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ
            stop_event.set()
            
            logger.warning(f"×”×¨×¦×ª {file_path} × ×¢×¦×¨×” ×¢×§×‘ ×—×¨×™×’×ª ×–××Ÿ")
            
            return {
                "success": False,
                "stdout": stdout if stdout else "",
                "stderr": stderr if stderr else "Error: Execution timed out",
                "return_code": -1,
                "duration": time.time() - start_time
            }
            
        except Exception as e:
            # ×¢×¦×™×¨×ª × ×™×˜×•×¨ ×–×™×›×¨×•×Ÿ
            stop_event.set()
            
            logger.error(f"×©×’×™××” ×‘×”×¨×¦×ª {file_path}: {str(e)}")
            
            # × ×™×¡×™×•×Ÿ ×œ×¡×™×™× ××ª ×”×ª×”×œ×™×š
            try:
                process.kill()
            except:
                pass
            
            return {
                "success": False,
                "stdout": "",
                "stderr": f"Error: {str(e)}",
                "return_code": -1,
                "duration": time.time() - start_time
            }
    
    def _cleanup_sandbox(self, sandbox_path: str) -> None:
        """
        × ×™×§×•×™ ×¡×‘×™×‘×ª ×”×¨×¦×”
        
        Args:
            sandbox_path: × ×ª×™×‘ ×œ×¡×‘×™×‘×ª ×”×”×¨×¦×”
        """
        try:
            if os.path.exists(sandbox_path):
                import shutil
                shutil.rmtree(sandbox_path)
                logger.info(f"×¡×‘×™×‘×ª ×”×¨×¦×” {sandbox_path} × ××—×§×” ×‘×”×¦×œ×—×”")
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘× ×™×§×•×™ ×¡×‘×™×‘×ª ×”×¨×¦×” {sandbox_path}: {str(e)}")
    
    def run_file(self, file_path: str, params: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ×”×¨×¦×ª ×§×•×‘×¥ ×§×•×“
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥ ×œ×”×¨×¦×”
            params: ×¤×¨××˜×¨×™× ×œ×”×¨×¦×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×¨×¦×”
        """
        if not self.enabled:
            logger.warning("×”×¨×¦×ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×”×¨×¦×ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª"}
        
        # ×‘×¨×™×¨×ª ××—×“×œ ×œ×¤×¨××˜×¨×™×
        if params is None:
            params = {}
        
        try:
            # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×§×™×™×
            if not os.path.exists(file_path):
                logger.error(f"×§×•×‘×¥ {file_path} ×œ× × ××¦×")
                return {"status": "error", "error": f"×§×•×‘×¥ {file_path} ×œ× × ××¦×"}
            
            # ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª
            language = params.get("language") or self._detect_language(file_path)
            
            if not language:
                logger.error(f"×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××ª ×©×¤×ª ×”×ª×›× ×•×ª ×©×œ ×”×§×•×‘×¥ {file_path}")
                return {"status": "error", "error": "×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××ª ×©×¤×ª ×”×ª×›× ×•×ª ×©×œ ×”×§×•×‘×¥"}
            
            if language not in self.supported_languages:
                logger.error(f"×©×¤×” {language} ××™× ×” × ×ª××›×ª")
                return {"status": "error", "error": f"×©×¤×” {language} ××™× ×” × ×ª××›×ª"}
            
            # ×™×¦×™×¨×ª ××–×”×” ×”×¨×¦×”
            run_id = str(uuid.uuid4())
            
            # ×™×¦×™×¨×ª ×¡×‘×™×‘×ª ×”×¨×¦×” ××‘×•×“×“×ª
            sandbox_path = self._create_sandbox(language)
            
            # ×”×›× ×ª ×”×§×•×‘×¥ ×œ×”×¨×¦×”
            try:
                prepared_file = self._prepare_file_for_execution(file_path, language, sandbox_path)
            except Exception as e:
                logger.error(f"×©×’×™××” ×‘×”×›× ×ª ×”×§×•×‘×¥ {file_path} ×œ×”×¨×¦×”: {str(e)}")
                self._cleanup_sandbox(sandbox_path)
                return {"status": "error", "error": f"×©×’×™××” ×‘×”×›× ×ª ×”×§×•×‘×¥ ×œ×”×¨×¦×”: {str(e)}"}
            
            # ×”×™×“×•×¨ ×”×§×•×‘×¥ ×× × ×“×¨×©
            compile_result = self._compile_if_needed(prepared_file, language, sandbox_path)
            
            if compile_result and not compile_result["success"]:
                logger.error(f"×”×™×“×•×¨ ×”×§×•×‘×¥ {file_path} × ×›×©×œ")
                result = {
                    "status": "error",
                    "run_id": run_id,
                    "error": "×©×’×™××ª ×”×™×“×•×¨",
                    "file": file_path,
                    "language": language,
                    "compile_stdout": compile_result["stdout"],
                    "compile_stderr": compile_result["stderr"],
                    "compile_return_code": compile_result["return_code"],
                    "compile_duration": compile_result["duration"]
                }
                
                # × ×™×§×•×™ ×¡×‘×™×‘×ª ×”×”×¨×¦×”
                self._cleanup_sandbox(sandbox_path)
                
                return result
            
            # ×”×¨×¦×ª ×”×§×•×‘×¥
            execution_result = self._execute_file(prepared_file, language, sandbox_path, params)
            
            # ×©××™×¨×ª ×ª×•×¦××•×ª ×”×”×¨×¦×”
            result = {
                "status": "success" if execution_result["success"] else "error",
                "run_id": run_id,
                "file": file_path,
                "language": language,
                "params": params,
                "stdout": execution_result["stdout"],
                "stderr": execution_result["stderr"],
                "return_code": execution_result["return_code"],
                "duration": execution_result["duration"]
            }
            
            # ×”×•×¡×¤×ª ×ª×•×¦××•×ª ×”×”×™×“×•×¨ ×× ×”×™×•
            if compile_result:
                result["compile_stdout"] = compile_result["stdout"]
                result["compile_stderr"] = compile_result["stderr"]
                result["compile_return_code"] = compile_result["return_code"]
                result["compile_duration"] = compile_result["duration"]
            
            # ×©××™×¨×ª ×”×”×¨×¦×” ×‘××¢×§×‘
            self.runs[run_id] = result
            
            # × ×™×§×•×™ ×¡×‘×™×‘×ª ×”×”×¨×¦×”
            self._cleanup_sandbox(sandbox_path)
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¨×¦×ª ×§×•×‘×¥ {file_path}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def run_code_snippet(self, code: str, language: str, params: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ×”×¨×¦×ª ×§×˜×¢ ×§×•×“
        
        Args:
            code: ×§×˜×¢ ×”×§×•×“ ×œ×”×¨×¦×”
            language: ×©× ×”×©×¤×”
            params: ×¤×¨××˜×¨×™× ×œ×”×¨×¦×”
            
        Returns:
            ×ª×•×¦××•×ª ×”×”×¨×¦×”
        """
        if not self.enabled:
            logger.warning("×”×¨×¦×ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×”×¨×¦×ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª"}
        
        # ×‘×¨×™×¨×ª ××—×“×œ ×œ×¤×¨××˜×¨×™×
        if params is None:
            params = {}
        
        try:
            # ×‘×“×™×§×” ×©×©×¤×ª ×”×ª×›× ×•×ª × ×ª××›×ª
            if language not in self.supported_languages:
                logger.error(f"×©×¤×” {language} ××™× ×” × ×ª××›×ª")
                return {"status": "error", "error": f"×©×¤×” {language} ××™× ×” × ×ª××›×ª"}
            
            # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×¢× ×”×§×•×“
            ext = self.languages_config.get(language, {}).get("extension", "")
            
            with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp:
                tmp.write(code.encode('utf-8'))
                tmp_path = tmp.name
            
            # ×”×¨×¦×ª ×”×§×•×“
            result = self.run_file(tmp_path, params)
            
            # ×”×•×¡×¤×ª ×”×§×•×“ ×”××§×•×¨×™ ×œ×ª×•×¦××”
            result["code"] = code
            
            # ××—×™×§×ª ×”×§×•×‘×¥ ×”×–×× ×™
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¨×¦×ª ×§×˜×¢ ×§×•×“: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def get_run_info(self, run_id: str) -> Dict[str, Any]:
        """
        ×§×‘×œ×ª ××™×“×¢ ×¢×œ ×”×¨×¦×”
        
        Args:
            run_id: ××–×”×” ×”×”×¨×¦×”
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×”×¨×¦×”
        """
        if run_id not in self.runs:
            logger.warning(f"×”×¨×¦×” {run_id} ×œ× × ××¦××”")
            return {"status": "error", "error": f"×”×¨×¦×” {run_id} ×œ× × ××¦××”"}
        
        return self.runs[run_id]
    
    def stop_code_execution(self, run_id: str) -> Dict[str, Any]:
        """
        ×¢×¦×™×¨×ª ×”×¨×¦×ª ×§×•×“
        
        ×©×™× ×œ×‘: ×›×¨×’×¢ ×œ× × ×ª××š ×‘×¦×•×¨×” ××œ××” ××›×™×•×•×Ÿ ×©×”×”×¨×¦×” ×”×™× ×¡×™× ×›×¨×•× ×™×ª.
        
        Args:
            run_id: ××–×”×” ×”×”×¨×¦×”
            
        Returns:
            ×ª×•×¦××ª ×”×¢×¦×™×¨×”
        """
        logger.warning(f"×¢×¦×™×¨×ª ×”×¨×¦×ª ×§×•×“ {run_id} ×œ× × ×ª××›×ª ×›×¨×’×¢")
        return {"status": "warning", "warning": "×¢×¦×™×¨×ª ×”×¨×¦×ª ×§×•×“ ××™× ×” × ×ª××›×ª ×›×¨×’×¢"}
CODE_RUNNER_PY

# ×™×¦×™×¨×ª ××•×“×•×œ ×”×©×œ××ª ×§×•×“
echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ ×”×©×œ××ª ×§×•×“..."
cat > "$BASE_DIR/core/code_completer.py" << 'CODE_COMPLETER_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
××•×“×•×œ ×”×©×œ××ª ×§×•×“ ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
×××¤×©×¨ ×–×™×”×•×™ ×•×”×©×œ××” ×©×œ ×§×•×“ ×—×¡×¨

××—×‘×¨: Claude AI
×’×¨×¡×”: 1.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import re
import sys
import ast
import json
import logging
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×”×’×“×¨×ª ×œ×•×’×™×
logger = logging.getLogger(__name__)

class CodeCompleter:
    """
    ×× ×”×œ ×”×©×œ××ª ×§×•×“ ×œ×–×™×”×•×™ ×•×”×©×œ××” ×©×œ ×§×•×“ ×—×¡×¨
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        ××ª×—×•×œ ×× ×”×œ ×”×©×œ××ª ×”×§×•×“
        
        Args:
            config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×ª×¦×•×¨×”
        """
        self.config = config
        self.enabled = config.get("enabled", True)
        self.suggestions_limit = config.get("suggestions_limit", 5)
        self.context_lines = config.get("context_lines", 10)
        self.supported_languages = config.get("supported_languages", ["python", "javascript", "java", "c", "cpp"])
        
        logger.info(f"×× ×”×œ ×”×©×œ××ª ×§×•×“ ××•×ª×—×œ ×¢× ×”×’×“×¨×•×ª: suggestions_limit={self.suggestions_limit}, "
                   f"context_lines={self.context_lines}")
    
    def _detect_language(self, file_path: str) -> Optional[str]:
        """
        ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª ×œ×¤×™ ×¡×™×•××ª ×”×§×•×‘×¥
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×©× ×”×©×¤×” ××• None ×× ×œ× ×–×•×”×ª×”
        """
        # ×”×•×¦××ª ×¡×™×•××ª ×”×§×•×‘×¥
        ext = os.path.splitext(file_path)[1].lower()
        
        # ××™×¤×•×™ ×¡×™×•××•×ª × ×¤×•×¦×•×ª ×œ×©×¤×•×ª
        extensions_map = {
            ".py": "python",
            ".js": "javascript",
            ".jsx": "javascript",
            ".ts": "typescript",
            ".tsx": "typescript",
            ".java": "java",
            ".c": "c",
            ".cpp": "cpp",
            ".cxx": "cpp",
            ".cc": "cpp",
            ".h": "c",
            ".hpp": "cpp",
            ".rb": "ruby",
            ".php": "php",
            ".go": "go",
            ".swift": "swift",
            ".kt": "kotlin",
            ".cs": "csharp",
            ".rs": "rust"
        }
        
        return extensions_map.get(ext)
    
    def _get_file_context(self, file_path: str, line: int, context_lines: int) -> Dict[str, Any]:
        """
        ×§×‘×œ×ª ×”×§×©×¨ ×”×§×•×“ ×¡×‘×™×‘ ×©×•×¨×” ××¡×•×™××ª
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            line: ××¡×¤×¨ ×”×©×•×¨×”
            context_lines: ××¡×¤×¨ ×©×•×¨×•×ª ×”×§×©×¨
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ×”×§×©×¨ ×”×§×•×“
        """
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # ×•×™×“×•× ×©××¡×¤×¨ ×”×©×•×¨×” ×ª×§×™×Ÿ
            line = max(1, min(line, len(lines)))
            
            # ×—×™×©×•×‘ ×˜×•×•×— ×©×•×¨×•×ª ×”×”×§×©×¨
            start_line = max(0, line - context_lines - 1)
            end_line = min(len(lines), line + context_lines)
            
            # ×”×•×¦××ª ×©×•×¨×•×ª ×”×”×§×©×¨
            before_lines = lines[start_line:line-1]
            target_line = lines[line-1] if line <= len(lines) else ""
            after_lines = lines[line:end_line]
            
            return {
                "before": "".join(before_lines),
                "target": target_line,
                "after": "".join(after_lines),
                "line": line,
                "file_path": file_path
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×§×‘×œ×ª ×”×§×©×¨ ×§×•×“ ××§×•×‘×¥ {file_path}: {str(e)}")
            return {
                "before": "",
                "target": "",
                "after": "",
                "line": line,
                "file_path": file_path
            }
    
    def detect_missing_parts(self, file_path: str) -> Dict[str, Any]:
        """
        ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×“
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ×—×œ×§×™× ×—×¡×¨×™× ×©×–×•×”×•
        """
        if not self.enabled:
            logger.warning("×”×©×œ××ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "warning", "warning": "×”×©×œ××ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª"}
        
        try:
            # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×§×™×™×
            if not os.path.exists(file_path):
                logger.error(f"×§×•×‘×¥ {file_path} ×œ× × ××¦×")
                return {"status": "error", "error": f"×§×•×‘×¥ {file_path} ×œ× × ××¦×"}
            
            # ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª
            language = self._detect_language(file_path)
            
            if not language:
                logger.error(f"×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××ª ×©×¤×ª ×”×ª×›× ×•×ª ×©×œ ×”×§×•×‘×¥ {file_path}")
                return {"status": "error", "error": "×œ× × ×™×ª×Ÿ ×œ×–×”×•×ª ××ª ×©×¤×ª ×”×ª×›× ×•×ª ×©×œ ×”×§×•×‘×¥"}
            
            if language not in self.supported_languages:
                logger.warning(f"×©×¤×” {language} ××™× ×” × ×ª××›×ª ×œ×”×©×œ××ª ×§×•×“")
                return {"status": "warning", "warning": f"×©×¤×” {language} ××™× ×” × ×ª××›×ª ×œ×”×©×œ××ª ×§×•×“"}
            
            # ×§×¨×™××ª ×”×§×•×‘×¥
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.splitlines()
            
            # ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×œ×¤×™ ×©×¤×”
            missing_parts = []
            
            if language == "python":
                missing_parts = self._detect_missing_parts_python(content, lines, file_path)
            elif language in ["javascript", "typescript"]:
                missing_parts = self._detect_missing_parts_javascript(content, lines, file_path)
            elif language == "java":
                missing_parts = self._detect_missing_parts_java(content, lines, file_path)
            elif language in ["c", "cpp"]:
                missing_parts = self._detect_missing_parts_c_cpp(content, lines, file_path)
            
            # ×¡×™×›×•× ×”××¦×‘
            if missing_parts:
                logger.info(f"× ××¦××• {len(missing_parts)} ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥ {file_path}")
                return {
                    "status": "success",
                    "file_path": file_path,
                    "language": language,
                    "missing_parts": missing_parts,
                    "missing_count": len(missing_parts)
                }
            else:
                logger.info(f"×œ× × ××¦××• ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥ {file_path}")
                return {
                    "status": "success",
                    "file_path": file_path,
                    "language": language,
                    "missing_parts": [],
                    "missing_count": 0
                }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥ {file_path}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _detect_missing_parts_python(self, content: str, lines: List[str], file_path: str) -> List[Dict[str, Any]]:
        """
        ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×“ Python
        
        Args:
            content: ×ª×•×›×Ÿ ×”×§×•×‘×¥
            lines: ×©×•×¨×•×ª ×”×§×•×‘×¥
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×¨×©×™××ª ×—×œ×§×™× ×—×¡×¨×™× ×©×–×•×”×•
        """
        missing_parts = []
        
        # × ×™×¡×™×•×Ÿ ×œ× ×ª×— ××ª ×”×§×•×“
        try:
            ast.parse(content)
            # ×× ×”×’×¢× ×• ×œ×›××Ÿ, ××™×Ÿ ×©×’×™××•×ª ×ª×—×‘×™×¨
        except SyntaxError as e:
            # ×™×© ×©×’×™××ª ×ª×—×‘×™×¨
            line_num = e.lineno
            context = self._get_file_context(file_path, line_num, self.context_lines)
            
            missing_parts.append({
                "type": "syntax_error",
                "line": line_num,
                "column": e.offset,
                "message": str(e),
                "context": context
            })
        
        # ×—×™×¤×•×© ×¤×•× ×§×¦×™×•×ª ×—×¡×¨×•×ª
        func_call_pattern = r'\b(\w+)\s*\('
        defined_functions = set()
        function_calls = set()
        
        # ××™×¡×•×£ ×¤×•× ×§×¦×™×•×ª ××•×’×“×¨×•×ª
        func_def_pattern = r'def\s+(\w+)\s*\('
        for match in re.finditer(func_def_pattern, content):
            defined_functions.add(match.group(1))
        
        # ××™×¡×•×£ ×§×¨×™××•×ª ×œ×¤×•× ×§×¦×™×•×ª
        for match in re.finditer(func_call_pattern, content):
            func_name = match.group(1)
            if func_name not in ["print", "int", "str", "float", "list", "dict", "set", "tuple", "len", "range", "enumerate", "zip", "open", "input", "type"]:
                function_calls.add(func_name)
        
        # ×¨×©×™××ª ×¤×•× ×§×¦×™×•×ª ×—×¡×¨×•×ª
        missing_functions = function_calls - defined_functions
        
        # ×”×¡×¨×ª ×¤×•× ×§×¦×™×•×ª ×¡×˜× ×“×¨×˜×™×•×ª ×©×œ× × ×—×©×‘×•×ª ×›×—×¡×¨×•×ª
        standard_functions = self._get_python_standard_functions()
        missing_functions = missing_functions - standard_functions
        
        # ×”×•×¡×¤×ª ×¤×•× ×§×¦×™×•×ª ×—×¡×¨×•×ª ×œ×¨×©×™××”
        for func_name in missing_functions:
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×§×¨×™××” ×”×¨××©×•× ×” ×œ×¤×•× ×§×¦×™×”
            pattern = r'\b' + re.escape(func_name) + r'\s*\('
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_function",
                        "name": func_name,
                        "line": i,
                        "message": f"×§×¨×™××” ×œ×¤×•× ×§×¦×™×” {func_name} ×©××™× ×” ××•×’×“×¨×ª",
                        "context": context
                    })
                    break
        
        # ×—×™×¤×•×© ××—×œ×§×•×ª ×—×¡×¨×•×ª
        class_usage_pattern = r'\b(\w+)\s*\(\s*\)'
        defined_classes = set()
        class_usages = set()
        
        # ××™×¡×•×£ ××—×œ×§×•×ª ××•×’×“×¨×•×ª
        class_def_pattern = r'class\s+(\w+)\s*[:\(]'
        for match in re.finditer(class_def_pattern, content):
            defined_classes.add(match.group(1))
        
        # ××™×¡×•×£ ×©×™××•×©×™× ×‘××—×œ×§×•×ª
        for match in re.finditer(class_usage_pattern, content):
            class_name = match.group(1)
            if class_name[0].isupper():  # ××•×¡×›××ª ×”×©××•×ª ×‘-Python ×œ××—×œ×§×•×ª
                class_usages.add(class_name)
        
        # ×¨×©×™××ª ××—×œ×§×•×ª ×—×¡×¨×•×ª
        missing_classes = class_usages - defined_classes
        
        # ×”×¡×¨×ª ××—×œ×§×•×ª ×¡×˜× ×“×¨×˜×™×•×ª ×©×œ× × ×—×©×‘×•×ª ×›×—×¡×¨×•×ª
        standard_classes = {"Exception", "ValueError", "TypeError", "FileNotFoundError", "IOError", "KeyError", "IndexError"}
        missing_classes = missing_classes - standard_classes
        
        # ×”×•×¡×¤×ª ××—×œ×§×•×ª ×—×¡×¨×•×ª ×œ×¨×©×™××”
        for class_name in missing_classes:
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×©×™××•×© ×”×¨××©×•× ×” ×‘××—×œ×§×”
            pattern = r'\b' + re.escape(class_name) + r'\s*\(\s*\)'
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_class",
                        "name": class_name,
                        "line": i,
                        "message": f"×©×™××•×© ×‘××—×œ×§×” {class_name} ×©××™× ×” ××•×’×“×¨×ª",
                        "context": context
                    })
                    break
        
        # ×—×™×¤×•×© ×™×™×‘×•× ×—×¡×¨
        import_pattern = r'(?:from\s+(\w+)(?:\.\w+)*\s+import|import\s+(\w+)(?:\.\w+)*)'
        imported_modules = set()
        
        # ××™×¡×•×£ ××•×“×•×œ×™× ××™×•×‘××™×
        for match in re.finditer(import_pattern, content):
            module_name = match.group(1) or match.group(2)
            imported_modules.add(module_name.split('.')[0])
        
        # ×—×™×¤×•×© ×©×™××•×© ×‘××•×“×•×œ×™×
        module_usage_pattern = r'\b(\w+)\.'
        used_modules = set()
        
        for match in re.finditer(module_usage_pattern, content):
            module_name = match.group(1)
            if not (module_name.startswith('_') or module_name[0].isupper() or module_name == 'self'):
                used_modules.add(module_name)
        
        # ×¨×©×™××ª ××•×“×•×œ×™× ×—×¡×¨×™×
        missing_modules = used_modules - imported_modules
        
        # ×”×•×¡×¤×ª ××•×“×•×œ×™× ×—×¡×¨×™× ×œ×¨×©×™××”
        for module_name in missing_modules:
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×©×™××•×© ×”×¨××©×•× ×” ×‘××•×“×•×œ
            pattern = r'\b' + re.escape(module_name) + r'\.'
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_import",
                        "name": module_name,
                        "line": i,
                        "message": f"×©×™××•×© ×‘××•×“×•×œ {module_name} ×œ×œ× ×™×™×‘×•×",
                        "context": context
                    })
                    break
        
        # ×—×™×¤×•×© ×¤×•× ×§×¦×™×•×ª ×œ× ××•×©×œ××•×ª ××• ×©×”×©××¨×• ×œ××™×œ×•×™ (×¨×™×§×•×ª ××• ×¢× pass ××• TODO)
        func_def_pattern = r'def\s+(\w+)\s*\(([^)]*)\)[^:]*:\s*(?:pass|TODO|FIXME|#[^\n]*)?$'
        for i, line in enumerate(lines, 1):
            match = re.search(func_def_pattern, line)
            if match:
                func_name = match.group(1)
                params = match.group(2)
                context = self._get_file_context(file_path, i, self.context_lines)
                
                missing_parts.append({
                    "type": "empty_function",
                    "name": func_name,
                    "params": params,
                    "line": i,
                    "message": f"×¤×•× ×§×¦×™×” ×¨×™×§×” {func_name}",
                    "context": context
                })
        
        return missing_parts
    
    def _detect_missing_parts_javascript(self, content: str, lines: List[str], file_path: str) -> List[Dict[str, Any]]:
        """
        ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×“ JavaScript
        
        Args:
            content: ×ª×•×›×Ÿ ×”×§×•×‘×¥
            lines: ×©×•×¨×•×ª ×”×§×•×‘×¥
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×¨×©×™××ª ×—×œ×§×™× ×—×¡×¨×™× ×©×–×•×”×•
        """
        missing_parts = []
        
        # ×—×™×¤×•×© ×¡×•×’×¨×™×™× ×œ× ×××•×–× ×™×
        brackets = {'(': ')', '[': ']', '{': '}'}
        stack = []
        
        for i, char in enumerate(content):
            if char in brackets.keys():
                stack.append((char, i))
            elif char in brackets.values():
                if not stack:
                    # ×™×•×ª×¨ ×¡×•×’×¨×™×™× ×¡×•×’×¨×™× ××¤×•×ª×—×™×
                    line_num = content[:i].count('\n') + 1
                    context = self._get_file_context(file_path, line_num, self.context_lines)
                    
                    missing_parts.append({
                        "type": "unbalanced_brackets",
                        "line": line_num,
                        "message": f"×¡×•×’×¨ {char} ×œ×œ× ×¤×•×ª×— ××ª××™×",
                        "context": context
                    })
                else:
                    last_open, _ = stack.pop()
                    if char != brackets[last_open]:
                        # ×¡×•×’×¨ ×œ× ××ª××™×
                        line_num = content[:i].count('\n') + 1
                        context = self._get_file_context(file_path, line_num, self.context_lines)
                        
                        missing_parts.append({
                            "type": "unbalanced_brackets",
                            "line": line_num,
                            "message": f"×¡×•×’×¨ {char} ×œ× ××ª××™× ×œ-{last_open}",
                            "context": context
                        })
        
        # ×¡×•×’×¨×™×™× ×¤×•×ª×—×™× ×©×œ× × ×¡×’×¨×•
        for open_bracket, pos in stack:
            line_num = content[:pos].count('\n') + 1
            context = self._get_file_context(file_path, line_num, self.context_lines)
            
            missing_parts.append({
                "type": "unbalanced_brackets",
                "line": line_num,
                "message": f"×¡×•×’×¨ ×¤×•×ª×— {open_bracket} ×œ×œ× ×¡×•×’×¨",
                "context": context
            })
        
        # ×—×™×¤×•×© ×¤×¡×™×§×™× ×—×¡×¨×™× ×‘××•×‘×™×™×§×˜×™× ×•××¢×¨×›×™×
        for i, line in enumerate(lines, 1):
            # ×‘×“×™×§×ª ×©×•×¨×•×ª ×©× ×¨××•×ª ×›××• ×—×œ×§ ×××•×‘×™×™×§×˜ ××• ××¢×¨×š
            if re.search(r'^\s*[\'"][^\'":]*[\'"]\s*:', line) or re.search(r'^\s*\w+\s*:', line):
                # ×× ×”×©×•×¨×” ××¡×ª×™×™××ª ×œ×œ× ×¤×¡×™×§ ×•×’× ×œ× ×‘×¡×•×’×¨
                if not re.search(r'[,{}[\]]$', line.rstrip()):
                    next_line_idx = i
                    if next_line_idx < len(lines):
                        next_line = lines[next_line_idx]
                        # ×× ×”×©×•×¨×” ×”×‘××” × ×¨××™×ª ×›××• ×”××©×š ×©×œ ××•×‘×™×™×§×˜/××¢×¨×š
                        if re.search(r'^\s*[\'"][^\'":]*[\'"]\s*:', next_line) or re.search(r'^\s*\w+\s*:', next_line):
                            context = self._get_file_context(file_path, i, self.context_lines)
                            
                            missing_parts.append({
                                "type": "missing_comma",
                                "line": i,
                                "message": "×¤×¡×™×§ ×—×¡×¨ ×‘×¡×•×£ ×©×•×¨×” ×‘××•×‘×™×™×§×˜/××¢×¨×š",
                                "context": context
                            })
        
        # ×—×™×¤×•×© × ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×”
        for i, line in enumerate(lines, 1):
            # × ×¡×™×¨ ×”×¢×¨×•×ª
            clean_line = re.sub(r'//.*$', '', line)
            # ×‘×“×™×§×ª ×©×•×¨×•×ª ×©× ×¨××•×ª ×›××• ×”×¦×”×¨×•×ª ××š ×œ×œ× × ×§×•×“×”-×¤×¡×™×§ ×‘×¡×•×£
            if (re.search(r'(var|let|const)\s+\w+\s*=', clean_line) or 
                re.search(r'\w+\.\w+\s*\(', clean_line) or 
                re.search(r'\w+\s*\+\+', clean_line) or 
                re.search(r'\w+\s*--', clean_line)):
                
                if not re.search(r';$', clean_line.rstrip()):
                    # ×‘×“×™×§×” ×©×”×©×•×¨×” ×œ× ××¡×ª×™×™××ª ×‘×¤×ª×™×—×ª ×‘×œ×•×§ ××• ××—×¨×•×–×ª
                    if not re.search(r'[{[(/"`\']$', clean_line.rstrip()):
                        context = self._get_file_context(file_path, i, self.context_lines)
                        
                        missing_parts.append({
                            "type": "missing_semicolon",
                            "line": i,
                            "message": "× ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×” ×‘×¡×•×£ ×©×•×¨×”",
                            "context": context
                        })
        
        # ×—×™×¤×•×© ×¤×•× ×§×¦×™×•×ª ×œ× ××•×©×œ××•×ª
        for i, line in enumerate(lines, 1):
            # ×ª×‘× ×™×ª ×œ×–×™×”×•×™ ×¤×•× ×§×¦×™×•×ª ×¨×™×§×•×ª ××• ×¢× TODO
            if re.search(r'function\s+(\w+)\s*\([^)]*\)\s*{\s*(//\s*TODO|$)', line):
                # ×‘×“×™×§×” ×× ×”×¤×•× ×§×¦×™×” ×¨×™×§×”
                is_empty = True
                for j in range(i+1, min(i+5, len(lines)+1)):
                    if re.search(r'[^whitespace]', lines[j-1]) and not re.search(r'^\s*(//|$)', lines[j-1]):
                        is_empty = False
                        break
                    if re.search(r'^\s*}', lines[j-1]):
                        break
                
                if is_empty:
                    match = re.search(r'function\s+(\w+)', line)
                    func_name = match.group(1) if match else "unknown"
                    context = self._get_file_context(file_path, i, self.context_lines)
                    
                    missing_parts.append({
                        "type": "empty_function",
                        "name": func_name,
                        "line": i,
                        "message": f"×¤×•× ×§×¦×™×” ×¨×™×§×” {func_name}",
                        "context": context
                    })
        
        # ×—×™×¤×•×© ×™×™×‘×•× ×—×¡×¨
        imported_modules = set()
        
        # ××™×¡×•×£ ××•×“×•×œ×™× ××™×•×‘××™×
        import_patterns = [
            r'import\s+\*\s+as\s+(\w+)\s+from',  # import * as name from
            r'import\s+{\s*[^}]*\s*}\s+from\s+[\'"]([^\'"]+)[\'"]',  # import { ... } from 'module'
            r'import\s+(\w+)(?:,\s*{[^}]*})?\s+from',  # import name from
            r'const\s+(\w+)\s*=\s*require\([\'"]([^\'"]+)[\'"]'  # const name = require('module')
        ]
        
        for pattern in import_patterns:
            for match in re.finditer(pattern, content):
                if match.lastindex and match.group(1):
                    imported_modules.add(match.group(1))
        
        # ×—×™×¤×•×© ×©×™××•×© ×‘××•×“×•×œ×™×
        module_usage_pattern = r'\b(\w+)\.[a-zA-Z_]\w*'
        used_modules = set()
        
        for match in re.finditer(module_usage_pattern, content):
            module_name = match.group(1)
            if not (module_name.startswith('_') or module_name == 'this' or module_name == 'window' or module_name == 'document' or module_name == 'console'):
                used_modules.add(module_name)
        
        # ×¨×©×™××ª ××•×“×•×œ×™× ×—×¡×¨×™×
        missing_modules = used_modules - imported_modules
        
        # ×¨×©×™××ª ××•×“×•×œ×™× ×’×œ×•×‘×œ×™×™× ×©×œ× × ×—×©×‘×™× ×›×—×¡×¨×™×
        global_modules = {"Math", "JSON", "Date", "Array", "Object", "String", "Number", "Boolean", "RegExp", "Map", "Set", "Promise", "Proxy", "Reflect"}
        missing_modules = missing_modules - global_modules
        
        # ×”×•×¡×¤×ª ××•×“×•×œ×™× ×—×¡×¨×™× ×œ×¨×©×™××”
        for module_name in missing_modules:
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×©×™××•×© ×”×¨××©×•× ×” ×‘××•×“×•×œ
            pattern = r'\b' + re.escape(module_name) + r'\.'
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_import",
                        "name": module_name,
                        "line": i,
                        "message": f"×©×™××•×© ×‘××•×“×•×œ {module_name} ×œ×œ× ×™×™×‘×•×",
                        "context": context
                    })
                    break
        
        return missing_parts
    
    def _detect_missing_parts_java(self, content: str, lines: List[str], file_path: str) -> List[Dict[str, Any]]:
        """
        ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×“ Java
        
        Args:
            content: ×ª×•×›×Ÿ ×”×§×•×‘×¥
            lines: ×©×•×¨×•×ª ×”×§×•×‘×¥
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×¨×©×™××ª ×—×œ×§×™× ×—×¡×¨×™× ×©×–×•×”×•
        """
        missing_parts = []
        
        # ×—×™×¤×•×© ×¡×•×’×¨×™×™× ×œ× ×××•×–× ×™×
        brackets = {'(': ')', '[': ']', '{': '}'}
        stack = []
        
        for i, char in enumerate(content):
            if char in brackets.keys():
                stack.append((char, i))
            elif char in brackets.values():
                if not stack:
                    # ×™×•×ª×¨ ×¡×•×’×¨×™×™× ×¡×•×’×¨×™× ××¤×•×ª×—×™×
                    line_num = content[:i].count('\n') + 1
                    context = self._get_file_context(file_path, line_num, self.context_lines)
                    
                    missing_parts.append({
                        "type": "unbalanced_brackets",
                        "line": line_num,
                        "message": f"×¡×•×’×¨ {char} ×œ×œ× ×¤×•×ª×— ××ª××™×",
                        "context": context
                    })
                else:
                    last_open, _ = stack.pop()
                    if char != brackets[last_open]:
                        # ×¡×•×’×¨ ×œ× ××ª××™×
                        line_num = content[:i].count('\n') + 1
                        context = self._get_file_context(file_path, line_num, self.context_lines)
                        
                        missing_parts.append({
                            "type": "unbalanced_brackets",
                            "line": line_num,
                            "message": f"×¡×•×’×¨ {char} ×œ× ××ª××™× ×œ-{last_open}",
                            "context": context
                        })
        
        # ×¡×•×’×¨×™×™× ×¤×•×ª×—×™× ×©×œ× × ×¡×’×¨×•
        for open_bracket, pos in stack:
            line_num = content[:pos].count('\n') + 1
            context = self._get_file_context(file_path, line_num, self.context_lines)
            
            missing_parts.append({
                "type": "unbalanced_brackets",
                "line": line_num,
                "message": f"×¡×•×’×¨ ×¤×•×ª×— {open_bracket} ×œ×œ× ×¡×•×’×¨",
                "context": context
            })
        
        # ×—×™×¤×•×© × ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×”
        for i, line in enumerate(lines, 1):
            # × ×¡×™×¨ ×”×¢×¨×•×ª
            clean_line = re.sub(r'//.*$', '', line)
            
            # ×‘×“×™×§×ª ×©×•×¨×•×ª ×©× ×¨××•×ª ×›××• ×”×¦×”×¨×•×ª ××š ×œ×œ× × ×§×•×“×”-×¤×¡×™×§ ×‘×¡×•×£
            if (not re.search(r'^\s*(?:public|private|protected|class|interface|enum|if|else|for|while|do|switch|case|try|catch|finally|import|package|\{|\}|$)', clean_line) and
                not re.search(r';$', clean_line.rstrip()) and
                not re.search(r'[{(/`\']$', clean_line.rstrip())):
                
                context = self._get_file_context(file_path, i, self.context_lines)
                
                missing_parts.append({
                    "type": "missing_semicolon",
                    "line": i,
                    "message": "× ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×” ×‘×¡×•×£ ×©×•×¨×”",
                    "context": context
                })
        
        # ×—×™×¤×•×© ××ª×•×“×•×ª ×œ× ××•×©×œ××•×ª
        method_pattern = r'\s*(?:public|private|protected)?\s+\w+\s+(\w+)\s*\([^)]*\)\s*\{\s*(?://.*)?$'
        for i, line in enumerate(lines, 1):
            match = re.search(method_pattern, line)
            if match:
                # ×‘×“×™×§×” ×× ×”××ª×•×“×” ×¨×™×§×”
                is_empty = True
                for j in range(i+1, min(i+5, len(lines)+1)):
                    if re.search(r'[^\s]', lines[j-1]) and not re.search(r'^\s*(?://|$)', lines[j-1]):
                        is_empty = False
                        break
                    if re.search(r'^\s*}', lines[j-1]):
                        break
                
                if is_empty:
                    method_name = match.group(1)
                    context = self._get_file_context(file_path, i, self.context_lines)
                    
                    missing_parts.append({
                        "type": "empty_method",
                        "name": method_name,
                        "line": i,
                        "message": f"××ª×•×“×” ×¨×™×§×” {method_name}",
                        "context": context
                    })
        
        # ×—×™×¤×•×© ×™×™×‘×•× ×—×¡×¨
        imported_classes = set()
        
        # ××™×¡×•×£ ××—×œ×§×•×ª ××™×•×‘××•×ª
        import_pattern = r'import\s+(?:static\s+)?([a-zA-Z_][\w.]*(?:\.\*)?);'
        for match in re.finditer(import_pattern, content):
            import_path = match.group(1)
            if import_path.endswith(".*"):
                # ×™×™×‘×•× ×—×‘×™×œ×” ×©×œ××”, ×œ× × ×™×ª×Ÿ ×œ×“×¢×ª ×‘×“×™×•×§ ××™×–×” ××—×œ×§×•×ª
                continue
            
            class_name = import_path.split(".")[-1]
            imported_classes.add(class_name)
        
        # ×—×™×¤×•×© ×©×™××•×© ×‘××—×œ×§×•×ª ×—×™×¦×•× ×™×•×ª
        # ×©×™××•×© ×‘×ª×‘× ×™×ª ×¤×©×•×˜×” - ×œ× ××•×©×œ× ××‘×œ ×¢×•×‘×“ ×¢×‘×•×¨ ×¨×•×‘ ×”××§×¨×™×
        class_usage_pattern = r'\b([A-Z][a-zA-Z0-9_]*)\b(?:\s*\.\s*\w+|\s*<|\s+\w+|\s*\[)'
        used_classes = set()
        
        for match in re.finditer(class_usage_pattern, content):
            class_name = match.group(1)
            if class_name not in ["String", "Integer", "Double", "Boolean", "Character", "Byte", "Short", "Long", "Float", "Object", "Class", "System", "Math"]:
                used_classes.add(class_name)
        
        # ×¨×©×™××ª ××—×œ×§×•×ª ×—×¡×¨×•×ª
        missing_classes = used_classes - imported_classes
        
        # ×”×•×¦××ª ××—×œ×§×•×ª ×©×”×•×’×“×¨×• ×‘×§×•×‘×¥ ×¢×¦××•
        defined_classes = set()
        class_def_pattern = r'(?:public|private|protected)?\s+class\s+([A-Z][a-zA-Z0-9_]*)'
        for match in re.finditer(class_def_pattern, content):
            defined_classes.add(match.group(1))
        
        missing_classes = missing_classes - defined_classes
        
        # ×”×¡×¨×ª ××—×œ×§×•×ª ×¡×˜× ×“×¨×˜×™×•×ª ×©×œ× × ×—×©×‘×•×ª ×›×—×¡×¨×•×ª
        standard_classes = {"String", "Integer", "Double", "Boolean", "Character", "Byte", "Short", "Long", "Float", "Object", "Class", "System", "Math", "Exception", "RuntimeException", "Thread", "Runnable"}
        missing_classes = missing_classes - standard_classes
        
        # ×”×•×¡×¤×ª ××—×œ×§×•×ª ×—×¡×¨×•×ª ×œ×¨×©×™××”
        for class_name in missing_classes:
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×©×™××•×© ×”×¨××©×•× ×” ×‘××—×œ×§×”
            pattern = r'\b' + re.escape(class_name) + r'\b'
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_import",
                        "name": class_name,
                        "line": i,
                        "message": f"×©×™××•×© ×‘××—×œ×§×” {class_name} ×œ×œ× ×™×™×‘×•×",
                        "context": context
                    })
                    break
        
        return missing_parts
    
    def _detect_missing_parts_c_cpp(self, content: str, lines: List[str], file_path: str) -> List[Dict[str, Any]]:
        """
        ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×“ C/C++
        
        Args:
            content: ×ª×•×›×Ÿ ×”×§×•×‘×¥
            lines: ×©×•×¨×•×ª ×”×§×•×‘×¥
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            
        Returns:
            ×¨×©×™××ª ×—×œ×§×™× ×—×¡×¨×™× ×©×–×•×”×•
        """
        missing_parts = []
        
        # ×—×™×¤×•×© ×¡×•×’×¨×™×™× ×œ× ×××•×–× ×™×
        brackets = {'(': ')', '[': ']', '{': '}'}
        stack = []
        
        for i, char in enumerate(content):
            if char in brackets.keys():
                stack.append((char, i))
            elif char in brackets.values():
                if not stack:
                    # ×™×•×ª×¨ ×¡×•×’×¨×™×™× ×¡×•×’×¨×™× ××¤×•×ª×—×™×
                    line_num = content[:i].count('\n') + 1
                    context = self._get_file_context(file_path, line_num, self.context_lines)
                    
                    missing_parts.append({
                        "type": "unbalanced_brackets",
                        "line": line_num,
                        "message": f"×¡×•×’×¨ {char} ×œ×œ× ×¤×•×ª×— ××ª××™×",
                        "context": context
                    })
                else:
                    last_open, _ = stack.pop()
                    if char != brackets[last_open]:
                        # ×¡×•×’×¨ ×œ× ××ª××™×
                        line_num = content[:i].count('\n') + 1
                        context = self._get_file_context(file_path, line_num, self.context_lines)
                        
                        missing_parts.append({
                            "type": "unbalanced_brackets",
                            "line": line_num,
                            "message": f"×¡×•×’×¨ {char} ×œ× ××ª××™× ×œ-{last_open}",
                            "context": context
                        })
        
        # ×¡×•×’×¨×™×™× ×¤×•×ª×—×™× ×©×œ× × ×¡×’×¨×•
        for open_bracket, pos in stack:
            line_num = content[:pos].count('\n') + 1
            context = self._get_file_context(file_path, line_num, self.context_lines)
            
            missing_parts.append({
                "type": "unbalanced_brackets",
                "line": line_num,
                "message": f"×¡×•×’×¨ ×¤×•×ª×— {open_bracket} ×œ×œ× ×¡×•×’×¨",
                "context": context
            })
        
        # ×—×™×¤×•×© × ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×”
        for i, line in enumerate(lines, 1):
            # × ×¡×™×¨ ×”×¢×¨×•×ª
            clean_line = re.sub(r'//.*$', '', line)
            
            # ×‘×“×™×§×ª ×©×•×¨×•×ª ×©× ×¨××•×ª ×›××• ×”×¦×”×¨×•×ª ××š ×œ×œ× × ×§×•×“×”-×¤×¡×™×§ ×‘×¡×•×£
            if (not re.search(r'^\s*(?:#|typedef|struct|class|enum|if|else|for|while|do|switch|case|try|catch|return|sizeof|void|template|\{|\}|$)', clean_line) and
                not re.search(r';$', clean_line.rstrip()) and
                not re.search(r'[{(/`\']$', clean_line.rstrip())):
                
                context = self._get_file_context(file_path, i, self.context_lines)
                
                missing_parts.append({
                    "type": "missing_semicolon",
                    "line": i,
                    "message": "× ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×” ×‘×¡×•×£ ×©×•×¨×”",
                    "context": context
                })
        
        # ×—×™×¤×•×© ×¤×•× ×§×¦×™×•×ª ×œ× ××•×©×œ××•×ª
        func_pattern = r'(?:int|void|char|float|double|bool|auto|unsigned|signed|short|long|size_t|std::\w+|\w+::\w+|\w+)\s+(\w+)\s*\([^)]*\)\s*\{\s*(?://.*)?$'
        for i, line in enumerate(lines, 1):
            match = re.search(func_pattern, line)
            if match:
                # ×‘×“×™×§×” ×× ×”×¤×•× ×§×¦×™×” ×¨×™×§×”
                is_empty = True
                for j in range(i+1, min(i+5, len(lines)+1)):
                    if re.search(r'[^\s]', lines[j-1]) and not re.search(r'^\s*(?://|$)', lines[j-1]):
                        is_empty = False
                        break
                    if re.search(r'^\s*}', lines[j-1]):
                        break
                
                if is_empty:
                    func_name = match.group(1)
                    context = self._get_file_context(file_path, i, self.context_lines)
                    
                    missing_parts.append({
                        "type": "empty_function",
                        "name": func_name,
                        "line": i,
                        "message": f"×¤×•× ×§×¦×™×” ×¨×™×§×” {func_name}",
                        "context": context
                    })
        
        # ×—×™×¤×•×© ×”×›×œ×œ×•×ª ×—×¡×¨×•×ª
        included_headers = set()
        
        # ××™×¡×•×£ ×›×•×ª×¨×•×ª ××•×›×œ×œ×•×ª
        include_pattern = r'#\s*include\s+[<"]([^>"]+)[>"]'
        for match in re.finditer(include_pattern, content):
            header = match.group(1)
            included_headers.add(header)
            
            # ×”×•×¡×¤×ª ×’×¨×¡××•×ª ×œ×œ× ×¡×™×•××ª .h
            if header.endswith('.h'):
                included_headers.add(header[:-2])
            
            # ×”×•×¡×¤×ª ×’×¨×¡××•×ª ×¢× .h
            if not header.endswith('.h'):
                included_headers.add(header + '.h')
        
        # ×—×™×¤×•×© ×¤×•× ×§×¦×™×•×ª ××¡×¤×¨×™×•×ª ×¡×˜× ×“×¨×˜×™×•×ª
        library_funcs = {
            "printf": "stdio.h",
            "scanf": "stdio.h",
            "fprintf": "stdio.h",
            "fscanf": "stdio.h",
            "sprintf": "stdio.h",
            "fopen": "stdio.h",
            "fclose": "stdio.h",
            "fread": "stdio.h",
            "fwrite": "stdio.h",
            "malloc": "stdlib.h",
            "free": "stdlib.h",
            "calloc": "stdlib.h",
            "realloc": "stdlib.h",
            "exit": "stdlib.h",
            "rand": "stdlib.h",
            "srand": "stdlib.h",
            "strlen": "string.h",
            "strcpy": "string.h",
            "strcat": "string.h",
            "strcmp": "string.h",
            "memcpy": "string.h",
            "memset": "string.h",
            "isalpha": "ctype.h",
            "isdigit": "ctype.h",
            "isalnum": "ctype.h",
            "tolower": "ctype.h",
            "toupper": "ctype.h",
            "atoi": "stdlib.h",
            "atof": "stdlib.h",
            "abs": "stdlib.h",
            "pow": "math.h",
            "sqrt": "math.h",
            "sin": "math.h",
            "cos": "math.h",
            "tan": "math.h",
            "log": "math.h",
            "exp": "math.h",
            "floor": "math.h",
            "ceil": "math.h",
            "time": "time.h",
            "ctime": "time.h",
            "cout": "iostream",
            "cin": "iostream",
            "cerr": "iostream",
            "endl": "iostream",
            "vector": "vector",
            "map": "map",
            "set": "set",
            "list": "list",
            "string": "string",
            "sort": "algorithm",
            "find": "algorithm",
            "count": "algorithm",
            "min": "algorithm",
            "max": "algorithm"
        }
        
        # ×—×™×¤×•×© ×©×™××•×© ×‘×¤×•× ×§×¦×™×•×ª ××¡×¤×¨×™×•×ª
        func_call_pattern = r'\b(\w+)\s*\('
        missing_includes = {}
        
        for match in re.finditer(func_call_pattern, content):
            func_name = match.group(1)
            if func_name in library_funcs:
                header = library_funcs[func_name]
                if header not in included_headers:
                    missing_includes[func_name] = header
        
        # ×—×™×¤×•×© ×©×™××•×© ×‘××—×œ×§×•×ª ×¡×¤×¨×™×™×” ×¡×˜× ×“×¨×˜×™×ª
        std_classes_pattern = r'\bstd::(\w+)\b'
        for match in re.finditer(std_classes_pattern, content):
            class_name = match.group(1)
            if class_name in library_funcs:
                header = library_funcs[class_name]
                if header not in included_headers:
                    missing_includes[class_name] = header
        
        # ×”×•×¡×¤×ª ×”×›×œ×œ×•×ª ×—×¡×¨×•×ª ×œ×¨×©×™××”
        for func_name, header in missing_includes.items():
            # ×—×™×¤×•×© ×©×•×¨×ª ×”×©×™××•×© ×”×¨××©×•× ×” ×‘×¤×•× ×§×¦×™×”
            pattern = r'\b' + re.escape(func_name) + r'\b'
            for i, line in enumerate(lines, 1):
                if re.search(pattern, line):
                    context = self._get_file_context(file_path, i, self.context_lines)
                    missing_parts.append({
                        "type": "missing_include",
                        "name": header,
                        "line": i,
                        "message": f"×©×™××•×© ×‘×¤×•× ×§×¦×™×” {func_name} ×œ×œ× ×”×›×œ×œ×ª {header}",
                        "context": context
                    })
                    break
        
        return missing_parts
    
    def _get_python_standard_functions(self) -> Set[str]:
        """
        ×§×‘×œ×ª ×¨×©×™××ª ×¤×•× ×§×¦×™×•×ª ×¡×˜× ×“×¨×˜×™×•×ª ×‘-Python
        
        Returns:
            ×¡×˜ ×©×œ ×©××•×ª ×¤×•× ×§×¦×™×•×ª ×¡×˜× ×“×¨×˜×™×•×ª
        """
        standard_functions = {
            "abs", "all", "any", "ascii", "bin", "bool", "breakpoint", "bytearray", "bytes", "callable", "chr",
            "classmethod", "compile", "complex", "delattr", "dict", "dir", "divmod", "enumerate", "eval", "exec",
            "filter", "float", "format", "frozenset", "getattr", "globals", "hasattr", "hash", "help", "hex", "id",
            "input", "int", "isinstance", "issubclass", "iter", "len", "list", "locals", "map", "max", "memoryview",
            "min", "next", "object", "oct", "open", "ord", "pow", "print", "property", "range", "repr", "reversed",
            "round", "set", "setattr", "slice", "sorted", "staticmethod", "str", "sum", "super", "tuple", "type",
            "vars", "zip", "__import__"
        }
        
        return standard_functions
    
    def complete_file(self, file_path: str, context_lines: int = None) -> Dict[str, Any]:
        """
        ×”×©×œ××ª ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥
        
        Args:
            file_path: × ×ª×™×‘ ×”×§×•×‘×¥
            context_lines: ××¡×¤×¨ ×©×•×¨×•×ª ×”×§×©×¨
            
        Returns:
            ××™×œ×•×Ÿ ×¢× ×ª×•×¦××•×ª ×”×”×©×œ××”
        """
        if not self.enabled:
            logger.warning("×”×©×œ××ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×”×©×œ××ª ×§×•×“ ××™× ×” ××•×¤×¢×œ×ª"}
        
        try:
            # ×”×’×“×¨×ª ××¡×¤×¨ ×©×•×¨×•×ª ×”×§×©×¨
            if context_lines is None:
                context_lines = self.context_lines
            
            # ×–×™×”×•×™ ×—×œ×§×™× ×—×¡×¨×™×
            detection_result = self.detect_missing_parts(file_path)
            
            if detection_result["status"] != "success":
                return detection_result
            
            missing_parts = detection_result.get("missing_parts", [])
            
            if not missing_parts:
                logger.info(f"×œ× × ××¦××• ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥ {file_path}")
                return {
                    "status": "success",
                    "file_path": file_path,
                    "message": "×œ× × ××¦××• ×—×œ×§×™× ×—×¡×¨×™× ×‘×§×•×‘×¥",
                    "changes_made": 0,
                    "completed_file": file_path
                }
            
            # ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª
            language = detection_result.get("language")
            
            # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×¢× ×”×©×œ××•×ª
            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(file_path)[1], delete=False) as tmp:
                tmp_path = tmp.name
            
            # ×§×¨×™××ª ×ª×•×›×Ÿ ×”×§×•×‘×¥ ×”××§×•×¨×™
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.splitlines()
            
            # ××™×œ×•×Ÿ ×”×©×™× ×•×™×™× ×©×™×© ×œ×‘×¦×¢
            changes = {}
            
            # ×™×¦×™×¨×ª ×”×¦×¢×•×ª ×œ×ª×™×§×•×Ÿ ×œ×›×œ ×—×œ×§ ×—×¡×¨
            for part in missing_parts:
                part_type = part.get("type")
                line_num = part.get("line", 0)
                
                if part_type == "syntax_error":
                    # ×˜×™×¤×•×œ ×‘×©×’×™××•×ª ×ª×—×‘×™×¨
                    fix = self._fix_syntax_error(part, language)
                    if fix:
                        changes[line_num] = fix
                
                elif part_type == "unbalanced_brackets":
                    # ×˜×™×¤×•×œ ×‘×¡×•×’×¨×™×™× ×œ× ×××•×–× ×™×
                    fix = self._fix_unbalanced_brackets(part, language, lines)
                    if fix:
                        changes[line_num] = fix
                
                elif part_type == "missing_semicolon":
                    # ×˜×™×¤×•×œ ×‘× ×§×•×“×”-×¤×¡×™×§ ×—×¡×¨×”
                    if line_num > 0 and line_num <= len(lines):
                        changes[line_num] = lines[line_num-1] + ";"
                
                elif part_type == "missing_comma":
                    # ×˜×™×¤×•×œ ×‘×¤×¡×™×§ ×—×¡×¨
                    if line_num > 0 and line_num <= len(lines):
                        changes[line_num] = lines[line_num-1] + ","
                
                elif part_type in ["missing_function", "empty_function"]:
                    # ×˜×™×¤×•×œ ×‘×¤×•× ×§×¦×™×•×ª ×—×¡×¨×•×ª ××• ×¨×™×§×•×ª
                    fix = self._create_function_stub(part, language)
                    if fix:
                        changes[line_num] = fix
                
                elif part_type == "missing_import":
                    # ×˜×™×¤×•×œ ×‘×™×™×‘×•× ×—×¡×¨
                    fix = self._create_import_statement(part, language)
                    if fix:
                        # ×”×•×¡×¤×ª ×™×™×‘×•× ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥
                        changes[0] = fix + "\n" + (lines[0] if lines else "")
                
                elif part_type == "missing_include":
                    # ×˜×™×¤×•×œ ×‘×”×›×œ×œ×” ×—×¡×¨×”
                    fix = self._create_include_statement(part)
                    if fix:
                        # ×”×•×¡×¤×ª ×”×›×œ×œ×” ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥
                        changes[0] = fix + "\n" + (lines[0] if lines else "")
            
            # ×™×¦×™×¨×ª ×ª×•×›×Ÿ ××¢×•×“×›×Ÿ
            updated_lines = lines.copy()
            
            # ×‘×™×¦×•×¢ ×”×©×™× ×•×™×™×
            for line_num, new_content in sorted(changes.items(), reverse=True):
                if line_num == 0:
                    # ×”×•×¡×¤×” ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥
                    updated_lines.insert(0, new_content)
                elif line_num <= len(updated_lines):
                    # ×”×—×œ×¤×ª ×©×•×¨×” ×§×™×™××ª
                    updated_lines[line_num-1] = new_content
            
            # ×›×ª×™×‘×ª ×”×ª×•×›×Ÿ ×”××¢×•×“×›×Ÿ ×œ×§×•×‘×¥ ×”×–×× ×™
            with open(tmp_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(updated_lines))
            
            logger.info(f"× ×•×¦×¨ ×§×•×‘×¥ ××•×©×œ× {tmp_path} ×¢× {len(changes)} ×©×™× ×•×™×™×")
            
            return {
                "status": "success",
                "file_path": file_path,
                "completed_file": tmp_path,
                "changes_made": len(changes),
                "changes": changes,
                "missing_parts": missing_parts
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×©×œ××ª ×§×•×‘×¥ {file_path}: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _fix_syntax_error(self, error_info: Dict[str, Any], language: str) -> Optional[str]:
        """
        ×ª×™×§×•×Ÿ ×©×’×™××ª ×ª×—×‘×™×¨
        
        Args:
            error_info: ××™×“×¢ ×¢×œ ×”×©×’×™××”
            language: ×©×¤×ª ×”×ª×›× ×•×ª
            
        Returns:
            ×”×©×•×¨×” ×”××ª×•×§× ×ª ××• None ×× ×œ× × ×™×ª×Ÿ ×œ×ª×§×Ÿ
        """
        if language == "python":
            message = error_info.get("message", "")
            line = error_info.get("context", {}).get("target", "")
            
            # ×ª×™×§×•×Ÿ ×©×’×™××•×ª ×ª×—×‘×™×¨ × ×¤×•×¦×•×ª
            if "EOF while scanning" in message:
                # ×—×¡×¨ ×¡×•×’×¨ ×¡×•×’×¨
                if "string literal" in message or "triple-quoted string" in message:
                    if "'" in line and line.count("'") % 2 == 1:
                        return line + "'"
                    elif '"' in line and line.count('"') % 2 == 1:
                        return line + '"'
            
            elif "unexpected EOF while parsing" in message:
                # ×—×¡×¨ ×¡×•×’×¨ ×¡×•×’×¨
                if line.count('(') > line.count(')'):
                    return line + ')' * (line.count('(') - line.count(')'))
                elif line.count('[') > line.count(']'):
                    return line + ']' * (line.count('[') - line.count(']'))
                elif line.count('{') > line.count('}'):
                    return line + '}' * (line.count('{') - line.count('}'))
            
            elif "invalid syntax" in message:
                # × ×™×¡×™×•×Ÿ ×œ×ª×§×Ÿ ×ª×—×‘×™×¨ ×œ× ×ª×§×™×Ÿ
                if ':' not in line and ('if ' in line or 'for ' in line or 'while ' in line or 'def ' in line or 'class ' in line):
                    return line + ':'
        
        return None
    
    def _fix_unbalanced_brackets(self, error_info: Dict[str, Any], language: str, lines: List[str]) -> Optional[str]:
        """
        ×ª×™×§×•×Ÿ ×¡×•×’×¨×™×™× ×œ× ×××•×–× ×™×
        
        Args:
            error_info: ××™×“×¢ ×¢×œ ×”×©×’×™××”
            language: ×©×¤×ª ×”×ª×›× ×•×ª
            lines: ×›×œ ×©×•×¨×•×ª ×”×§×•×‘×¥
            
        Returns:
            ×”×©×•×¨×” ×”××ª×•×§× ×ª ××• None ×× ×œ× × ×™×ª×Ÿ ×œ×ª×§×Ÿ
        """
        line_num = error_info.get("line", 0)
        message = error_info.get("message", "")
        
        if line_num > 0 and line_num <= len(lines):
            line = lines[line_num-1]
            
            if "×¡×•×’×¨ ×¤×•×ª×—" in message:
                # ×—×¡×¨ ×¡×•×’×¨ ×¡×•×’×¨
                if '(' in message:
                    return line + ')'
                elif '[' in message:
                    return line + ']'
                elif '{' in message:
                    return line + '}'
            
            elif "×¡×•×’×¨" in message and "×œ×œ× ×¤×•×ª×—" in message:
                # ×™×© ×¡×•×’×¨ ×¡×•×’×¨ ××™×•×ª×¨
                if ')' in message:
                    return line.replace(')', '', 1)
                elif ']' in message:
                    return line.replace(']', '', 1)
                elif '}' in message:
                    return line.replace('}', '', 1)
        
        return None
    
    def _create_function_stub(self, func_info: Dict[str, Any], language: str) -> Optional[str]:
        """
        ×™×¦×™×¨×ª ×©×œ×“ ×œ×¤×•× ×§×¦×™×” ×—×¡×¨×”
        
        Args:
            func_info: ××™×“×¢ ×¢×œ ×”×¤×•× ×§×¦×™×”
            language: ×©×¤×ª ×”×ª×›× ×•×ª
            
        Returns:
            ×©×œ×“ ×”×¤×•× ×§×¦×™×” ××• None ×× ×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨
        """
        func_name = func_info.get("name", "unknown")
        line = func_info.get("context", {}).get("target", "")
        
        if language == "python":
            if "empty_function" in func_info.get("type", ""):
                # ×¤×•× ×§×¦×™×” ×¨×™×§×” - ×”×•×¡×¤×ª ×”×¢×¨×” ×•×¢×¨×š ×”×—×–×¨×”
                if "return" not in line and "pass" in line:
                    return line.replace("pass", "# TODO: Implement function\n    pass\n    return None")
                return line + "\n    # TODO: Implement function\n    return None"
            else:
                # ×™×¦×™×¨×ª ×¤×•× ×§×¦×™×” ×—×“×©×”
                params = func_info.get("params", "")
                return f"def {func_name}({params}):\n    # TODO: Implement function\n    pass"
        
        elif language in ["javascript", "typescript"]:
            if "empty_function" in func_info.get("type", ""):
                # ×¤×•× ×§×¦×™×” ×¨×™×§×” - ×”×•×¡×¤×ª ×”×¢×¨×” ×•×¢×¨×š ×”×—×–×¨×”
                if "return" not in line:
                    return line + "\n  // TODO: Implement function\n  return null;"
                return line + "\n  // TODO: Implement function"
            else:
                # ×™×¦×™×¨×ª ×¤×•× ×§×¦×™×” ×—×“×©×”
                return f"function {func_name}() {{\n  // TODO: Implement function\n  return null;\n}}"
        
        elif language == "java":
            if "empty_function" in func_info.get("type", ""):
                # ××ª×•×“×” ×¨×™×§×” - ×”×•×¡×¤×ª ×”×¢×¨×” ×•×¢×¨×š ×”×—×–×¨×”
                if "return" not in line:
                    return line + "\n    // TODO: Implement method\n    return null;"
                return line + "\n    // TODO: Implement method"
            else:
                # ×™×¦×™×¨×ª ××ª×•×“×” ×—×“×©×”
                return f"public Object {func_name}() {{\n    // TODO: Implement method\n    return null;\n}}"
        
        elif language in ["c", "cpp"]:
            if "empty_function" in func_info.get("type", ""):
                # ×¤×•× ×§×¦×™×” ×¨×™×§×” - ×”×•×¡×¤×ª ×”×¢×¨×” ×•×¢×¨×š ×”×—×–×¨×”
                if "return" not in line:
                    return line + "\n    // TODO: Implement function\n    return 0;"
                return line + "\n    // TODO: Implement function"
            else:
                # ×™×¦×™×¨×ª ×¤×•× ×§×¦×™×” ×—×“×©×”
                return f"int {func_name}() {{\n    // TODO: Implement function\n    return 0;\n}}"
        
        return None
    
    def _create_import_statement(self, import_info: Dict[str, Any], language: str) -> Optional[str]:
        """
        ×™×¦×™×¨×ª ×”×¦×”×¨×ª ×™×™×‘×•× ×—×¡×¨×”
        
        Args:
            import_info: ××™×“×¢ ×¢×œ ×”×™×™×‘×•×
            language: ×©×¤×ª ×”×ª×›× ×•×ª
            
        Returns:
            ×”×¦×”×¨×ª ×”×™×™×‘×•× ××• None ×× ×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨
        """
        module_name = import_info.get("name", "")
        
        if not module_name:
            return None
        
        if language == "python":
            return f"import {module_name}"
        
        elif language in ["javascript", "typescript"]:
            # × ×™×¡×™×•×Ÿ ×œ×–×”×•×ª ×× ×–×” ×™×™×‘×•× ×©×œ ××•×“×•×œ ×—×™×¦×•× ×™ ××• ×§×•×‘×¥ ××§×•××™
            if module_name[0].islower():  # ××•×¡×›××” ×©××•×ª ×œ××•×“×•×œ×™× ×—×™×¦×•× ×™×™×
                return f"import * as {module_name} from '{module_name}';"
            else:
                return f"import {{ {module_name} }} from './{module_name}';"
        
        elif language == "java":
            # × ×™×—×•×© ×—×‘×™×œ×” × ×¤×•×¦×”
            if module_name in ["List", "ArrayList", "Map", "HashMap", "Set", "HashSet"]:
                return f"import java.util.{module_name};"
            elif module_name in ["File", "FileReader", "FileWriter", "IOException"]:
                return f"import java.io.{module_name};"
            else:
                return f"import {module_name};"
        
        return None
    
    def _create_include_statement(self, include_info: Dict[str, Any]) -> Optional[str]:
        """
        ×™×¦×™×¨×ª ×”×¦×”×¨×ª ×”×›×œ×œ×” ×—×¡×¨×” ×¢×‘×•×¨ C/C++
        
        Args:
            include_info: ××™×“×¢ ×¢×œ ×”×”×›×œ×œ×”
            
        Returns:
            ×”×¦×”×¨×ª ×”×”×›×œ×œ×” ××• None ×× ×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨
        """
        header_name = include_info.get("name", "")
        
        if not header_name:
            return None
        
        # ×‘×“×™×§×” ×× ×–×” ×›×•×ª×¨ ×©×œ ×¡×¤×¨×™×™×” ×¡×˜× ×“×¨×˜×™×ª ××• ×›×•×ª×¨ ××§×•××™
        if header_name in ["stdio.h", "stdlib.h", "string.h", "math.h", "ctype.h", "time.h", "iostream", "vector", "string", "algorithm", "map", "set", "list"]:
            # ×›×•×ª×¨ ×©×œ ×¡×¤×¨×™×™×” ×¡×˜× ×“×¨×˜×™×ª
            if header_name in ["iostream", "vector", "string", "algorithm", "map", "set", "list"]:
                return f"#include <{header_name}>"
            else:
                return f"#include <{header_name}>"
        else:
            # ×›×•×ª×¨ ××§×•××™
            return f'#include "{header_name}"'
CODE_COMPLETER_PY

# ×™×¦×™×¨×ª ××•×“×•×œ ×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§
echo "ğŸ“ ×™×•×¦×¨ ××•×“×•×œ ××—×¡×•×Ÿ ××¨×•×—×§..."
cat > "$BASE_DIR/utils/remote_storage.py" << 'REMOTE_STORAGE_PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
××•×“×•×œ ×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0
×××¤×©×¨ ×’×™×©×” ×œ××¢×¨×›×•×ª ×§×‘×¦×™× ××¨×•×—×§×•×ª

××—×‘×¨: Claude AI
×’×¨×¡×”: 1.0.0
×ª××¨×™×š: ×××™ 2025
"""

import os
import re
import sys
import json
import uuid
import time
import shutil
import logging
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional, Union, Set

# ×”×’×“×¨×ª ×œ×•×’×™×
logger = logging.getLogger(__name__)

class RemoteStorageManager:
    """
    ×× ×”×œ ×’×™×©×” ×œ××¢×¨×›×•×ª ×§×‘×¦×™× ××¨×•×—×§×•×ª
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        ××ª×—×•×œ ×× ×”×œ ×”××—×¡×•×Ÿ ×”××¨×•×—×§
        
        Args:
            config: ××™×œ×•×Ÿ ×”×’×“×¨×•×ª ×ª×¦×•×¨×”
        """
        self.config = config
        self.enabled = config.get("enabled", True)
        self.storage_types = config.get("types", ["local", "ssh", "s3", "ftp", "webdav", "smb", "nfs"])
        self.timeout_seconds = config.get("timeout_seconds", 30)
        self.cache_enabled = config.get("cache_enabled", True)
        self.cache_expiry_seconds = config.get("cache_expiry_seconds", 3600)
        
        # ×ª×™×§×™×™×ª ××˜××•×Ÿ
        self.cache_dir = config.get("cache_dir", "remote_cache")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # ××™×œ×•×Ÿ ×—×™×‘×•×¨×™× ×¤×¢×™×œ×™×
        self.active_connections = {}
        
        logger.info(f"×× ×”×œ ××—×¡×•×Ÿ ××¨×•×—×§ ××•×ª×—×œ ×¢× ×”×’×“×¨×•×ª: storage_types={self.storage_types}, "
                   f"timeout={self.timeout_seconds}s, cache_enabled={self.cache_enabled}")
        
        # ×‘×“×™×§×ª ×ª×œ×•×™×•×ª
        self._check_dependencies()
    
    def _check_dependencies(self) -> None:
        """
        ×‘×“×™×§×ª ×ª×œ×•×™×•×ª × ×“×¨×©×•×ª ×œ×¡×•×’×™ ×”××—×¡×•×Ÿ ×”×©×•× ×™×
        """
        missing_deps = {}
        
        if "ssh" in self.storage_types:
            try:
                import paramiko
            except ImportError:
                missing_deps["ssh"] = "paramiko"
        
        if "s3" in self.storage_types:
            try:
                import boto3
            except ImportError:
                missing_deps["s3"] = "boto3"
        
        if "webdav" in self.storage_types:
            try:
                import webdav3.client
            except ImportError:
                missing_deps["webdav"] = "webdav3.client"
        
        if "smb" in self.storage_types:
            try:
                import pysmb
            except ImportError:
                missing_deps["smb"] = "pysmb"
        
        if missing_deps:
            deps_str = ", ".join([f"{dep} ({pkg})" for dep, pkg in missing_deps.items()])
            logger.warning(f"×—×¡×¨×•×ª ×ª×œ×•×™×•×ª ×œ×¡×•×’×™ ××—×¡×•×Ÿ: {deps_str}")
            logger.warning("×”×ª×§×Ÿ ××ª ×”×ª×œ×•×™×•×ª ×”×—×¡×¨×•×ª ×¢×: pip install " + " ".join(missing_deps.values()))
    
    def connect(self, storage_type: str, connection_params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××¢×¨×›×ª ××—×¡×•×Ÿ ××¨×•×—×§×ª
        
        Args:
            storage_type: ×¡×•×’ ×”××—×¡×•×Ÿ
            connection_params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        if not self.enabled:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª"}
        
        if storage_type not in self.storage_types:
            logger.error(f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š")
            return {"status": "error", "error": f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š"}
        
        try:
            logger.info(f"××ª×—×‘×¨ ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××¡×•×’ {storage_type}")
            
            # ×™×¦×™×¨×ª ××–×”×” ×—×™×‘×•×¨
            connection_id = f"{storage_type}_{uuid.uuid4().hex[:8]}"
            
            # ×‘×—×™×¨×ª ×¤×•× ×§×¦×™×™×ª ×”×ª×—×‘×¨×•×ª ××ª××™××”
            if storage_type == "local":
                connection = self._connect_local(connection_id, connection_params)
            elif storage_type == "ssh":
                connection = self._connect_ssh(connection_id, connection_params)
            elif storage_type == "s3":
                connection = self._connect_s3(connection_id, connection_params)
            elif storage_type == "ftp":
                connection = self._connect_ftp(connection_id, connection_params)
            elif storage_type == "webdav":
                connection = self._connect_webdav(connection_id, connection_params)
            elif storage_type == "smb":
                connection = self._connect_smb(connection_id, connection_params)
            elif storage_type == "nfs":
                connection = self._connect_nfs(connection_id, connection_params)
            else:
                return {"status": "error", "error": f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š"}
            
            # ×‘×“×™×§×ª ×”×¦×œ×—×ª ×”×—×™×‘×•×¨
            if connection.get("status") != "success":
                return connection
            
            # ×©××™×¨×ª ×”×—×™×‘×•×¨
            self.active_connections[connection_id] = {
                "type": storage_type,
                "params": connection_params,
                "connection": connection.get("connection"),
                "client": connection.get("client"),
                "created_at": time.time()
            }
            
            logger.info(f"×—×™×‘×•×¨ ×œ××—×¡×•×Ÿ ××¨×•×—×§ {connection_id} × ×•×¦×¨ ×‘×”×¦×œ×—×”")
            
            # ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨ (×œ×œ× ××•×‘×™×™×§×˜ ×”×—×™×‘×•×¨)
            result = {
                "status": "success",
                "connection_id": connection_id,
                "type": storage_type,
                "description": connection.get("description", ""),
                "base_path": connection_params.get("base_path", "/")
            }
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ ××¨×•×—×§: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _connect_local(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ ××§×•××™
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        base_path = params.get("base_path", ".")
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ ×§×™×™×
        if not os.path.exists(base_path):
            logger.error(f"× ×ª×™×‘ ×‘×¡×™×¡ {base_path} ××™× ×• ×§×™×™×")
            return {"status": "error", "error": f"× ×ª×™×‘ ×‘×¡×™×¡ {base_path} ××™× ×• ×§×™×™×"}
        
        # ×©××™×¨×ª ×”× ×ª×™×‘ ×›××•×‘×™×™×§×˜ ×—×™×‘×•×¨
        connection = {"base_path": os.path.abspath(base_path)}
        
        return {
            "status": "success",
            "connection_id": connection_id,
            "connection": connection,
            "client": None,
            "description": f"××—×¡×•×Ÿ ××§×•××™: {base_path}"
        }
    
    def _connect_ssh(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ SSH
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        try:
            import paramiko
        except ImportError:
            logger.error("×œ× × ×™×ª×Ÿ ×œ×™×™×‘× ××ª paramiko - ×”×ª×§×Ÿ ×¢× pip install paramiko")
            return {"status": "error", "error": "×—×¡×¨×” ×ª×œ×•×ª paramiko"}
        
        host = params.get("host", "")
        port = params.get("port", 22)
        username = params.get("username", "")
        password = params.get("password", "")
        key_file = params.get("key_file", "")
        base_path = params.get("base_path", "/")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not host:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'host'"}
        if not username:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'username'"}
        if not password and not key_file:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'password' ××• 'key_file'"}
        
        try:
            # ×™×¦×™×¨×ª ×—×™×‘×•×¨ SSH
            ssh_client = paramiko.SSHClient()
            ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
            
            # ×”×ª×—×‘×¨×•×ª ×¢× ×¡×™×¡××” ××• ×§×•×‘×¥ ××¤×ª×—
            if key_file:
                key = paramiko.RSAKey.from_private_key_file(key_file)
                ssh_client.connect(hostname=host, port=port, username=username, pkey=key, timeout=self.timeout_seconds)
            else:
                ssh_client.connect(hostname=host, port=port, username=username, password=password, timeout=self.timeout_seconds)
            
            # ×™×¦×™×¨×ª ×œ×§×•×— SFTP
            sftp_client = ssh_client.open_sftp()
            
            # ×‘×“×™×§×” ×©× ×ª×™×‘ ×”×‘×¡×™×¡ ×§×™×™×
            try:
                sftp_client.stat(base_path)
            except FileNotFoundError:
                ssh_client.close()
                return {"status": "error", "error": f"× ×ª×™×‘ ×‘×¡×™×¡ {base_path} ××™× ×• ×§×™×™×"}
            
            connection = {
                "host": host,
                "port": port,
                "username": username,
                "base_path": base_path
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": {"ssh": ssh_client, "sftp": sftp_client},
                "description": f"SSH: {username}@{host}:{port}{base_path}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-SSH: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-SSH: {str(e)}"}
    
    def _connect_s3(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ S3
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        try:
            import boto3
        except ImportError:
            logger.error("×œ× × ×™×ª×Ÿ ×œ×™×™×‘× ××ª boto3 - ×”×ª×§×Ÿ ×¢× pip install boto3")
            return {"status": "error", "error": "×—×¡×¨×” ×ª×œ×•×ª boto3"}
        
        region = params.get("region", "us-east-1")
        access_key = params.get("access_key", "")
        secret_key = params.get("secret_key", "")
        bucket = params.get("bucket", "")
        base_path = params.get("base_path", "")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not bucket:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'bucket'"}
        
        try:
            # ×™×¦×™×¨×ª ×œ×§×•×— S3
            if access_key and secret_key:
                s3_client = boto3.client(
                    's3',
                    region_name=region,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key
                )
            else:
                # ×©×™××•×© ×‘×¤×¨×•×¤×™×œ ×‘×¨×™×¨×ª ××—×“×œ
                s3_client = boto3.client('s3', region_name=region)
            
            # ×‘×“×™×§×” ×©×”×“×œ×™ ×§×™×™×
            try:
                s3_client.head_bucket(Bucket=bucket)
            except Exception as e:
                return {"status": "error", "error": f"×©×’×™××” ×‘×’×™×©×” ×œ×“×œ×™ {bucket}: {str(e)}"}
            
            connection = {
                "region": region,
                "bucket": bucket,
                "base_path": base_path
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": s3_client,
                "description": f"S3: {bucket}/{base_path}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-S3: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-S3: {str(e)}"}
    
    def _connect_ftp(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ FTP
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        try:
            from ftplib import FTP
        except ImportError:
            logger.error("×œ× × ×™×ª×Ÿ ×œ×™×™×‘× ××ª ftplib")
            return {"status": "error", "error": "×—×¡×¨×” ×ª×œ×•×ª ftplib"}
        
        host = params.get("host", "")
        port = params.get("port", 21)
        username = params.get("username", "")
        password = params.get("password", "")
        base_path = params.get("base_path", "/")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not host:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'host'"}
        
        try:
            # ×™×¦×™×¨×ª ×—×™×‘×•×¨ FTP
            ftp_client = FTP()
            ftp_client.connect(host, port, self.timeout_seconds)
            
            # ×”×ª×—×‘×¨×•×ª
            if username and password:
                ftp_client.login(username, password)
            else:
                ftp_client.login()
            
            # ××¢×‘×¨ ×œ× ×ª×™×‘ ×”×‘×¡×™×¡
            if base_path and base_path != "/":
                ftp_client.cwd(base_path)
            
            connection = {
                "host": host,
                "port": port,
                "username": username,
                "base_path": base_path
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": ftp_client,
                "description": f"FTP: {username}@{host}:{port}{base_path}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-FTP: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-FTP: {str(e)}"}
    
    def _connect_webdav(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ WebDAV
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        try:
            from webdav3.client import Client
        except ImportError:
            logger.error("×œ× × ×™×ª×Ÿ ×œ×™×™×‘× ××ª webdav3.client - ×”×ª×§×Ÿ ×¢× pip install webdav3.client")
            return {"status": "error", "error": "×—×¡×¨×” ×ª×œ×•×ª webdav3.client"}
        
        host = params.get("host", "")
        username = params.get("username", "")
        password = params.get("password", "")
        base_path = params.get("base_path", "/")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not host:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'host'"}
        
        try:
            # ×™×¦×™×¨×ª ×œ×§×•×— WebDAV
            options = {
                'webdav_hostname': host,
                'webdav_login': username,
                'webdav_password': password,
                'webdav_root': base_path
            }
            webdav_client = Client(options)
            
            # ×‘×“×™×§×ª ×—×™×‘×•×¨
            webdav_client.check()
            
            connection = {
                "host": host,
                "username": username,
                "base_path": base_path
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": webdav_client,
                "description": f"WebDAV: {username}@{host}{base_path}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-WebDAV: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-WebDAV: {str(e)}"}
    
    def _connect_smb(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ SMB
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        try:
            from smb.SMBConnection import SMBConnection
        except ImportError:
            logger.error("×œ× × ×™×ª×Ÿ ×œ×™×™×‘× ××ª pysmb - ×”×ª×§×Ÿ ×¢× pip install pysmb")
            return {"status": "error", "error": "×—×¡×¨×” ×ª×œ×•×ª pysmb"}
        
        host = params.get("host", "")
        port = params.get("port", 445)
        username = params.get("username", "")
        password = params.get("password", "")
        share = params.get("share", "")
        domain = params.get("domain", "")
        client_name = params.get("client_name", "SmartCodeMerger")
        server_name = params.get("server_name", "")
        base_path = params.get("base_path", "/")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not host:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'host'"}
        if not share:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'share'"}
        if not server_name:
            server_name = host.split('.')[0].upper()
        
        try:
            # ×™×¦×™×¨×ª ×—×™×‘×•×¨ SMB
            smb_client = SMBConnection(
                username=username,
                password=password,
                my_name=client_name,
                remote_name=server_name,
                domain=domain,
                use_ntlm_v2=True
            )
            
            # ×”×ª×—×‘×¨×•×ª
            connected = smb_client.connect(host, port)
            
            if not connected:
                return {"status": "error", "error": f"×œ× × ×™×ª×Ÿ ×œ×”×ª×—×‘×¨ ×œ-SMB: {host}:{port}"}
            
            # ×‘×“×™×§×” ×©×”×©×™×ª×•×£ ×§×™×™×
            shares = smb_client.listShares()
            share_names = [s.name for s in shares]
            
            if share not in share_names:
                smb_client.close()
                return {"status": "error", "error": f"×©×™×ª×•×£ {share} ×œ× × ××¦×"}
            
            connection = {
                "host": host,
                "port": port,
                "username": username,
                "share": share,
                "base_path": base_path
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": smb_client,
                "description": f"SMB: {username}@{host}:{port}/{share}{base_path}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-SMB: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-SMB: {str(e)}"}
    
    def _connect_nfs(self, connection_id: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        ×”×ª×—×‘×¨×•×ª ×œ××—×¡×•×Ÿ NFS
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            params: ×¤×¨××˜×¨×™ ×”×—×™×‘×•×¨
            
        Returns:
            ××™×“×¢ ×¢×œ ×”×—×™×‘×•×¨
        """
        # ×‘×“×™×§×” ×©×”××¢×¨×›×ª ×”×™× Linux
        if sys.platform != "linux":
            logger.error("×—×™×‘×•×¨ NFS × ×ª××š ×¨×§ ×‘-Linux")
            return {"status": "error", "error": "×—×™×‘×•×¨ NFS × ×ª××š ×¨×§ ×‘-Linux"}
        
        host = params.get("host", "")
        path = params.get("path", "")
        mount_point = params.get("mount_point", "")
        options = params.get("options", "")
        
        # ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
        if not host:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'host'"}
        if not path:
            return {"status": "error", "error": "×—×¡×¨ ×¤×¨××˜×¨ 'path'"}
        
        # × ×ª×™×‘ ×œ×¢×™×’×•×Ÿ
        if not mount_point:
            mount_point = os.path.join(self.cache_dir, f"nfs_{uuid.uuid4().hex[:8]}")
        
        # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×œ×¢×™×’×•×Ÿ
        os.makedirs(mount_point, exist_ok=True)
        
        try:
            # ×¢×™×’×•×Ÿ ×”-NFS
            mount_cmd = ["mount", "-t", "nfs"]
            
            # ×”×•×¡×¤×ª ××¤×©×¨×•×™×•×ª ×× ×™×©
            if options:
                mount_cmd.extend(["-o", options])
            
            # ×”×•×¡×¤×ª ××§×•×¨ ×•×™×¢×“
            mount_cmd.append(f"{host}:{path}")
            mount_cmd.append(mount_point)
            
            # ×‘×™×¦×•×¢ ×”×¤×§×•×“×”
            import subprocess
            result = subprocess.run(mount_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            if result.returncode != 0:
                error = result.stderr.decode('utf-8', errors='ignore')
                return {"status": "error", "error": f"×©×’×™××” ×‘×¢×™×’×•×Ÿ NFS: {error}"}
            
            connection = {
                "host": host,
                "path": path,
                "mount_point": mount_point,
                "options": options
            }
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "connection": connection,
                "client": None,
                "description": f"NFS: {host}:{path} -> {mount_point}"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-NFS: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-NFS: {str(e)}"}
    
    def disconnect(self, connection_id: str) -> Dict[str, Any]:
        """
        × ×™×ª×•×§ ×××—×¡×•×Ÿ ××¨×•×—×§
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            
        Returns:
            ×ª×•×¦××ª ×”× ×™×ª×•×§
        """
        if not self.enabled:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª"}
        
        if connection_id not in self.active_connections:
            logger.warning(f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×")
            return {"status": "error", "error": f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×"}
        
        try:
            # ×©×œ×™×¤×ª × ×ª×•× ×™ ×”×—×™×‘×•×¨
            connection_info = self.active_connections[connection_id]
            storage_type = connection_info["type"]
            client = connection_info["client"]
            
            # × ×™×ª×•×§ ×”×—×™×‘×•×¨ ×œ×¤×™ ×¡×•×’
            if storage_type == "ssh":
                try:
                    client["sftp"].close()
                    client["ssh"].close()
                except:
                    pass
            
            elif storage_type == "ftp":
                try:
                    client.quit()
                except:
                    pass
            
            elif storage_type == "smb":
                try:
                    client.close()
                except:
                    pass
            
            elif storage_type == "nfs":
                # × ×™×ª×•×§ NFS
                mount_point = connection_info["connection"]["mount_point"]
                
                try:
                    import subprocess
                    subprocess.run(["umount", mount_point], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                    
                    # × ×™×¡×™×•×Ÿ ×œ××—×•×§ ××ª ×ª×™×§×™×™×ª ×”×¢×™×’×•×Ÿ
                    try:
                        os.rmdir(mount_point)
                    except:
                        pass
                except:
                    pass
            
            # ×”×¡×¨×ª ×”×—×™×‘×•×¨ ××”××™×œ×•×Ÿ
            del self.active_connections[connection_id]
            
            logger.info(f"×—×™×‘×•×¨ {connection_id} × ×•×ª×§ ×‘×”×¦×œ×—×”")
            
            return {
                "status": "success",
                "connection_id": connection_id,
                "message": f"×—×™×‘×•×¨ {connection_id} × ×•×ª×§ ×‘×”×¦×œ×—×”"
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘× ×™×ª×•×§ ×—×™×‘×•×¨ {connection_id}: {str(e)}")
            return {"status": "error", "error": f"×©×’×™××” ×‘× ×™×ª×•×§ ×—×™×‘×•×¨: {str(e)}"}
    
    def list_remote_files(self, remote_path: str, connection_id: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× ×‘××—×¡×•×Ÿ ××¨×•×—×§
        
        Args:
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        if not self.enabled:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª"}
        
        if connection_id not in self.active_connections:
            logger.warning(f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×")
            return {"status": "error", "error": f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×"}
        
        try:
            # ×©×œ×™×¤×ª × ×ª×•× ×™ ×”×—×™×‘×•×¨
            connection_info = self.active_connections[connection_id]
            storage_type = connection_info["type"]
            connection = connection_info["connection"]
            client = connection_info["client"]
            
            # ×‘×“×™×§×ª ×”××˜××•×Ÿ
            cache_key = f"{connection_id}_{remote_path}"
            cache_result = self._get_from_cache(cache_key)
            
            if cache_result:
                logger.info(f"× ××¦× ×‘××˜××•×Ÿ: {cache_key}")
                return cache_result
            
            # ×¨×©×™××ª ×§×‘×¦×™× ×œ×¤×™ ×¡×•×’ ××—×¡×•×Ÿ
            if storage_type == "local":
                result = self._list_local_files(connection, remote_path)
            elif storage_type == "ssh":
                result = self._list_ssh_files(connection, client, remote_path)
            elif storage_type == "s3":
                result = self._list_s3_files(connection, client, remote_path)
            elif storage_type == "ftp":
                result = self._list_ftp_files(connection, client, remote_path)
            elif storage_type == "webdav":
                result = self._list_webdav_files(connection, client, remote_path)
            elif storage_type == "smb":
                result = self._list_smb_files(connection, client, remote_path)
            elif storage_type == "nfs":
                result = self._list_nfs_files(connection, remote_path)
            else:
                return {"status": "error", "error": f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š"}
            
            # ×©××™×¨×” ×‘××˜××•×Ÿ
            if result["status"] == "success" and self.cache_enabled:
                self._save_to_cache(cache_key, result)
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™× ××¨×•×—×§×™×: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_local_files(self, connection: Dict[str, Any], remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× ××§×•××™×™×
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        base_path = connection["base_path"]
        full_path = os.path.normpath(os.path.join(base_path, remote_path.lstrip("/")))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×ª×™×‘ ×”×‘×¡×™×¡
        if not full_path.startswith(base_path):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ ×§×™×™×
        if not os.path.exists(full_path):
            return {"status": "error", "error": f"× ×ª×™×‘ {remote_path} ×œ× × ××¦×"}
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ ×”×•× ×ª×™×§×™×™×”
        if not os.path.isdir(full_path):
            return {"status": "error", "error": f"× ×ª×™×‘ {remote_path} ××™× ×• ×ª×™×§×™×™×”"}
        
        # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        files = []
        directories = []
        
        for item in os.listdir(full_path):
            item_path = os.path.join(full_path, item)
            
            if os.path.isdir(item_path):
                directories.append({
                    "name": item,
                    "path": os.path.join(remote_path, item).replace("\\", "/"),
                    "type": "directory"
                })
            else:
                files.append({
                    "name": item,
                    "path": os.path.join(remote_path, item).replace("\\", "/"),
                    "type": "file",
                    "size": os.path.getsize(item_path),
                    "modified": datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).isoformat()
                })
        
        return {
            "status": "success",
            "path": remote_path,
            "files": files,
            "directories": directories
        }
    
    def _list_ssh_files(self, connection: Dict[str, Any], client: Dict[str, Any], remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× SSH
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SSH
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        sftp_client = client["sftp"]
        base_path = connection["base_path"]
        full_path = os.path.normpath(os.path.join(base_path, remote_path.lstrip("/")))
        
        try:
            # ×¨×©×™××ª ×§×‘×¦×™×
            items = sftp_client.listdir_attr(full_path)
            
            files = []
            directories = []
            
            import stat
            
            for item in items:
                is_dir = stat.S_ISDIR(item.st_mode)
                
                if is_dir:
                    directories.append({
                        "name": item.filename,
                        "path": os.path.join(remote_path, item.filename).replace("\\", "/"),
                        "type": "directory"
                    })
                else:
                    files.append({
                        "name": item.filename,
                        "path": os.path.join(remote_path, item.filename).replace("\\", "/"),
                        "type": "file",
                        "size": item.st_size,
                        "modified": datetime.datetime.fromtimestamp(item.st_mtime).isoformat()
                    })
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ SSH: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_s3_files(self, connection: Dict[str, Any], client: Any, remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× S3
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— S3
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        bucket = connection["bucket"]
        base_path = connection["base_path"]
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ××œ×
        prefix = os.path.join(base_path, remote_path.lstrip("/")).replace("\\", "/")
        prefix = prefix.strip("/")
        if prefix:
            prefix += "/"
        
        try:
            # ×¨×©×™××ª ××•×‘×™×™×§×˜×™×
            response = client.list_objects_v2(
                Bucket=bucket,
                Prefix=prefix,
                Delimiter="/"
            )
            
            files = []
            directories = []
            
            # ×ª×™×§×™×•×ª (prefixes)
            if "CommonPrefixes" in response:
                for prefix_obj in response["CommonPrefixes"]:
                    prefix_path = prefix_obj["Prefix"]
                    prefix_name = os.path.basename(prefix_path.rstrip("/"))
                    
                    directories.append({
                        "name": prefix_name,
                        "path": os.path.join(remote_path, prefix_name).replace("\\", "/"),
                        "type": "directory"
                    })
            
            # ×§×‘×¦×™×
            if "Contents" in response:
                for obj in response["Contents"]:
                    if obj["Key"] == prefix:
                        continue  # ×“×™×œ×•×’ ×¢×œ ×”×§×™×“×•××ª ×¢×¦××”
                    
                    obj_path = obj["Key"]
                    obj_name = os.path.basename(obj_path)
                    
                    files.append({
                        "name": obj_name,
                        "path": os.path.join(remote_path, obj_name).replace("\\", "/"),
                        "type": "file",
                        "size": obj["Size"],
                        "modified": obj["LastModified"].isoformat() if hasattr(obj["LastModified"], "isoformat") else str(obj["LastModified"])
                    })
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ S3: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_ftp_files(self, connection: Dict[str, Any], client: Any, remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× FTP
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— FTP
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        base_path = connection["base_path"]
        current_dir = client.pwd()
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ××œ×
        full_path = os.path.normpath(os.path.join(base_path, remote_path.lstrip("/")))
        
        try:
            # ××¢×‘×¨ ×œ×ª×™×§×™×™×” ×”××‘×•×§×©×ª
            client.cwd(full_path)
            
            # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
            items = []
            client.dir(lambda line: items.append(line))
            
            files = []
            directories = []
            
            for item in items:
                parts = item.split()
                if len(parts) < 9:
                    continue
                
                # ×”×¤×¨×“×ª ×”××™×“×¢
                permissions = parts[0]
                size = parts[4]
                month = parts[5]
                day = parts[6]
                year_or_time = parts[7]
                name = " ".join(parts[8:])
                
                # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
                is_dir = permissions.startswith("d")
                
                if is_dir:
                    directories.append({
                        "name": name,
                        "path": os.path.join(remote_path, name).replace("\\", "/"),
                        "type": "directory"
                    })
                else:
                    files.append({
                        "name": name,
                        "path": os.path.join(remote_path, name).replace("\\", "/"),
                        "type": "file",
                        "size": int(size)
                    })
            
            # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            client.cwd(current_dir)
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            # × ×™×¡×™×•×Ÿ ×œ×—×–×•×¨ ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            try:
                client.cwd(current_dir)
            except:
                pass
            
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ FTP: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_webdav_files(self, connection: Dict[str, Any], client: Any, remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× WebDAV
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— WebDAV
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        try:
            full_path = remote_path.lstrip("/")
            if not full_path:
                full_path = "/"
            
            # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
            items = client.list(full_path)
            
            files = []
            directories = []
            
            for name, info in items.items():
                if name == full_path or name == ".":
                    continue
                
                is_dir = info.get("isdir", False)
                base_name = os.path.basename(name.rstrip("/"))
                
                if is_dir:
                    directories.append({
                        "name": base_name,
                        "path": os.path.join(remote_path, base_name).replace("\\", "/"),
                        "type": "directory"
                    })
                else:
                    files.append({
                        "name": base_name,
                        "path": os.path.join(remote_path, base_name).replace("\\", "/"),
                        "type": "file",
                        "size": info.get("size", 0),
                        "modified": info.get("modified", "")
                    })
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ WebDAV: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_smb_files(self, connection: Dict[str, Any], client: Any, remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× SMB
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SMB
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        share = connection["share"]
        base_path = connection["base_path"].lstrip("/").replace("/", "\\")
        remote_path = remote_path.lstrip("/").replace("/", "\\")
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ××œ×
        full_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        try:
            # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
            items = client.listPath(share, full_path)
            
            files = []
            directories = []
            
            for item in items:
                if item.filename in [".", ".."]:
                    continue
                
                # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
                is_dir = (item.isDirectory or item.isDirectory())
                
                if is_dir:
                    directories.append({
                        "name": item.filename,
                        "path": os.path.join(remote_path, item.filename).replace("\\", "/"),
                        "type": "directory"
                    })
                else:
                    files.append({
                        "name": item.filename,
                        "path": os.path.join(remote_path, item.filename).replace("\\", "/"),
                        "type": "file",
                        "size": item.file_size,
                        "modified": datetime.datetime.fromtimestamp(item.last_write_time).isoformat()
                    })
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            # ×¡×’×™×¨×ª ×”×—×™×‘×•×¨ ×‘××§×¨×” ×©×œ ×©×’×™××”
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ SMB: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _list_nfs_files(self, connection: Dict[str, Any], remote_path: str) -> Dict[str, Any]:
        """
        ×¨×©×™××ª ×§×‘×¦×™× NFS
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
        """
        mount_point = connection["mount_point"]
        remote_path = remote_path.lstrip("/")
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ××œ×
        full_path = os.path.normpath(os.path.join(mount_point, remote_path))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×§×•×“×ª ×”×¢×™×’×•×Ÿ
        if not full_path.startswith(mount_point):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        try:
            # ×‘×“×™×§×” ×©×”× ×ª×™×‘ ×§×™×™×
            if not os.path.exists(full_path):
                return {"status": "error", "error": f"× ×ª×™×‘ {remote_path} ×œ× × ××¦×"}
            
            # ×‘×“×™×§×” ×©×”× ×ª×™×‘ ×”×•× ×ª×™×§×™×™×”
            if not os.path.isdir(full_path):
                return {"status": "error", "error": f"× ×ª×™×‘ {remote_path} ××™× ×• ×ª×™×§×™×™×”"}
            
            # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
            files = []
            directories = []
            
            for item in os.listdir(full_path):
                item_path = os.path.join(full_path, item)
                
                if os.path.isdir(item_path):
                    directories.append({
                        "name": item,
                        "path": os.path.join(remote_path, item).replace("\\", "/"),
                        "type": "directory"
                    })
                else:
                    files.append({
                        "name": item,
                        "path": os.path.join(remote_path, item).replace("\\", "/"),
                        "type": "file",
                        "size": os.path.getsize(item_path),
                        "modified": datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).isoformat()
                    })
            
            return {
                "status": "success",
                "path": remote_path,
                "files": files,
                "directories": directories
            }
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¨×©×™××ª ×§×‘×¦×™ NFS: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """
        ×§×‘×œ×ª ××™×“×¢ ××”××˜××•×Ÿ
        
        Args:
            cache_key: ××¤×ª×— ×”××˜××•×Ÿ
            
        Returns:
            ×”××™×“×¢ ××”××˜××•×Ÿ ××• None ×× ×œ× × ××¦×
        """
        if not self.cache_enabled:
            return None
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ×œ×§×•×‘×¥ ×”××˜××•×Ÿ
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        if not os.path.exists(cache_file):
            return None
        
        try:
            # ×‘×“×™×§×ª ×ª×•×§×£ ×”××˜××•×Ÿ
            mod_time = os.path.getmtime(cache_file)
            if time.time() - mod_time > self.cache_expiry_seconds:
                # ×”××˜××•×Ÿ ×¤×’ ×ª×•×§×£
                try:
                    os.remove(cache_file)
                except:
                    pass
                return None
            
            # ×§×¨×™××ª ×”××˜××•×Ÿ
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
                
        except Exception as e:
            logger.warning(f"×©×’×™××” ×‘×§×¨×™××ª ××˜××•×Ÿ {cache_key}: {str(e)}")
            return None
    
    def _save_to_cache(self, cache_key: str, data: Dict[str, Any]) -> bool:
        """
        ×©××™×¨×ª ××™×“×¢ ×‘××˜××•×Ÿ
        
        Args:
            cache_key: ××¤×ª×— ×”××˜××•×Ÿ
            data: ×”××™×“×¢ ×œ×©××™×¨×”
            
        Returns:
            ×”×× ×”×©××™×¨×” ×”×¦×œ×™×—×”
        """
        if not self.cache_enabled:
            return False
        
        # ×™×¦×™×¨×ª × ×ª×™×‘ ×œ×§×•×‘×¥ ×”××˜××•×Ÿ
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        
        try:
            # ×©××™×¨×ª ×”××™×“×¢
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
                
        except Exception as e:
            logger.warning(f"×©×’×™××” ×‘×©××™×¨×ª ××˜××•×Ÿ {cache_key}: {str(e)}")
            return False
    
    def _clear_cache(self, connection_id: str = None) -> bool:
        """
        × ×™×§×•×™ ×”××˜××•×Ÿ
        
        Args:
            connection_id: ××–×”×” ×—×™×‘×•×¨ ×œ× ×™×§×•×™ (××•×¤×¦×™×•× ×œ×™)
            
        Returns:
            ×”×× ×”× ×™×§×•×™ ×”×¦×œ×™×—
        """
        if not self.cache_enabled:
            return False
        
        try:
            # × ×™×§×•×™ ×”××˜××•×Ÿ
            if connection_id:
                # × ×™×§×•×™ ×¨×§ ×©×œ ×—×™×‘×•×¨ ××¡×•×™×
                pattern = f"{connection_id}_*.json"
                for cache_file in glob.glob(os.path.join(self.cache_dir, pattern)):
                    try:
                        os.remove(cache_file)
                    except:
                        pass
            else:
                # × ×™×§×•×™ ×›×œ ×”××˜××•×Ÿ
                for cache_file in os.listdir(self.cache_dir):
                    if cache_file.endswith(".json"):
                        try:
                            os.remove(os.path.join(self.cache_dir, cache_file))
                        except:
                            pass
            
            return True
                
        except Exception as e:
            logger.warning(f"×©×’×™××” ×‘× ×™×§×•×™ ××˜××•×Ÿ: {str(e)}")
            return False
    
    def sync_from_remote(self, connection_id: str, remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ ××¨×•×—×§ ×œ××§×•××™
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        if not self.enabled:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª"}
        
        if connection_id not in self.active_connections:
            logger.warning(f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×")
            return {"status": "error", "error": f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×"}
        
        try:
            # ×©×œ×™×¤×ª × ×ª×•× ×™ ×”×—×™×‘×•×¨
            connection_info = self.active_connections[connection_id]
            storage_type = connection_info["type"]
            connection = connection_info["connection"]
            client = connection_info["client"]
            
            logger.info(f"××¡× ×›×¨×Ÿ ××¨×—×•×§: {remote_path} -> ××§×•××™: {local_path}")
            
            # ×•×™×“×•× ×©×ª×™×§×™×™×ª ×”×™×¢×“ ×§×™×™××ª
            os.makedirs(os.path.dirname(os.path.abspath(local_path)), exist_ok=True)
            
            # ×”×•×¨×“×ª ×”×§×•×‘×¥ ×œ×¤×™ ×¡×•×’ ××—×¡×•×Ÿ
            if storage_type == "local":
                result = self._sync_local_to_local(connection, remote_path, local_path)
            elif storage_type == "ssh":
                result = self._sync_ssh_to_local(connection, client, remote_path, local_path)
            elif storage_type == "s3":
                result = self._sync_s3_to_local(connection, client, remote_path, local_path)
            elif storage_type == "ftp":
                result = self._sync_ftp_to_local(connection, client, remote_path, local_path)
            elif storage_type == "webdav":
                result = self._sync_webdav_to_local(connection, client, remote_path, local_path)
            elif storage_type == "smb":
                result = self._sync_smb_to_local(connection, client, remote_path, local_path)
            elif storage_type == "nfs":
                result = self._sync_nfs_to_local(connection, remote_path, local_path)
            else:
                return {"status": "error", "error": f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š"}
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡× ×›×¨×•×Ÿ ××¨×—×•×§ ×œ××§×•××™: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_local(self, connection: Dict[str, Any], remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ ××§×•××™ ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×ª×™×‘ ×”×‘×¡×™×¡
        if not full_remote_path.startswith(base_path):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        try:
            # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×§×™×™×
            if not os.path.exists(full_remote_path):
                return {"status": "error", "error": f"×§×•×‘×¥ {remote_path} ×œ× × ××¦×"}
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(full_remote_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                shutil.copytree(full_remote_path, local_path, dirs_exist_ok=True)
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                shutil.copy2(full_remote_path, local_path)
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_ssh_to_local(self, connection: Dict[str, Any], client: Dict[str, Any], remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ SSH ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SSH
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        sftp_client = client["sftp"]
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        try:
            # ×‘×“×™×§×ª ×¡×•×’ ×”×§×•×‘×¥
            is_dir = False
            try:
                is_dir = sftp_client.stat(full_remote_path).st_mode & 0o40000 != 0
            except:
                # × ×™×¡×™×•×Ÿ ×œ×–×”×•×ª ×× ×–×• ×ª×™×§×™×™×”
                try:
                    sftp_client.listdir(full_remote_path)
                    is_dir = True
                except:
                    pass
            
            if is_dir:
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                os.makedirs(local_path, exist_ok=True)
                
                # ×¨×©×™××ª ×§×‘×¦×™×
                items = sftp_client.listdir(full_remote_path)
                
                for item in items:
                    # ×“×™×œ×•×’ ×¢×œ ×ª×™×§×™×•×ª ××™×•×—×“×•×ª
                    if item in ['.', '..']:
                        continue
                    
                    remote_item_path = os.path.join(full_remote_path, item)
                    local_item_path = os.path.join(local_path, item)
                    
                    # ×‘×“×™×§×” ×× ×¤×¨×™×˜ ×–×” ×ª×™×§×™×™×”
                    item_is_dir = False
                    try:
                        item_is_dir = sftp_client.stat(remote_item_path).st_mode & 0o40000 != 0
                    except:
                        try:
                            sftp_client.listdir(remote_item_path)
                            item_is_dir = True
                        except:
                            pass
                    
                    if item_is_dir:
                        # ×¨×§×•×¨×¡×™×” ×œ×ª×™×§×™×™×”
                        self._sync_ssh_to_local(connection, client, os.path.join(remote_path, item), local_item_path)
                    else:
                        # ×”×¢×ª×§×ª ×§×•×‘×¥
                        sftp_client.get(remote_item_path, local_item_path)
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                sftp_client.get(full_remote_path, local_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ SSH: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_s3_to_local(self, connection: Dict[str, Any], client: Any, remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ S3 ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— S3
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        bucket = connection["bucket"]
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.join(base_path, remote_path).replace("\\", "/").strip("/")
        
        try:
            # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×” ××• ×§×•×‘×¥
            is_dir = False
            
            # × ×™×¡×™×•×Ÿ ×œ×§×‘×œ ××ª ×”××•×‘×™×™×§×˜
            try:
                client.head_object(Bucket=bucket, Key=full_remote_path)
                is_dir = False
            except:
                # × ×™×¡×™×•×Ÿ ×œ×‘×“×•×§ ×× ×–×• ×ª×™×§×™×™×” (×ª×™×§×™×•×ª ×‘-S3 ×”×Ÿ ×•×™×¨×˜×•××œ×™×•×ª)
                try:
                    response = client.list_objects_v2(
                        Bucket=bucket,
                        Prefix=full_remote_path + '/',
                        Delimiter='/',
                        MaxKeys=1
                    )
                    is_dir = 'Contents' in response or 'CommonPrefixes' in response
                except:
                    pass
            
            if is_dir:
                # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×™×¢×“
                os.makedirs(local_path, exist_ok=True)
                
                # ×§×‘×œ×ª ×¨×©×™××ª ××•×‘×™×™×§×˜×™×
                paginator = client.get_paginator('list_objects_v2')
                operation_parameters = {
                    'Bucket': bucket,
                    'Prefix': full_remote_path + '/'
                }
                
                file_count = 0
                for page in paginator.paginate(**operation_parameters):
                    if 'Contents' in page:
                        for obj in page['Contents']:
                            # ×—×™×©×•×‘ ×”× ×ª×™×‘ ×”××§×•××™
                            relative_path = obj['Key'][len(full_remote_path):].lstrip('/')
                            local_file_path = os.path.join(local_path, relative_path)
                            
                            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
                            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)
                            
                            # ×”×•×¨×“×ª ×”×§×•×‘×¥
                            client.download_file(bucket, obj['Key'], local_file_path)
                            file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×•×¨×“×ª ×”×§×•×‘×¥
                client.download_file(bucket, full_remote_path, local_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ S3: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_ftp_to_local(self, connection: Dict[str, Any], client: Any, remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ FTP ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— FTP
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        current_dir = client.pwd()
        
        try:
            # × ×™×¡×™×•×Ÿ ×œ×¢×‘×•×¨ ×œ×ª×™×§×™×™×” ×›×“×™ ×œ×‘×“×•×§ ×× ×”×™× ×§×™×™××ª
            try:
                client.cwd(full_remote_path)
                is_dir = True
                client.cwd(current_dir)  # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            except:
                is_dir = False
            
            if is_dir:
                # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×™×¢×“
                os.makedirs(local_path, exist_ok=True)
                
                # ××¢×‘×¨ ×œ×ª×™×§×™×™×” ×”××¨×•×—×§×ª
                client.cwd(full_remote_path)
                
                # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
                items = []
                client.dir(lambda line: items.append(line))
                
                # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
                client.cwd(current_dir)
                
                file_count = 0
                for item in items:
                    parts = item.split()
                    if len(parts) < 9:
                        continue
                    
                    # ×”×¤×¨×“×ª ×”××™×“×¢
                    permissions = parts[0]
                    name = " ".join(parts[8:])
                    
                    # ×“×™×œ×•×’ ×¢×œ ×ª×™×§×™×•×ª ××™×•×—×“×•×ª
                    if name in ['.', '..']:
                        continue
                    
                    # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
                    item_is_dir = permissions.startswith('d')
                    
                    if item_is_dir:
                        # ×¨×§×•×¨×¡×™×” ×œ×ª×™×§×™×™×”
                        self._sync_ftp_to_local(connection, client, os.path.join(remote_path, name), os.path.join(local_path, name))
                    else:
                        # ×”×•×¨×“×ª ×”×§×•×‘×¥
                        item_remote_path = os.path.join(full_remote_path, name)
                        item_local_path = os.path.join(local_path, name)
                        
                        with open(item_local_path, 'wb') as f:
                            client.retrbinary(f"RETR {item_remote_path}", f.write)
                        
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×•×¨×“×ª ×”×§×•×‘×¥
                with open(local_path, 'wb') as f:
                    client.retrbinary(f"RETR {full_remote_path}", f.write)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            # × ×™×¡×™×•×Ÿ ×œ×—×–×•×¨ ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            try:
                client.cwd(current_dir)
            except:
                pass
            
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ FTP: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_webdav_to_local(self, connection: Dict[str, Any], client: Any, remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ WebDAV ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— WebDAV
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        remote_path = remote_path.lstrip("/")
        
        try:
            # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
            is_dir = client.is_dir(remote_path)
            
            if is_dir:
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                client.download_sync(remote_path, local_path)
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                client.download_file(remote_path, local_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ WebDAV: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_smb_to_local(self, connection: Dict[str, Any], client: Any, remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ SMB ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SMB
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        share = connection["share"]
        base_path = connection["base_path"].lstrip("/").replace("/", "\\")
        remote_path = remote_path.lstrip("/").replace("/", "\\")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        try:
            from smb.smb_structs import OperationFailure
            
            # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
            is_dir = False
            try:
                items = client.listPath(share, full_remote_path)
                is_dir = True
            except OperationFailure:
                is_dir = False
            
            if is_dir:
                # ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×”×™×¢×“
                os.makedirs(local_path, exist_ok=True)
                
                # ×¨×©×™××ª ×§×‘×¦×™× ×•×ª×™×§×™×•×ª
                items = client.listPath(share, full_remote_path)
                
                file_count = 0
                for item in items:
                    # ×“×™×œ×•×’ ×¢×œ ×ª×™×§×™×•×ª ××™×•×—×“×•×ª
                    if item.filename in ['.', '..']:
                        continue
                    
                    # ×‘×“×™×§×” ×× ×–×• ×ª×™×§×™×™×”
                    item_is_dir = item.isDirectory
                    
                    item_remote_path = os.path.join(remote_path, item.filename)
                    item_local_path = os.path.join(local_path, item.filename)
                    
                    if item_is_dir:
                        # ×¨×§×•×¨×¡×™×” ×œ×ª×™×§×™×™×”
                        self._sync_smb_to_local(connection, client, item_remote_path, item_local_path)
                    else:
                        # ×”×•×¨×“×ª ×”×§×•×‘×¥
                        item_full_remote_path = os.path.join(full_remote_path, item.filename)
                        
                        with open(item_local_path, 'wb') as f:
                            client.retrieveFile(share, item_full_remote_path, f)
                        
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×•×¨×“×ª ×”×§×•×‘×¥
                with open(local_path, 'wb') as f:
                    client.retrieveFile(share, full_remote_path, f)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ SMB: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_nfs_to_local(self, connection: Dict[str, Any], remote_path: str, local_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××—×¡×•×Ÿ NFS ×œ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            local_path: × ×ª×™×‘ ××§×•××™
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        mount_point = connection["mount_point"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(mount_point, remote_path))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×§×•×“×ª ×”×¢×™×’×•×Ÿ
        if not full_remote_path.startswith(mount_point):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        try:
            # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×§×™×™×
            if not os.path.exists(full_remote_path):
                return {"status": "error", "error": f"×§×•×‘×¥ {remote_path} ×œ× × ××¦×"}
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(full_remote_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                shutil.copytree(full_remote_path, local_path, dirs_exist_ok=True)
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {remote_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                shutil.copy2(full_remote_path, local_path)
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {remote_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{local_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ NFS: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def sync_to_remote(self, connection_id: str, local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ ××¨×•×—×§
        
        Args:
            connection_id: ××–×”×” ×”×—×™×‘×•×¨
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        if not self.enabled:
            logger.warning("×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª")
            return {"status": "error", "error": "×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§ ××™× ×” ××•×¤×¢×œ×ª"}
        
        if connection_id not in self.active_connections:
            logger.warning(f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×")
            return {"status": "error", "error": f"×—×™×‘×•×¨ {connection_id} ×œ× × ××¦×"}
        
        try:
            # ×‘×“×™×§×” ×©×”×§×•×‘×¥ ×”××§×•××™ ×§×™×™×
            if not os.path.exists(local_path):
                return {"status": "error", "error": f"×§×•×‘×¥ ××§×•××™ {local_path} ×œ× × ××¦×"}
            
            # ×©×œ×™×¤×ª × ×ª×•× ×™ ×”×—×™×‘×•×¨
            connection_info = self.active_connections[connection_id]
            storage_type = connection_info["type"]
            connection = connection_info["connection"]
            client = connection_info["client"]
            
            logger.info(f"××¡× ×›×¨×Ÿ ××§×•××™: {local_path} -> ××¨×•×—×§: {remote_path}")
            
            # ×”×¢×œ××ª ×”×§×•×‘×¥ ×œ×¤×™ ×¡×•×’ ××—×¡×•×Ÿ
            if storage_type == "local":
                result = self._sync_local_to_remote(connection, local_path, remote_path)
            elif storage_type == "ssh":
                result = self._sync_local_to_ssh(connection, client, local_path, remote_path)
            elif storage_type == "s3":
                result = self._sync_local_to_s3(connection, client, local_path, remote_path)
            elif storage_type == "ftp":
                result = self._sync_local_to_ftp(connection, client, local_path, remote_path)
            elif storage_type == "webdav":
                result = self._sync_local_to_webdav(connection, client, local_path, remote_path)
            elif storage_type == "smb":
                result = self._sync_local_to_smb(connection, client, local_path, remote_path)
            elif storage_type == "nfs":
                result = self._sync_local_to_nfs(connection, local_path, remote_path)
            else:
                return {"status": "error", "error": f"×¡×•×’ ××—×¡×•×Ÿ {storage_type} ××™× ×• × ×ª××š"}
            
            # × ×™×§×•×™ ×”××˜××•×Ÿ ×× ×”×¤×¢×•×œ×” ×”×¦×œ×™×—×”
            if result["status"] == "success" and self.cache_enabled:
                cache_key = f"{connection_id}_{os.path.dirname(remote_path)}"
                self._clear_cache(connection_id)
            
            return result
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¡× ×›×¨×•×Ÿ ××§×•××™ ×œ××¨×•×—×§: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_remote(self, connection: Dict[str, Any], local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ ××§×•××™
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×ª×™×‘ ×”×‘×¡×™×¡
        if not full_remote_path.startswith(base_path):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
            os.makedirs(os.path.dirname(full_remote_path), exist_ok=True)
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                shutil.copytree(local_path, full_remote_path, dirs_exist_ok=True)
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                shutil.copy2(local_path, full_remote_path)
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ××§×•××™: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_ssh(self, connection: Dict[str, Any], client: Dict[str, Any], local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ SSH
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SSH
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        sftp_client = client["sftp"]
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
            remote_dir = os.path.dirname(full_remote_path)
            try:
                sftp_client.stat(remote_dir)
            except FileNotFoundError:
                # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™× ×¨×§×•×¨×¡×™×‘×™×ª
                current_dir = base_path
                for part in os.path.relpath(remote_dir, base_path).split('/'):
                    if not part:
                        continue
                    current_dir = os.path.join(current_dir, part)
                    try:
                        sftp_client.stat(current_dir)
                    except FileNotFoundError:
                        sftp_client.mkdir(current_dir)
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                try:
                    sftp_client.stat(full_remote_path)
                except FileNotFoundError:
                    sftp_client.mkdir(full_remote_path)
                
                file_count = 0
                for root, dirs, files in os.walk(local_path):
                    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×¦×“ ×”××¨×•×—×§
                    for dir_name in dirs:
                        local_dir = os.path.join(root, dir_name)
                        rel_path = os.path.relpath(local_dir, local_path)
                        remote_dir = os.path.join(full_remote_path, rel_path).replace('\\', '/')
                        
                        try:
                            sftp_client.stat(remote_dir)
                        except FileNotFoundError:
                            sftp_client.mkdir(remote_dir)
                    
                    # ×”×¢×ª×§×ª ×§×‘×¦×™×
                    for file_name in files:
                        local_file = os.path.join(root, file_name)
                        rel_path = os.path.relpath(local_file, local_path)
                        remote_file = os.path.join(full_remote_path, rel_path).replace('\\', '/')
                        
                        sftp_client.put(local_file, remote_file)
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                sftp_client.put(local_path, full_remote_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-SSH: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_s3(self, connection: Dict[str, Any], client: Any, local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ S3
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— S3
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        bucket = connection["bucket"]
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.join(base_path, remote_path).replace("\\", "/").strip("/")
        
        try:
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                file_count = 0
                for root, dirs, files in os.walk(local_path):
                    for file_name in files:
                        local_file = os.path.join(root, file_name)
                        rel_path = os.path.relpath(local_file, local_path)
                        remote_key = f"{full_remote_path}/{rel_path}".replace("\\", "/")
                        
                        # ×”×¢×œ××ª ×”×§×•×‘×¥
                        client.upload_file(local_file, bucket, remote_key)
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                client.upload_file(local_path, bucket, full_remote_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-S3: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_ftp(self, connection: Dict[str, Any], client: Any, local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ FTP
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— FTP
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        base_path = connection["base_path"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        current_dir = client.pwd()
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
            remote_dir = os.path.dirname(full_remote_path)
            try:
                client.cwd(remote_dir)
                client.cwd(current_dir)  # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            except:
                # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™× ×¨×§×•×¨×¡×™×‘×™×ª
                current_path = base_path
                for part in os.path.relpath(remote_dir, base_path).split('/'):
                    if not part:
                        continue
                    current_path = os.path.join(current_path, part)
                    try:
                        client.cwd(current_path)
                        client.cwd(current_dir)  # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
                    except:
                        client.mkd(current_path)
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                try:
                    client.cwd(full_remote_path)
                    client.cwd(current_dir)  # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
                except:
                    client.mkd(full_remote_path)
                
                file_count = 0
                for root, dirs, files in os.walk(local_path):
                    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×¦×“ ×”××¨×•×—×§
                    for dir_name in dirs:
                        local_dir = os.path.join(root, dir_name)
                        rel_path = os.path.relpath(local_dir, local_path)
                        remote_dir = os.path.join(full_remote_path, rel_path).replace('\\', '/')
                        
                        try:
                            client.cwd(remote_dir)
                            client.cwd(current_dir)  # ×—×–×¨×” ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
                        except:
                            client.mkd(remote_dir)
                    
                    # ×”×¢×ª×§×ª ×§×‘×¦×™×
                    for file_name in files:
                        local_file = os.path.join(root, file_name)
                        rel_path = os.path.relpath(local_file, local_path)
                        remote_file = os.path.join(full_remote_path, rel_path).replace('\\', '/')
                        
                        with open(local_file, 'rb') as f:
                            client.storbinary(f"STOR {remote_file}", f)
                        
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                with open(local_path, 'rb') as f:
                    client.storbinary(f"STOR {full_remote_path}", f)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            # × ×™×¡×™×•×Ÿ ×œ×—×–×•×¨ ×œ×ª×™×§×™×™×” ×”××§×•×¨×™×ª
            try:
                client.cwd(current_dir)
            except:
                pass
            
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-FTP: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_webdav(self, connection: Dict[str, Any], client: Any, local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ WebDAV
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— WebDAV
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        remote_path = remote_path.lstrip("/")
        
        try:
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                client.upload_sync(local_path, remote_path)
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                client.upload_file(local_path, remote_path)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-WebDAV: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_smb(self, connection: Dict[str, Any], client: Any, local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ SMB
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            client: ×œ×§×•×— SMB
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        share = connection["share"]
        base_path = connection["base_path"].lstrip("/").replace("/", "\\")
        remote_path = remote_path.lstrip("/").replace("/", "\\")
        full_remote_path = os.path.normpath(os.path.join(base_path, remote_path))
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
            remote_dir = os.path.dirname(full_remote_path)
            try:
                client.listPath(share, remote_dir)
            except:
                # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™× ×¨×§×•×¨×¡×™×‘×™×ª
                current_path = base_path
                for part in os.path.relpath(remote_dir, base_path).split('\\'):
                    if not part:
                        continue
                    current_path = os.path.join(current_path, part)
                    try:
                        client.listPath(share, current_path)
                    except:
                        client.createDirectory(share, current_path)
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                try:
                    client.listPath(share, full_remote_path)
                except:
                    client.createDirectory(share, full_remote_path)
                
                file_count = 0
                for root, dirs, files in os.walk(local_path):
                    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×¦×“ ×”××¨×•×—×§
                    for dir_name in dirs:
                        local_dir = os.path.join(root, dir_name)
                        rel_path = os.path.relpath(local_dir, local_path)
                        remote_dir = os.path.join(full_remote_path, rel_path).replace('/', '\\')
                        
                        try:
                            client.listPath(share, remote_dir)
                        except:
                            client.createDirectory(share, remote_dir)
                    
                    # ×”×¢×ª×§×ª ×§×‘×¦×™×
                    for file_name in files:
                        local_file = os.path.join(root, file_name)
                        rel_path = os.path.relpath(local_file, local_path)
                        remote_file = os.path.join(full_remote_path, rel_path).replace('/', '\\')
                        
                        with open(local_file, 'rb') as f:
                            client.storeFile(share, remote_file, f)
                        
                        file_count += 1
                
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path} ({file_count} ×§×‘×¦×™×)",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                with open(local_path, 'rb') as f:
                    client.storeFile(share, full_remote_path, f)
                
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-SMB: {str(e)}")
            return {"status": "error", "error": str(e)}
    
    def _sync_local_to_nfs(self, connection: Dict[str, Any], local_path: str, remote_path: str) -> Dict[str, Any]:
        """
        ×¡× ×›×¨×•×Ÿ ×××§×•××™ ×œ××—×¡×•×Ÿ NFS
        
        Args:
            connection: ××™×“×¢ ×”×—×™×‘×•×¨
            local_path: × ×ª×™×‘ ××§×•××™
            remote_path: × ×ª×™×‘ ××¨×•×—×§
            
        Returns:
            ×ª×•×¦××ª ×”×¡× ×›×¨×•×Ÿ
        """
        mount_point = connection["mount_point"]
        remote_path = remote_path.lstrip("/")
        full_remote_path = os.path.normpath(os.path.join(mount_point, remote_path))
        
        # ×‘×“×™×§×” ×©×”× ×ª×™×‘ × ××¦× ×‘×ª×•×š × ×§×•×“×ª ×”×¢×™×’×•×Ÿ
        if not full_remote_path.startswith(mount_point):
            return {"status": "error", "error": "× ×ª×™×‘ ×œ× ×—×•×§×™"}
        
        try:
            # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×‘×™× ×™×™×
            os.makedirs(os.path.dirname(full_remote_path), exist_ok=True)
            
            # ×”×¢×ª×§×ª ×”×§×•×‘×¥
            if os.path.isdir(local_path):
                # ×”×¢×ª×§×ª ×ª×™×§×™×™×”
                shutil.copytree(local_path, full_remote_path, dirs_exist_ok=True)
                return {
                    "status": "success",
                    "message": f"×ª×™×§×™×™×” {local_path} ×”×•×¢×ª×§×” ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "directory"
                }
            else:
                # ×”×¢×ª×§×ª ×§×•×‘×¥
                shutil.copy2(local_path, full_remote_path)
                return {
                    "status": "success",
                    "message": f"×§×•×‘×¥ {local_path} ×”×•×¢×ª×§ ×‘×”×¦×œ×—×” ×œ-{remote_path}",
                    "type": "file",
                    "size": os.path.getsize(local_path)
                }
                
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×”×¢×ª×§×ª ×§×•×‘×¥ ××§×•××™ ×œ-NFS: {str(e)}")
            return {"status": "error", "error": str(e)}
REMOTE_STORAGE_PY

# ×™×¦×™×¨×ª ×§×•×‘×¥ ×××©×§ ××©×ª××© ×‘×¡×™×¡×™
echo "ğŸ“ ×™×•×¦×¨ ×××©×§ ××©×ª××© ×‘×¡×™×¡×™..."
mkdir -p "$BASE_DIR/ui/templates"

cat > "$BASE_DIR/ui/templates/index.html" << 'INDEX_HTML'
<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>×××—×“ ×§×•×“ ×—×›× Pro 2.0</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
    <link rel="manifest" href="../../pwa/manifest.json">
    <link rel="icon" type="image/png" href="../../assets/images/favicon.png">
    <script defer src="../../assets/js/app.js"></script>
    
    <!-- ×”×’×“×¨×•×ª PWA -->
    <meta name="theme-color" content="#2196f3">
    <meta name="description" content="×××—×“ ×§×•×“ ×—×›× Pro - ×›×œ×™ ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP">
    <meta name="application-name" content="×××—×“ ×§×•×“ ×—×›× Pro">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="×××—×“ ×§×•×“ ×—×›× Pro">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
</head>
<body>
    <div class="app-container">
        <header class="app-header">
            <div class="logo">
                <img src="../../assets/images/logo.svg" alt="×××—×“ ×§×•×“ ×—×›× Pro 2.0" />
                <h1>×××—×“ ×§×•×“ ×—×›× Pro 2.0</h1>
            </div>
            <nav class="main-nav">
                <ul>
                    <li><a href="#" data-tab="home" class="active">×¨××©×™</a></li>
                    <li><a href="#" data-tab="projects">×¤×¨×•×™×§×˜×™×</a></li>
                    <li><a href="#" data-tab="security">××‘×˜×—×”</a></li>
                    <li><a href="#" data-tab="settings">×”×’×“×¨×•×ª</a></li>
                </ul>
            </nav>
        </header>
        
        <main class="app-content">
            <!-- ×œ×©×•× ×™×ª ×¨××©×™×ª -->
            <section id="home" class="tab-content active">
                <div class="card">
                    <h2>×‘×¨×•×›×™× ×”×‘××™× ×œ×××—×“ ×§×•×“ ×—×›× Pro 2.0</h2>
                    <p>×›×œ×™ ××ª×§×“× ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP</p>
                    
                    <div class="file-upload-container">
                        <h3>×”×¢×œ××ª ×§×‘×¦×™ ZIP ×œ× ×™×ª×•×—</h3>
                        <div class="file-upload-area" id="dropZone">
                            <img src="../../assets/images/upload-icon.svg" alt="×”×¢×œ××ª ×§×‘×¦×™×" />
                            <p>×’×¨×•×¨ ×§×‘×¦×™ ZIP ×œ×›××Ÿ ××• <label for="fileInput" class="file-input-label">×‘×—×¨ ×§×‘×¦×™×</label></p>
                            <input type="file" id="fileInput" multiple accept=".zip" class="file-input" />
                        </div>
                        <div class="selected-files-list" id="selectedFilesList"></div>
                    </div>
                    
                    <div class="action-buttons">
                        <button id="analyzeBtn" class="btn btn-primary" disabled>
                            <span class="btn-text">× ×ª×— ×¤×¨×•×™×§×˜×™×</span>
                            <span class="spinner"></span>
                        </button>
                        <button id="clearBtn" class="btn btn-secondary" disabled>× ×§×”</button>
                    </div>
                </div>
                
                <div class="card" id="analysisResults" style="display: none;">
                    <h2>×ª×•×¦××•×ª × ×™×ª×•×—</h2>
                    <div class="analysis-summary">
                        <div class="summary-item">
                            <span class="summary-icon"><img src="../../assets/images/project-icon.svg" alt="×¤×¨×•×™×§×˜×™×" /></span>
                            <span class="summary-value" id="projectsCount">0</span>
                            <span class="summary-label">×¤×¨×•×™×§×˜×™× ×–×•×”×•</span>
                        </div>
                        <div class="summary-item">
                            <span class="summary-icon"><img src="../../assets/images/file-icon.svg" alt="×§×‘×¦×™×" /></span>
                            <span class="summary-value" id="filesCount">0</span>
                            <span class="summary-label">×§×‘×¦×™× ×¡×”"×›</span>
                        </div>
                        <div class="summary-item">
                            <span class="summary-icon"><img src="../../assets/images/security-icon.svg" alt="×‘×¢×™×•×ª ××‘×˜×—×”" /></span>
                            <span class="summary-value" id="securityIssuesCount">0</span>
                            <span class="summary-label">×‘×¢×™×•×ª ××‘×˜×—×”</span>
                        </div>
                    </div>
                    
                    <div class="detected-projects">
                        <h3>×¤×¨×•×™×§×˜×™× ×©×–×•×”×•</h3>
                        <div class="projects-list" id="projectsList"></div>
                    </div>
                    
                    <div class="action-buttons">
                        <button id="mergeSelectedBtn" class="btn btn-primary" disabled>
                            <span class="btn-text">××–×’ ×¤×¨×•×™×§×˜×™× × ×‘×—×¨×™×</span>
                            <span class="spinner"></span>
                        </button>
                        <button id="downloadReportBtn" class="btn btn-secondary" disabled>×”×•×¨×“ ×“×•×—</button>
                    </div>
                </div>
            </section>
            
            <!-- ×œ×©×•× ×™×ª ×¤×¨×•×™×§×˜×™× -->
            <section id="projects" class="tab-content">
                <div class="card">
                    <h2>×¤×¨×•×™×§×˜×™× ×§×™×™××™×</h2>
                    <div class="projects-history" id="projectsHistory">
                        <p class="empty-state">××™×Ÿ ×¤×¨×•×™×§×˜×™× ×§×™×™××™× ×¢×“×™×™×Ÿ</p>
                    </div>
                </div>
            </section>
            
            <!-- ×œ×©×•× ×™×ª ××‘×˜×—×” -->
            <section id="security" class="tab-content">
                <div class="card">
                    <h2>×“×•×—×•×ª ××‘×˜×—×”</h2>
                    <div class="security-reports" id="securityReports">
                        <p class="empty-state">××™×Ÿ ×“×•×—×•×ª ××‘×˜×—×” ×¢×“×™×™×Ÿ</p>
                    </div>
                </div>
            </section>
            
            <!-- ×œ×©×•× ×™×ª ×”×’×“×¨×•×ª -->
            <section id="settings" class="tab-content">
                <div class="card">
                    <h2>×”×’×“×¨×•×ª ×›×œ×œ×™×•×ª</h2>
                    <form id="settingsForm">
                        <div class="form-group">
                            <label for="outputPath">×ª×™×§×™×™×ª ×¤×œ×˜</label>
                            <input type="text" id="outputPath" placeholder="× ×ª×™×‘ ×œ×ª×™×§×™×™×ª ×”×¤×œ×˜">
                            <button type="button" id="browsePath" class="btn btn-small">×¢×™×•×Ÿ...</button>
                        </div>
                        
                        <div class="form-group">
                            <label for="maxFileSize">×’×•×“×œ ×§×•×‘×¥ ××§×¡×™××œ×™ ×œ× ×™×ª×•×— (MB)</label>
                            <input type="number" id="maxFileSize" min="1" max="1000" value="100">
                        </div>
                        
                        <div class="form-group">
                            <label for="threadCount">××¡×¤×¨ ×—×•×˜×™× ×œ×¢×™×‘×•×“ ××§×‘×™×œ×™</label>
                            <input type="number" id="threadCount" min="1" max="16" value="4">
                        </div>
                        
                        <h3>×”×’×“×¨×•×ª ××‘×˜×—×”</h3>
                        
                        <div class="form-group">
                            <label>
                                <input type="checkbox" id="enableSecurity" checked>
                                ×”×¤×¢×œ ×¡×¨×™×§×•×ª ××‘×˜×—×”
                            </label>
                        </div>
                        
                        <div class="form-group">
                            <label for="securityLevel">×¨××ª ×¡×¨×™×§×ª ××‘×˜×—×”</label>
                            <select id="securityLevel">
                                <option value="low">×‘×¡×™×¡×™×ª</option>
                                <option value="medium" selected>×‘×™× ×•× ×™×ª</option>
                                <option value="high">××ª×§×“××ª</option>
                            </select>
                        </div>
                        
                        <h3>××—×¡×•×Ÿ ××¨×•×—×§</h3>
                        
                        <div class="form-group">
                            <label>
                                <input type="checkbox" id="enableRemoteStorage">
                                ×”×¤×¢×œ ×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§
                            </label>
                        </div>
                        
                        <div class="form-group">
                            <label for="remoteStorageType">×¡×•×’ ××—×¡×•×Ÿ ××¨×•×—×§</label>
                            <select id="remoteStorageType" disabled>
                                <option value="sftp">SFTP</option>
                                <option value="s3">Amazon S3</option>
                                <option value="ftp">FTP</option>
                                <option value="webdav">WebDAV</option>
                            </select>
                        </div>
                        
                        <div class="action-buttons">
                            <button type="submit" id="saveSettingsBtn" class="btn btn-primary">
                                <span class="btn-text">×©××•×¨ ×”×’×“×¨×•×ª</span>
                                <span class="spinner"></span>
                            </button>
                            <button type="button" id="resetSettingsBtn" class="btn btn-secondary">××¤×¡ ×”×’×“×¨×•×ª</button>
                        </div>
                    </form>
                </div>
                
                <div class="card">
                    <h2>××•×“×•×ª</h2>
                    <div class="about-info">
                        <p>×’×¨×¡×ª ×ª×•×›× ×”: <span id="versionNumber">2.0.0</span></p>
                        <p>×ª××¨×™×š ×©×—×¨×•×¨: ×××™ 2025</p>
                        <p>××¤×ª×—: Claude AI</p>
                        <p>×¨×™×©×™×•×Ÿ: MIT</p>
                    </div>
                </div>
            </section>
        </main>
        
        <footer class="app-footer">
            <p>&copy; 2025 ×××—×“ ×§×•×“ ×—×›× Pro. ×›×œ ×”×–×›×•×™×•×ª ×©××•×¨×•×ª.</p>
        </footer>
    </div>
    
    <!-- ×“×™××œ×•×’ ××™×–×•×’ -->
    <div class="dialog-overlay" id="mergeDialogOverlay" style="display: none;">
        <div class="dialog" id="mergeDialog">
            <div class="dialog-header">
                <h2>××™×–×•×’ ×¤×¨×•×™×§×˜×™×</h2>
                <button class="close-btn" id="closeMergeDialog">&times;</button>
            </div>
            <div class="dialog-content">
                <p>×‘×—×¨ ×ª×™×§×™×™×ª ×™×¢×“ ×œ××™×–×•×’ ×”×¤×¨×•×™×§×˜×™×:</p>
                <div class="form-group">
                    <input type="text" id="mergeOutputPath" placeholder="× ×ª×™×‘ ×œ×ª×™×§×™×™×ª ×”×™×¢×“">
                    <button type="button" id="browseMergePath" class="btn btn-small">×¢×™×•×Ÿ...</button>
                </div>
                <div class="form-group">
                    <label>
                        <input type="checkbox" id="createZip" checked>
                        ×¦×•×¨ ×§×•×‘×¥ ZIP ××”×ª×•×¦××”
                    </label>
                </div>
                <div class="form-group">
                    <label>
                        <input type="checkbox" id="runSecurityScan" checked>
                        ×”×¤×¢×œ ×¡×¨×™×§×ª ××‘×˜×—×” ××œ××”
                    </label>
                </div>
            </div>
            <div class="dialog-footer">
                <button id="startMergeBtn" class="btn btn-primary">
                    <span class="btn-text">×”×ª×—×œ ××™×–×•×’</span>
                    <span class="spinner"></span>
                </button>
                <button id="cancelMergeBtn" class="btn btn-secondary">×‘×™×˜×•×œ</button>
            </div>
        </div>
    </div>
    
    <!-- ×¡×§×¨×™×¤×˜ ×”×ª×§× ×ª PWA -->
    <script>
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', function() {
                navigator.serviceWorker.register('../../pwa/service-worker.js')
                    .then(function(registration) {
                        console.log('Service Worker registered with scope:', registration.scope);
                    })
                    .catch(function(error) {
                        console.log('Service Worker registration failed:', error);
                    });
            });
        }
    </script>
</body>
</html>
INDEX_HTML

# ×™×¦×™×¨×ª ×§×•×‘×¥ CSS
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ CSS..."
mkdir -p "$BASE_DIR/assets/css"

cat > "$BASE_DIR/assets/css/style.css" << 'STYLE_CSS'
:root {
    --primary-color: #2196f3;
    --primary-dark: #1976d2;
    --primary-light: #bbdefb;
    --accent-color: #ff4081;
    --text-color: #333333;
    --text-light: #757575;
    --background-color: #f5f5f5;
    --card-color: #ffffff;
    --border-color: #e0e0e0;
    --success-color: #4caf50;
    --warning-color: #ff9800;
    --error-color: #f44336;
    --info-color: #2196f3;
    
    --shadow-small: 0 2px 4px rgba(0, 0, 0, 0.1);
    --shadow-medium: 0 4px 8px rgba(0, 0, 0, 0.1);
    --shadow-large: 0 8px 16px rgba(0, 0, 0, 0.1);
    
    --border-radius: 4px;
    --spacing-xs: 4px;
    --spacing-sm: 8px;
    --spacing-md: 16px;
    --spacing-lg: 24px;
    --spacing-xl: 32px;
    
    --transition-speed: 0.3s;
    --font-family: 'Segoe UI', 'Arial', sans-serif;
}

* {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
}

body {
    font-family: var(--font-family);
    font-size: 16px;
    line-height: 1.5;
    color: var(--text-color);
    background-color: var(--background-color);
    direction: rtl;
}

.app-container {
    display: flex;
    flex-direction: column;
    min-height: 100vh;
    max-width: 1200px;
    margin: 0 auto;
    padding: var(--spacing-md);
}

/* ×›×•×ª×¨×ª ×¢×œ×™×•× ×” */
.app-header {
    background-color: var(--card-color);
    border-radius: var(--border-radius);
    box-shadow: var(--shadow-medium);
    padding: var(--spacing-md);
    margin-bottom: var(--spacing-lg);
    display: flex;
    justify-content: space-between;
    align-items: center;
    flex-wrap: wrap;
}

.logo {
    display: flex;
    align-items: center;
}

.logo img {
    height: 40px;
    margin-left: var(--spacing-md);
}

.logo h1 {
    font-size: 1.5rem;
    color: var(--primary-dark);
}

.main-nav ul {
    display: flex;
    list-style: none;
}

.main-nav a {
    display: block;
    padding: var(--spacing-sm) var(--spacing-md);
    color: var(--text-light);
    text-decoration: none;
    border-radius: var(--border-radius);
    transition: background-color var(--transition-speed), color var(--transition-speed);
}

.main-nav a.active, .main-nav a:hover {
    color: var(--primary-color);
    background-color: var(--primary-light);
}

/* ×ª×•×›×Ÿ ×¢×™×§×¨×™ */
.app-content {
    flex: 1;
}

.tab-content {
    display: none;
}

.tab-content.active {
    display: block;
}

.card {
    background-color: var(--card-color);
    border-radius: var(--border-radius);
    box-shadow: var(--shadow-medium);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-lg);
}

.card h2 {
    color: var(--primary-dark);
    margin-bottom: var(--spacing-md);
    font-size: 1.5rem;
}

.card h3 {
    color: var(--text-color);
    margin: var(--spacing-lg) 0 var(--spacing-md);
    font-size: 1.2rem;
}

/* ×˜×•×¤×¡ ×•××œ×× ×˜×™ ×§×œ×˜ */
.form-group {
    margin-bottom: var(--spacing-md);
}

.form-group label {
    display: block;
    margin-bottom: var(--spacing-xs);
    color: var(--text-light);
}

input[type="text"],
input[type="number"],
select,
textarea {
    width: 100%;
    padding: var(--spacing-sm);
    border: 1px solid var(--border-color);
    border-radius: var(--border-radius);
    font-family: var(--font-family);
    font-size: 1rem;
    transition: border-color var(--transition-speed);
}

input[type="text"]:focus,
input[type="number"]:focus,
select:focus,
textarea:focus {
    outline: none;
    border-color: var(--primary-color);
}

/* ×›×¤×ª×•×¨×™× */
.btn {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: var(--spacing-sm) var(--spacing-lg);
    border: none;
    border-radius: var(--border-radius);
    font-family: var(--font-family);
    font-size: 1rem;
    font-weight: 500;
    cursor: pointer;
    transition: background-color var(--transition-speed), transform var(--transition-speed);
    position: relative;
    overflow: hidden;
}

.btn-primary {
    background-color: var(--primary-color);
    color: white;
}

.btn-primary:hover {
    background-color: var(--primary-dark);
}

.btn-secondary {
    background-color: var(--background-color);
    color: var(--text-color);
    border: 1px solid var(--border-color);
}

.btn-secondary:hover {
    background-color: var(--border-color);
}

.btn-small {
    padding: var(--spacing-xs) var(--spacing-sm);
    font-size: 0.875rem;
}

.btn:active {
    transform: translateY(2px);
}

.btn:disabled {
    opacity: 0.7;
    cursor: not-allowed;
}

/* ×›×¤×ª×•×¨ ×¢× ×× ×™××¦×™×ª ×˜×¢×™× ×” */
.btn .spinner {
    display: none;
    width: 16px;
    height: 16px;
    margin-right: var(--spacing-sm);
    border: 2px solid rgba(255, 255, 255, 0.3);
    border-radius: 50%;
    border-top-color: #fff;
    animation: spin 1s linear infinite;
}

@keyframes spin {
    to {
        transform: rotate(360deg);
    }
}

.btn.loading .spinner {
    display: inline-block;
}

.btn.loading .btn-text {
    opacity: 0.7;
}

/* ××–×•×¨ ×”×¢×œ××ª ×§×‘×¦×™× */
.file-upload-container {
    margin: var(--spacing-lg) 0;
}

.file-upload-area {
    border: 2px dashed var(--border-color);
    border-radius: var(--border-radius);
    padding: var(--spacing-xl);
    text-align: center;
    background-color: var(--background-color);
    cursor: pointer;
    transition: border-color var(--transition-speed), background-color var(--transition-speed);
}

.file-upload-area:hover, .file-upload-area.dragover {
    border-color: var(--primary-color);
    background-color: var(--primary-light);
}

.file-upload-area img {
    width: 64px;
    height: 64px;
    margin-bottom: var(--spacing-md);
}

.file-upload-area p {
    color: var(--text-light);
}

.file-input-label {
    color: var(--primary-color);
    cursor: pointer;
    text-decoration: underline;
}

.file-input {
    display: none;
}

.selected-files-list {
    margin-top: var(--spacing-md);
}

.selected-file-item {
    display: flex;
    align-items: center;
    padding: var(--spacing-sm) 0;
    border-bottom: 1px solid var(--border-color);
}

.selected-file-item:last-child {
    border-bottom: none;
}

.selected-file-icon {
    margin-left: var(--spacing-sm);
    color: var(--primary-color);
}

.selected-file-name {
    flex: 1;
}

.selected-file-size {
    color: var(--text-light);
    font-size: 0.875rem;
    margin-right: var(--spacing-md);
}

.selected-file-remove {
    background: none;
    border: none;
    color: var(--error-color);
    cursor: pointer;
    font-size: 1.2rem;
    margin-right: var(--spacing-sm);
}

/* ×ª×§×¦×™×¨ × ×™×ª×•×— */
.analysis-summary {
    display: flex;
    justify-content: space-around;
    flex-wrap: wrap;
    margin: var(--spacing-lg) 0;
}

.summary-item {
    text-align: center;
    padding: var(--spacing-md);
    flex: 1;
    min-width: 150px;
}

.summary-icon {
    display: block;
    margin: 0 auto var(--spacing-sm);
}

.summary-icon img {
    width: 48px;
    height: 48px;
}

.summary-value {
    display: block;
    font-size: 2rem;
    font-weight: bold;
    color: var(--primary-color);
    margin-bottom: var(--spacing-xs);
}

.summary-label {
    color: var(--text-light);
}

/* ×¨×©×™××ª ×¤×¨×•×™×§×˜×™× */
.projects-list {
    margin-top: var(--spacing-md);
}

.project-item {
    border: 1px solid var(--border-color);
    border-radius: var(--border-radius);
    padding: var(--spacing-md);
    margin-bottom: var(--spacing-md);
    transition: box-shadow var(--transition-speed);
}

.project-item:hover {
    box-shadow: var(--shadow-medium);
}

.project-header {
    display: flex;
    align-items: center;
    margin-bottom: var(--spacing-sm);
}

.project-checkbox {
    margin-left: var(--spacing-md);
}

.project-name {
    flex: 1;
    font-weight: bold;
    color: var(--primary-dark);
}

.project-toggle {
    background: none;
    border: none;
    color: var(--text-light);
    cursor: pointer;
    font-size: 1.5rem;
    transition: transform var(--transition-speed);
}

.project-toggle.expanded {
    transform: rotate(180deg);
}

.project-details {
    display: none;
    margin-top: var(--spacing-md);
    padding-top: var(--spacing-md);
    border-top: 1px solid var(--border-color);
}

.project-details.visible {
    display: block;
}

.project-stats {
    display: flex;
    flex-wrap: wrap;
    margin-bottom: var(--spacing-md);
}

.project-stat {
    flex: 1;
    min-width: 100px;
    margin-bottom: var(--spacing-sm);
}

.project-stat-label {
    color: var(--text-light);
    font-size: 0.875rem;
}

.project-stat-value {
    font-weight: bold;
}

.project-files {
    background-color: var(--background-color);
    border-radius: var(--border-radius);
    padding: var(--spacing-sm);
    max-height: 200px;
    overflow-y: auto;
}

.project-file {
    padding: var(--spacing-xs) var(--spacing-sm);
    font-family: monospace;
    font-size: 0.875rem;
}

.project-file:nth-child(odd) {
    background-color: rgba(0, 0, 0, 0.03);
}

/* ×›×¤×ª×•×¨×™ ×¤×¢×•×œ×” */
.action-buttons {
    display: flex;
    justify-content: flex-end;
    gap: var(--spacing-md);
    margin-top: var(--spacing-lg);
}

/* ×”×•×“×¢×•×ª ××¦×‘ ×¨×™×§ */
.empty-state {
    text-align: center;
    padding: var(--spacing-xl);
    color: var(--text-light);
    font-style: italic;
}

/* ×“×™××œ×•×’×™× */
.dialog-overlay {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background-color: rgba(0, 0, 0, 0.5);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
}

.dialog {
    background-color: var(--card-color);
    border-radius: var(--border-radius);
    box-shadow: var(--shadow-large);
    width: 90%;
    max-width: 500px;
    max-height: 90vh;
    display: flex;
    flex-direction: column;
}

.dialog-header {
    padding: var(--spacing-md);
    border-bottom: 1px solid var(--border-color);
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.dialog-header h2 {
    margin: 0;
}

.close-btn {
    background: none;
    border: none;
    font-size: 1.5rem;
    cursor: pointer;
    color: var(--text-light);
}

.dialog-content {
    padding: var(--spacing-md);
    overflow-y: auto;
    flex: 1;
}

.dialog-footer {
    padding: var(--spacing-md);
    border-top: 1px solid var(--border-color);
    display: flex;
    justify-content: flex-end;
    gap: var(--spacing-md);
}

/* ×›×•×ª×¨×ª ×ª×—×ª×•× ×” */
.app-footer {
    margin-top: var(--spacing-lg);
    padding: var(--spacing-md) 0;
    text-align: center;
    color: var(--text-light);
    font-size: 0.875rem;
}

/* ×× ×™××¦×™×•×ª */
@keyframes pulse {
    0% {
        transform: scale(1);
    }
    50% {
        transform: scale(1.05);
    }
    100% {
        transform: scale(1);
    }
}

.pulse {
    animation: pulse 2s infinite;
}

@keyframes fadeIn {
    from {
        opacity: 0;
    }
    to {
        opacity: 1;
    }
}

.fade-in {
    animation: fadeIn 0.3s ease-in-out;
}

/* ×”×ª×××” ×œ××•×‘×™×™×œ */
@media (max-width: 768px) {
    .app-header {
        flex-direction: column;
        align-items: center;
    }
    
    .logo {
        margin-bottom: var(--spacing-md);
    }
    
    .main-nav {
        width: 100%;
    }
    
    .main-nav ul {
        justify-content: space-around;
    }
    
    .summary-item {
        min-width: 100px;
    }
    
    .action-buttons {
        flex-direction: column;
        gap: var(--spacing-sm);
    }
    
    .btn {
        width: 100%;
    }
}
STYLE_CSS

# ×™×¦×™×¨×ª ×§×•×‘×¥ JavaScript
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ JavaScript..."
mkdir -p "$BASE_DIR/assets/js"

cat > "$BASE_DIR/assets/js/app.js" << 'APP_JS'
/**
 * ×××—×“ ×§×•×“ ×—×›× Pro 2.0
 * ×§×•×‘×¥ JavaScript ×¨××©×™
 * 
 * ××—×‘×¨: Claude AI
 * ×’×¨×¡×”: 1.0.0
 * ×ª××¨×™×š: ×××™ 2025
 */

// ×˜×¢×™× ×ª ×”×“×£
document.addEventListener('DOMContentLoaded', function() {
    // ××ª×—×•×œ ××©×ª× ×™× ×•×”×¤× ×™×•×ª ×œ××¨×›×™×‘×™ ×××©×§
    const fileInput = document.getElementById('fileInput');
    const dropZone = document.getElementById('dropZone');
    const selectedFilesList = document.getElementById('selectedFilesList');
    const analyzeBtn = document.getElementById('analyzeBtn');
    const clearBtn = document.getElementById('clearBtn');
    const analysisResults = document.getElementById('analysisResults');
    const projectsCount = document.getElementById('projectsCount');
    const filesCount = document.getElementById('filesCount');
    const securityIssuesCount = document.getElementById('securityIssuesCount');
    const projectsList = document.getElementById('projectsList');
    const mergeSelectedBtn = document.getElementById('mergeSelectedBtn');
    const downloadReportBtn = document.getElementById('downloadReportBtn');
    
    // ×“×™××œ×•×’ ××™×–×•×’
    const mergeDialog = document.getElementById('mergeDialog');
    const mergeDialogOverlay = document.getElementById('mergeDialogOverlay');
    const closeMergeDialog = document.getElementById('closeMergeDialog');
    const startMergeBtn = document.getElementById('startMergeBtn');
    const cancelMergeBtn = document.getElementById('cancelMergeBtn');
    
    // ×”×’×“×¨×•×ª
    const settingsForm = document.getElementById('settingsForm');
    const saveSettingsBtn = document.getElementById('saveSettingsBtn');
    const resetSettingsBtn = document.getElementById('resetSettingsBtn');
    
    // × ×™×•×•×˜ ×‘×™×Ÿ ×œ×©×•× ×™×•×ª
    const tabLinks = document.querySelectorAll('.main-nav a');
    const tabContents = document.querySelectorAll('.tab-content');
    
    // × ×ª×•× ×™× ×¤× ×™××™×™×
    let selectedFiles = [];
    let analyzedProjects = [];
    let selectedProjects = [];
    
    // ××ª×—×•×œ ×”××¤×œ×™×§×¦×™×”
    initApp();
    
    function initApp() {
        // ×˜×¢×™× ×ª ×”×’×“×¨×•×ª
        loadSettings();
        
        // ×”×’×“×¨×ª ××™×¨×•×¢×™×
        setupEventListeners();
        
        // ×˜×¢×™× ×ª ××™×“×¢ ××—×¡×•×Ÿ
        loadStoredData();
        
        // ×× ×™××¦×™×™×ª ×˜×¢×™× ×”
        showWelcomeAnimation();
        
        console.log('×××—×“ ×§×•×“ ×—×›× Pro 2.0 ××•×ª×—×œ ×‘×”×¦×œ×—×”');
    }
    
    /**
     * ×˜×¢×™× ×ª ×”×’×“×¨×•×ª ××”××—×¡×•×Ÿ ×”××§×•××™
     */
    function loadSettings() {
        const settings = JSON.parse(localStorage.getItem('smartCodeMergerSettings')) || getDefaultSettings();
        
        document.getElementById('outputPath').value = settings.outputPath;
        document.getElementById('maxFileSize').value = settings.maxFileSize;
        document.getElementById('threadCount').value = settings.threadCount;
        document.getElementById('enableSecurity').checked = settings.enableSecurity;
        document.getElementById('securityLevel').value = settings.securityLevel;
        document.getElementById('enableRemoteStorage').checked = settings.enableRemoteStorage;
        document.getElementById('remoteStorageType').disabled = !settings.enableRemoteStorage;
        document.getElementById('remoteStorageType').value = settings.remoteStorageType;
        
        console.log('×”×’×“×¨×•×ª × ×˜×¢× ×•');
    }
    
    /**
     * ×”×—×–×¨×ª ×”×’×“×¨×•×ª ×‘×¨×™×¨×ª ××—×“×œ
     */
    function getDefaultSettings() {
        return {
            outputPath: '',
            maxFileSize: 100,
            threadCount: 4,
            enableSecurity: true,
            securityLevel: 'medium',
            enableRemoteStorage: false,
            remoteStorageType: 'sftp'
        };
    }
    
    /**
     * ×©××™×¨×ª ×”×’×“×¨×•×ª ×‘××—×¡×•×Ÿ ×”××§×•××™
     */
    function saveSettings() {
        const settings = {
            outputPath: document.getElementById('outputPath').value,
            maxFileSize: parseInt(document.getElementById('maxFileSize').value),
            threadCount: parseInt(document.getElementById('threadCount').value),
            enableSecurity: document.getElementById('enableSecurity').checked,
            securityLevel: document.getElementById('securityLevel').value,
            enableRemoteStorage: document.getElementById('enableRemoteStorage').checked,
            remoteStorageType: document.getElementById('remoteStorageType').value
        };
        
        localStorage.setItem('smartCodeMergerSettings', JSON.stringify(settings));
        console.log('×”×’×“×¨×•×ª × ×©××¨×•');
    }
    
    /**
     * ×˜×¢×™× ×ª × ×ª×•× ×™× ××”××—×¡×•×Ÿ ×”××§×•××™
     */
    function loadStoredData() {
        // ×˜×¢×™× ×ª ×”×™×¡×˜×•×¨×™×™×ª ×¤×¨×•×™×§×˜×™×
        const projectsHistory = document.getElementById('projectsHistory');
        const storedProjects = JSON.parse(localStorage.getItem('smartCodeMergerProjects')) || [];
        
        if (storedProjects.length > 0) {
            projectsHistory.innerHTML = '';
            storedProjects.forEach(project => {
                const projectElement = createProjectElement(project, true);
                projectsHistory.appendChild(projectElement);
            });
        }
        
        // ×˜×¢×™× ×ª ×“×•×—×•×ª ××‘×˜×—×”
        const securityReports = document.getElementById('securityReports');
        const storedReports = JSON.parse(localStorage.getItem('smartCodeMergerSecurityReports')) || [];
        
        if (storedReports.length > 0) {
            securityReports.innerHTML = '';
            storedReports.forEach(report => {
                const reportElement = createReportElement(report);
                securityReports.appendChild(reportElement);
            });
        }
    }
    
    /**
     * ×× ×™××¦×™×™×ª ×‘×¨×•×›×™× ×”×‘××™×
     */
    function showWelcomeAnimation() {
        const welcomeCard = document.querySelector('#home .card');
        welcomeCard.classList.add('fade-in');
        
        setTimeout(() => {
            welcomeCard.classList.remove('fade-in');
        }, 1000);
    }
    
    /**
     * ×”×’×“×¨×ª ×××–×™× ×™ ××™×¨×•×¢×™×
     */
    function setupEventListeners() {
        // × ×™×•×•×˜ ×‘×™×Ÿ ×œ×©×•× ×™×•×ª
        tabLinks.forEach(link => {
            link.addEventListener('click', function(e) {
                e.preventDefault();
                const tabId = this.getAttribute('data-tab');
                
                // ×”×¡×¨×ª ××—×œ×§×” ×¤×¢×™×œ×” ××›×œ ×”×œ×©×•× ×™×•×ª
                tabLinks.forEach(innerLink => {
                    innerLink.classList.remove('active');
                });
                
                // ×”×¡×ª×¨×ª ×›×œ ×”×ª×•×›×Ÿ
                tabContents.forEach(content => {
                    content.classList.remove('active');
                });
                
                // ×”×•×¡×¤×ª ××—×œ×§×” ×¤×¢×™×œ×” ×œ×œ×©×•× ×™×ª ×©× ×‘×—×¨×”
                this.classList.add('active');
                document.getElementById(tabId).classList.add('active');
            });
        });
        
        // ×‘×—×™×¨×ª ×§×‘×¦×™×
        fileInput.addEventListener('change', handleFileSelection);
        
        // ×’×¨×™×¨×ª ×§×‘×¦×™×
        dropZone.addEventListener('dragover', function(e) {
            e.preventDefault();
            dropZone.classList.add('dragover');
        });
        
        dropZone.addEventListener('dragleave', function() {
            dropZone.classList.remove('dragover');
        });
        
        dropZone.addEventListener('drop', function(e) {
            e.preventDefault();
            dropZone.classList.remove('dragover');
            
            if (e.dataTransfer.files.length > 0) {
                handleFiles(e.dataTransfer.files);
            }
        });
        
        dropZone.addEventListener('click', function() {
            fileInput.click();
        });
        
        // ×›×¤×ª×•×¨×™ ×¤×¢×•×œ×”
        analyzeBtn.addEventListener('click', analyzeFiles);
        clearBtn.addEventListener('click', clearFiles);
        mergeSelectedBtn.addEventListener('click', openMergeDialog);
        downloadReportBtn.addEventListener('click', downloadReport);
        
        // ×“×™××œ×•×’ ××™×–×•×’
        closeMergeDialog.addEventListener('click', closeMergeDialogHandler);
        cancelMergeBtn.addEventListener('click', closeMergeDialogHandler);
        startMergeBtn.addEventListener('click', mergeSelectedProjects);
        
        // ×œ×—×™×¦×” ××—×•×¥ ×œ×“×™××œ×•×’
        mergeDialogOverlay.addEventListener('click', function(e) {
            if (e.target === mergeDialogOverlay) {
                closeMergeDialogHandler();
            }
        });
        
        // ×˜×•×¤×¡ ×”×’×“×¨×•×ª
        settingsForm.addEventListener('submit', function(e) {
            e.preventDefault();
            
            const saveBtn = document.getElementById('saveSettingsBtn');
            saveBtn.classList.add('loading');
            saveBtn.disabled = true;
            
            // ×”×©×”×™×™×” ××œ××›×•×ª×™×ª ×œ×”×“×’××ª ×”×× ×™××¦×™×”
            setTimeout(() => {
                saveSettings();
                saveBtn.classList.remove('loading');
                saveBtn.disabled = false;
                
                // ×”×•×“×¢×ª ×”×¦×œ×—×”
                showToast('×”×”×’×“×¨×•×ª × ×©××¨×• ×‘×”×¦×œ×—×”', 'success');
            }, 1000);
        });
        
        // ××¤×¡ ×”×’×“×¨×•×ª
        resetSettingsBtn.addEventListener('click', function() {
            if (confirm('×”×× ××ª×” ×‘×˜×•×— ×©×‘×¨×¦×•× ×š ×œ××¤×¡ ××ª ×”×”×’×“×¨×•×ª?')) {
                localStorage.removeItem('smartCodeMergerSettings');
                loadSettings();
                showToast('×”×”×’×“×¨×•×ª ××•×¤×¡×• ×‘×”×¦×œ×—×”', 'info');
            }
        });
        
        // ×”×¤×¢×œ×ª ×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§
        document.getElementById('enableRemoteStorage').addEventListener('change', function() {
            document.getElementById('remoteStorageType').disabled = !this.checked;
        });
    }
    
    /**
     * ×˜×™×¤×•×œ ×‘×‘×—×™×¨×ª ×§×‘×¦×™×
     */
    function handleFileSelection(event) {
        if (event.target.files.length > 0) {
            handleFiles(event.target.files);
        }
    }
    
    /**
     * ×˜×™×¤×•×œ ×‘×§×‘×¦×™× ×—×“×©×™×
     */
    function handleFiles(files) {
        const zipFiles = Array.from(files).filter(file => file.name.toLowerCase().endsWith('.zip'));
        
        if (zipFiles.length === 0) {
            showToast('×× × ×‘×—×¨ ×§×‘×¦×™ ZIP ×‘×œ×‘×“', 'warning');
            return;
        }
        
        // ×”×•×¡×¤×ª ×§×‘×¦×™× ×—×“×©×™× ×œ×¨×©×™××”
        zipFiles.forEach(file => {
            if (!selectedFiles.some(existingFile => existingFile.name === file.name)) {
                selectedFiles.push(file);
            }
        });
        
        // ×¢×“×›×•×Ÿ ×ª×¦×•×’×ª ×”×¨×©×™××”
        updateSelectedFilesList();
        
        // ×”×¤×¢×œ×ª ×›×¤×ª×•×¨×™×
        analyzeBtn.disabled = selectedFiles.length === 0;
        clearBtn.disabled = selectedFiles.length === 0;
    }
    
    /**
     * ×¢×“×›×•×Ÿ ×¨×©×™××ª ×”×§×‘×¦×™× ×©× ×‘×—×¨×•
     */
    function updateSelectedFilesList() {
        selectedFilesList.innerHTML = '';
        
        if (selectedFiles.length === 0) {
            selectedFilesList.innerHTML = '<p class="empty-state">×œ× × ×‘×—×¨×• ×§×‘×¦×™×</p>';
            return;
        }
        
        selectedFiles.forEach((file, index) => {
            const fileItem = document.createElement('div');
            fileItem.className = 'selected-file-item';
            
            // ×”××¨×ª ×’×•×“×œ ×”×§×•×‘×¥ ×œ×™×—×™×“×•×ª ×§×¨×™××•×ª
            const fileSizeFormatted = formatFileSize(file.size);
            
            fileItem.innerHTML = `
                <span class="selected-file-icon">
                    <i class="fas fa-file-archive"></i>
                </span>
                <span class="selected-file-name">${file.name}</span>
                <span class="selected-file-size">${fileSizeFormatted}</span>
                <button class="selected-file-remove" data-index="${index}">Ã—</button>
            `;
            
            selectedFilesList.appendChild(fileItem);
            
            // ×”×•×¡×¤×ª ×××–×™×Ÿ ×œ×›×¤×ª×•×¨ ×”×¡×¨×”
            const removeButton = fileItem.querySelector('.selected-file-remove');
            removeButton.addEventListener('click', function() {
                const fileIndex = parseInt(this.getAttribute('data-index'));
                selectedFiles.splice(fileIndex, 1);
                updateSelectedFilesList();
                
                // ×¢×“×›×•×Ÿ ××¦×‘ ×›×¤×ª×•×¨×™×
                analyzeBtn.disabled = selectedFiles.length === 0;
                clearBtn.disabled = selectedFiles.length === 0;
            });
        });
    }
    
    /**
     * × ×™×ª×•×— ×§×‘×¦×™× ×©× ×‘×—×¨×•
     */
    function analyzeFiles() {
        // ×”×•×¡×¤×ª ×× ×™××¦×™×™×ª ×˜×¢×™× ×” ×œ×›×¤×ª×•×¨
        analyzeBtn.classList.add('loading');
        analyzeBtn.disabled = true;
        
        // ×× ×™××¦×™×™×ª ×˜×¢×™× ×” ××§×¨××™×ª
        setTimeout(() => {
            // ×¡×™××•×œ×¦×™×” ×œ× ×™×ª×•×— ×§×‘×¦×™×
            analyzedProjects = generateMockProjects();
            
            // ×¢×“×›×•×Ÿ ×ª×¦×•×’×”
            updateAnalysisResults(analyzedProjects);
            
            // ×”×¦×’×ª ×ª×•×¦××•×ª ×”× ×™×ª×•×—
            analysisResults.style.display = 'block';
            analysisResults.classList.add('fade-in');
            
            // ×¢×“×›×•×Ÿ ×›×¤×ª×•×¨×™×
            analyzeBtn.classList.remove('loading');
            analyzeBtn.disabled = false;
            
            // ×’×œ×™×œ×” ×œ×ª×•×¦××•×ª
            analysisResults.scrollIntoView({ behavior: 'smooth' });
            
            // ×”×•×“×¢×ª ×¡×™×•×
            showToast('× ×™×ª×•×— ×”×§×‘×¦×™× ×”×•×©×œ× ×‘×”×¦×œ×—×”', 'success');
        }, 2000);
    }
    
    /**
     * × ×™×§×•×™ ×§×‘×¦×™× ×©× ×‘×—×¨×•
     */
    function clearFiles() {
        selectedFiles = [];
        updateSelectedFilesList();
        
        // ×”×¡×ª×¨×ª ×ª×•×¦××•×ª × ×™×ª×•×—
        analysisResults.style.display = 'none';
        
        // ×¢×“×›×•×Ÿ ×›×¤×ª×•×¨×™×
        analyzeBtn.disabled = true;
        clearBtn.disabled = true;
        
        // ××™×¤×•×¡ ×‘×—×™×¨×ª ×¤×¨×•×™×§×˜×™×
        selectedProjects = [];
        updateMergeButtonState();
    }
    
    /**
     * ×¢×“×›×•×Ÿ ×ª×•×¦××•×ª × ×™×ª×•×—
     */
    function updateAnalysisResults(projects) {
        // ×¢×“×›×•×Ÿ ××•× ×™×
        let totalFiles = 0;
        let totalSecurityIssues = 0;
        
        projects.forEach(project => {
            totalFiles += project.files.length;
            totalSecurityIssues += project.securityIssues.length;
        });
        
        projectsCount.textContent = projects.length;
        filesCount.textContent = totalFiles;
        securityIssuesCount.textContent = totalSecurityIssues;
        
        // ×× ×™××¦×™×™×ª ×¢×“×›×•×Ÿ ××•× ×™×
        [projectsCount, filesCount, securityIssuesCount].forEach(element => {
            element.classList.add('pulse');
            setTimeout(() => element.classList.remove('pulse'), 1000);
        });
        
        // ×™×¦×™×¨×ª ×¨×©×™××ª ×¤×¨×•×™×§×˜×™×
        projectsList.innerHTML = '';
        if (projects.length === 0) {
            projectsList.innerHTML = '<p class="empty-state">×œ× ×–×•×”×• ×¤×¨×•×™×§×˜×™×</p>';
            return;
        }
        
        projects.forEach(project => {
            const projectElement = createProjectElement(project);
            projectsList.appendChild(projectElement);
        });
        
        // ×¢×“×›×•×Ÿ ××¦×‘ ×›×¤×ª×•×¨ ××™×–×•×’
        updateMergeButtonState();
    }
    
    /**
     * ×™×¦×™×¨×ª ××œ×× ×˜ ×¤×¨×•×™×§×˜ ×œ×ª×¦×•×’×”
     */
    function createProjectElement(project, isHistory = false) {
        const projectElement = document.createElement('div');
        projectElement.className = 'project-item';
        projectElement.dataset.projectId = project.id;
        
        const headerHtml = `
            <div class="project-header">
                ${!isHistory ? `<input type="checkbox" class="project-checkbox" data-project-id="${project.id}">` : ''}
                <span class="project-name">${project.name}</span>
                <button class="project-toggle">â–¼</button>
            </div>
        `;
        
        let filesHtml = '';
        if (project.files && project.files.length > 0) {
            filesHtml = '<div class="project-files">';
            project.files.forEach(file => {
                filesHtml += `<div class="project-file">${file.path}</div>`;
            });
            filesHtml += '</div>';
        }
        
        let securityHtml = '';
        if (project.securityIssues && project.securityIssues.length > 0) {
            securityHtml = `
                <div class="security-issues">
                    <h4>×‘×¢×™×•×ª ××‘×˜×—×” (${project.securityIssues.length})</h4>
                    <ul>
                        ${project.securityIssues.map(issue => `<li>${issue.description}</li>`).join('')}
                    </ul>
                </div>
            `;
        }
        
        const detailsHtml = `
            <div class="project-details">
                <div class="project-stats">
                    <div class="project-stat">
                        <div class="project-stat-label">×¡×•×’ ×¤×¨×•×™×§×˜</div>
                        <div class="project-stat-value">${project.type}</div>
                    </div>
                    <div class="project-stat">
                        <div class="project-stat-label">××¡×¤×¨ ×§×‘×¦×™×</div>
                        <div class="project-stat-value">${project.files ? project.files.length : 0}</div>
                    </div>
                    <div class="project-stat">
                        <div class="project-stat-label">×©×¤×•×ª ×¢×™×§×¨×™×•×ª</div>
                        <div class="project-stat-value">${project.languages.join(', ')}</div>
                    </div>
                </div>
                ${filesHtml}
                ${securityHtml}
                ${isHistory ? `
                    <div class="project-history-info">
                        <div class="project-stat">
                            <div class="project-stat-label">×ª××¨×™×š ×™×¦×™×¨×”</div>
                            <div class="project-stat-value">${project.createdAt}</div>
                        </div>
                        <div class="project-stat">
                            <div class="project-stat-label">× ×ª×™×‘</div>
                            <div class="project-stat-value">${project.outputPath}</div>
                        </div>
                    </div>
                ` : ''}
            </div>
        `;
        
        projectElement.innerHTML = headerHtml + detailsHtml;
        
        // ×”×•×¡×¤×ª ×××–×™× ×™ ××™×¨×•×¢×™×
        const toggleButton = projectElement.querySelector('.project-toggle');
        const projectDetails = projectElement.querySelector('.project-details');
        
        toggleButton.addEventListener('click', function() {
            projectDetails.classList.toggle('visible');
            toggleButton.classList.toggle('expanded');
        });
        
        // ×”×•×¡×¤×ª ×××–×™×Ÿ ×œ×ª×™×‘×ª ×¡×™××•×Ÿ
        if (!isHistory) {
            const checkbox = projectElement.querySelector('.project-checkbox');
            checkbox.addEventListener('change', function() {
                const projectId = this.getAttribute('data-project-id');
                
                if (this.checked) {
                    // ×”×•×¡×¤×” ×œ×¤×¨×•×™×§×˜×™× ×©× ×‘×—×¨×•
                    if (!selectedProjects.includes(projectId)) {
                        selectedProjects.push(projectId);
                    }
                } else {
                    // ×”×¡×¨×” ××”×¤×¨×•×™×§×˜×™× ×©× ×‘×—×¨×•
                    const index = selectedProjects.indexOf(projectId);
                    if (index > -1) {
                        selectedProjects.splice(index, 1);
                    }
                }
                
                // ×¢×“×›×•×Ÿ ××¦×‘ ×›×¤×ª×•×¨ ××™×–×•×’
                updateMergeButtonState();
            });
        }
        
        return projectElement;
    }
    
    /**
     * ×™×¦×™×¨×ª ××œ×× ×˜ ×“×•×— ××‘×˜×—×” ×œ×ª×¦×•×’×”
     */
    function createReportElement(report) {
        const reportElement = document.createElement('div');
        reportElement.className = 'security-report-item';
        
        reportElement.innerHTML = `
            <div class="report-header">
                <span class="report-name">${report.name}</span>
                <span class="report-date">${report.date}</span>
            </div>
            <div class="report-summary">
                <div class="report-stat">
                    <div class="report-stat-label">×¡×”"×› ×‘×¢×™×•×ª</div>
                    <div class="report-stat-value">${report.totalIssues}</div>
                </div>
                <div class="report-stat">
                    <div class="report-stat-label">×‘×¢×™×•×ª ×—××•×¨×•×ª</div>
                    <div class="report-stat-value">${report.highSeverityIssues}</div>
                </div>
            </div>
            <div class="report-actions">
                <button class="btn btn-small">×¦×¤×” ×‘×“×•×— ×”××œ×</button>
                <button class="btn btn-small">×”×•×¨×“ ×›-PDF</button>
            </div>
        `;
        
        return reportElement;
    }
    
    /**
     * ×¢×“×›×•×Ÿ ××¦×‘ ×›×¤×ª×•×¨ ××™×–×•×’
     */
    function updateMergeButtonState() {
        mergeSelectedBtn.disabled = selectedProjects.length === 0;
        downloadReportBtn.disabled = analyzedProjects.length === 0;
    }
    
    /**
     * ×¤×ª×™×—×ª ×“×™××œ×•×’ ××™×–×•×’
     */
    function openMergeDialog() {
        // ×”×¦×’×ª ×“×™××œ×•×’
        mergeDialogOverlay.style.display = 'flex';
        
        // ×× ×™×© × ×ª×™×‘ ×¤×œ×˜ ××•×’×“×¨ ×‘×”×’×“×¨×•×ª, ×”×©×ª××© ×‘×•
        const settings = JSON.parse(localStorage.getItem('smartCodeMergerSettings')) || getDefaultSettings();
        if (settings.outputPath) {
            document.getElementById('mergeOutputPath').value = settings.outputPath;
        }
    }
    
    /**
     * ×¡×’×™×¨×ª ×“×™××œ×•×’ ××™×–×•×’
     */
    function closeMergeDialogHandler() {
        mergeDialogOverlay.style.display = 'none';
    }
    
    /**
     * ××™×–×•×’ ×¤×¨×•×™×§×˜×™× × ×‘×—×¨×™×
     */
    function mergeSelectedProjects() {
        // ×”×•×¡×¤×ª ×× ×™××¦×™×™×ª ×˜×¢×™× ×” ×œ×›×¤×ª×•×¨
        startMergeBtn.classList.add('loading');
        startMergeBtn.disabled = true;
        
        // ×§×‘×œ×ª ×”×’×“×¨×•×ª ××™×–×•×’
        const outputPath = document.getElementById('mergeOutputPath').value;
        const createZip = document.getElementById('createZip').checked;
        const runSecurityScan = document.getElementById('runSecurityScan').checked;
        
        // ×× ××™×Ÿ × ×ª×™×‘ ×¤×œ×˜, ×”×¦×’ ×©×’×™××”
        if (!outputPath) {
            showToast('×× × ×‘×—×¨ × ×ª×™×‘ ×¤×œ×˜ ×œ××™×–×•×’', 'error');
            startMergeBtn.classList.remove('loading');
            startMergeBtn.disabled = false;
            return;
        }
        
        // ×× ×™××¦×™×™×ª ×˜×¢×™× ×” ××§×¨××™×ª
        setTimeout(() => {
            // ×¡×™××•×œ×¦×™×” ×œ××™×–×•×’ ×¤×¨×•×™×§×˜×™×
            const mergedProjects = generateMockMergeResult(selectedProjects);
            
            // ×©××™×¨×” ×‘×œ×•×§×œ ×¡×˜×•×¨×’'
            storeMergedProjects(mergedProjects);
            
            // ×¢×“×›×•×Ÿ ×›×¤×ª×•×¨×™×
            startMergeBtn.classList.remove('loading');
            startMergeBtn.disabled = false;
            
            // ×¡×’×™×¨×ª ×“×™××œ×•×’
            closeMergeDialogHandler();
            
            // ××™×¤×•×¡ ×‘×—×™×¨×ª ×¤×¨×•×™×§×˜×™×
            selectedProjects = [];
            
            // ×¢×“×›×•×Ÿ ×ª×¦×•×’×”
            const checkboxes = document.querySelectorAll('.project-checkbox');
            checkboxes.forEach(checkbox => {
                checkbox.checked = false;
            });
            
            // ×¢×“×›×•×Ÿ ××¦×‘ ×›×¤×ª×•×¨ ××™×–×•×’
            updateMergeButtonState();
            
            // ×”×•×“×¢×ª ×¡×™×•×
            showToast('××™×–×•×’ ×”×¤×¨×•×™×§×˜×™× ×”×•×©×œ× ×‘×”×¦×œ×—×”', 'success');
            
            // ×˜×¢×™× ×” ××—×“×© ×©×œ × ×ª×•× ×™ ×”××—×¡×•×Ÿ
            loadStoredData();
            
            // ×”×—×œ×¤×ª ×œ×©×•× ×™×ª ×œ×¤×¨×•×™×§×˜×™×
            document.querySelector('.main-nav a[data-tab="projects"]').click();
        }, 3000);
    }
    
    /**
     * ×©××™×¨×ª ×¤×¨×•×™×§×˜×™× ×©××•×–×’×• ×‘××—×¡×•×Ÿ ×”××§×•××™
     */
    function storeMergedProjects(mergedProjects) {
        // ×˜×¢×™× ×ª ×¤×¨×•×™×§×˜×™× ×§×™×™××™×
        const storedProjects = JSON.parse(localStorage.getItem('smartCodeMergerProjects')) || [];
        
        // ×”×•×¡×¤×ª ×¤×¨×•×™×§×˜×™× ×—×“×©×™×
        const updatedProjects = [...storedProjects, ...mergedProjects];
        
        // ×©××™×¨×” ×‘××—×¡×•×Ÿ
        localStorage.setItem('smartCodeMergerProjects', JSON.stringify(updatedProjects));
        
        // ×× ×”×¤×¢×œ× ×• ×¡×¨×™×§×ª ××‘×˜×—×”, ×©××•×¨ ×’× ×“×•×—×•×ª ××‘×˜×—×”
        if (document.getElementById('runSecurityScan').checked) {
            const storedReports = JSON.parse(localStorage.getItem('smartCodeMergerSecurityReports')) || [];
            
            // ×™×¦×™×¨×ª ×“×•×—×•×ª ××‘×˜×—×”
            const securityReports = mergedProjects.map(project => {
                return {
                    name: `×“×•×— ××‘×˜×—×” - ${project.name}`,
                    date: project.createdAt,
                    totalIssues: Math.floor(Math.random() * 10),
                    highSeverityIssues: Math.floor(Math.random() * 3),
                    projectId: project.id
                };
            });
            
            // ×”×•×¡×¤×ª ×“×•×—×•×ª ×—×“×©×™×
            const updatedReports = [...storedReports, ...securityReports];
            
            // ×©××™×¨×” ×‘××—×¡×•×Ÿ
            localStorage.setItem('smartCodeMergerSecurityReports', JSON.stringify(updatedReports));
        }
    }
    
    /**
     * ×”×•×¨×“×ª ×“×•×— × ×™×ª×•×—
     */
    function downloadReport() {
        // ×™×¦×™×¨×ª × ×ª×•× ×™ ×“×•×—
        const reportData = {
            timestamp: new Date().toISOString(),
            analyzedFiles: selectedFiles.map(file => file.name),
            projects: analyzedProjects
        };
        
        // ×”××¨×” ×œ××—×¨×•×–×ª JSON
        const jsonData = JSON.stringify(reportData, null, 2);
        
        // ×™×¦×™×¨×ª ×§×•×‘×¥ ×œ×”×•×¨×“×”
        const blob = new Blob([jsonData], { type: 'application/json' });
        const url = URL.createObjectURL(blob);
        
        // ×™×¦×™×¨×ª ×§×™×©×•×¨ ×”×•×¨×“×”
        const a = document.createElement('a');
        a.href = url;
        a.download = `analysis_report_${new Date().toISOString().replace(/:/g, '-')}.json`;
        document.body.appendChild(a);
        a.click();
        
        // × ×™×§×•×™
        setTimeout(() => {
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }, 100);
        
        // ×”×•×“×¢×ª ×¡×™×•×
        showToast('×”×“×•×— ×”×•×¨×“ ×‘×”×¦×œ×—×”', 'success');
    }
    
    /**
     * ×”××¨×ª ×’×•×“×œ ×§×•×‘×¥ ×œ×™×—×™×“×•×ª ×§×¨×™××•×ª
     */
    function formatFileSize(bytes) {
        if (bytes === 0) return '0 B';
        
        const units = ['B', 'KB', 'MB', 'GB', 'TB'];
        const i = Math.floor(Math.log(bytes) / Math.log(1024));
        
        return parseFloat((bytes / Math.pow(1024, i)).toFixed(2)) + ' ' + units[i];
    }
    
    /**
     * ×”×¦×’×ª ×”×•×“×¢×ª Toast
     */
    function showToast(message, type = 'info') {
        // ×‘×“×™×§×” ×× ×™×© ×›×‘×¨ ××œ×× ×˜ toast
        let toast = document.querySelector('.toast');
        
        if (!toast) {
            // ×™×¦×™×¨×ª ××œ×× ×˜ toast
            toast = document.createElement('div');
            toast.className = 'toast';
            document.body.appendChild(toast);
            
            // ×”×•×¡×¤×ª ×¡×’× ×•× ×•×ª
            const style = document.createElement('style');
            style.textContent = `
                .toast {
                    position: fixed;
                    bottom: 20px;
                    left: 50%;
                    transform: translateX(-50%);
                    background-color: var(--card-color);
                    color: var(--text-color);
                    padding: 10px 20px;
                    border-radius: 4px;
                    box-shadow: var(--shadow-medium);
                    z-index: 1000;
                    font-size: 14px;
                    opacity: 0;
                    transition: opacity 0.3s ease-in-out;
                }
                
                .toast.show {
                    opacity: 1;
                }
                
                .toast.info {
                    border-right: 4px solid var(--info-color);
                }
                
                .toast.success {
                    border-right: 4px solid var(--success-color);
                }
                
                .toast.warning {
                    border-right: 4px solid var(--warning-color);
                }
                
                .toast.error {
                    border-right: 4px solid var(--error-color);
                }
            `;
            document.head.appendChild(style);
        }
        
        // ×”×’×“×¨×ª ×ª×•×›×Ÿ ×•×¡×•×’
        toast.textContent = message;
        toast.className = `toast ${type}`;
        
        // ×”×¦×’×ª ×”×”×•×“×¢×”
        setTimeout(() => {
            toast.classList.add('show');
        }, 10);
        
        // ×”×¡×ª×¨×ª ×”×”×•×“×¢×” ×œ××—×¨ ×–××Ÿ ××•×’×“×¨
        setTimeout(() => {
            toast.classList.remove('show');
        }, 3000);
    }
    
    /**
     * ×™×¦×™×¨×ª × ×ª×•× ×™ ×¤×¨×•×™×§×˜×™× ××“×•××™× ×œ×¦×•×¨×›×™ ×”×“×’××”
     */
    function generateMockProjects() {
        const projectTypes = ['Node.js', 'Python', 'Java', 'React', 'Angular', 'Django', 'Flask', 'Spring Boot'];
        const languagesList = [
            ['JavaScript', 'HTML', 'CSS'], 
            ['Python', 'HTML', 'CSS'], 
            ['Java', 'XML'], 
            ['JavaScript', 'JSX', 'CSS'], 
            ['TypeScript', 'HTML', 'CSS'],
            ['Python', 'HTML', 'JavaScript'],
            ['Python', 'HTML', 'CSS'],
            ['Java', 'XML', 'SQL']
        ];
        
        const projects = [];
        const numProjects = Math.floor(Math.random() * 3) + 2; // 2-4 ×¤×¨×•×™×§×˜×™×
        
        for (let i = 0; i < numProjects; i++) {
            const typeIndex = Math.floor(Math.random() * projectTypes.length);
            const type = projectTypes[typeIndex];
            const languages = languagesList[typeIndex];
            
            // ×™×¦×™×¨×ª ×©× ×¤×¨×•×™×§×˜ ××§×¨××™
            const projectName = `${type}-project-${Math.floor(Math.random() * 1000)}`;
            
            // ×™×¦×™×¨×ª ×§×‘×¦×™× ××§×¨××™×™×
            const files = [];
            const numFiles = Math.floor(Math.random() * 20) + 10; // 10-30 ×§×‘×¦×™×
            
            for (let j = 0; j < numFiles; j++) {
                let extension;
                
                // ×‘×—×™×¨×ª ×¡×™×•××ª ×§×•×‘×¥ ×œ×¤×™ ×©×¤×”
                if (languages.includes('JavaScript') || languages.includes('TypeScript')) {
                    extension = Math.random() > 0.5 ? 
                        (languages.includes('TypeScript') ? '.ts' : '.js') : 
                        (Math.random() > 0.5 ? '.html' : '.css');
                } else if (languages.includes('Python')) {
                    extension = Math.random() > 0.6 ? '.py' : (Math.random() > 0.5 ? '.html' : '.css');
                } else if (languages.includes('Java')) {
                    extension = Math.random() > 0.7 ? '.java' : '.xml';
                }
                
                // ×™×¦×™×¨×ª × ×ª×™×‘ ×§×•×‘×¥ ××§×¨××™
                let filePath;
                if (Math.random() > 0.7) {
                    // ×§×•×‘×¥ ×‘×ª×™×§×™×™×” ××©× ×™×ª
                    const subdir = ['src', 'lib', 'modules', 'components', 'utils', 'tests'][Math.floor(Math.random() * 6)];
                    filePath = `${subdir}/${Math.random().toString(36).substring(7)}${extension}`;
                } else {
                    // ×§×•×‘×¥ ×‘×ª×™×§×™×™×” ×”×¨××©×™×ª
                    filePath = `${Math.random().toString(36).substring(7)}${extension}`;
                }
                
                files.push({
                    path: filePath,
                    size: Math.floor(Math.random() * 100000) + 1000 // 1KB - 100KB
                });
            }
            
            // ×™×¦×™×¨×ª ×‘×¢×™×•×ª ××‘×˜×—×” ××§×¨××™×•×ª
            const securityIssues = [];
            const numIssues = Math.floor(Math.random() * 5); // 0-4 ×‘×¢×™×•×ª
            
            const issueTypes = [
                '×—×©×™×¤×ª ××™×“×¢ ×¨×’×™×©',
                'SQL Injection ××¤×©×¨×™',
                '×—×•×œ×©×ª Cross-Site Scripting (XSS)',
                '×©×™××•×© ×‘×¡×¤×¨×™×•×ª ××™×•×©× ×•×ª',
                '×¡×™×¡××” ×§×‘×•×¢×” ×‘×§×•×“',
                '×—×•×œ×©×ª Cross-Site Request Forgery (CSRF)',
                '×”×¨×©××•×ª ×§×‘×¦×™× ×œ× ×××•×‘×˜×—×•×ª',
                '×˜×™×¤×•×œ ×œ× ×××•×‘×˜×— ×‘× ×ª×•× ×™ ×§×œ×˜'
            ];
            
            for (let j = 0; j < numIssues; j++) {
                const issueType = issueTypes[Math.floor(Math.random() * issueTypes.length)];
                const severity = ['× ××•×›×”', '×‘×™× ×•× ×™×ª', '×’×‘×•×”×”'][Math.floor(Math.random() * 3)];
                
                securityIssues.push({
                    description: `${issueType} - ×—×•××¨×” ${severity}`,
                    severity: severity,
                    file: files[Math.floor(Math.random() * files.length)].path
                });
            }
            
            projects.push({
                id: `project-${i}-${Date.now()}`,
                name: projectName,
                type: type,
                languages: languages,
                files: files,
                securityIssues: securityIssues
            });
        }
        
        return projects;
    }
    
    /**
     * ×™×¦×™×¨×ª ×ª×•×¦××•×ª ××™×–×•×’ ××“×•××•×ª
     */
    function generateMockMergeResult(selectedProjectIds) {
        const mergedProjects = [];
        
        // ×™×¦×™×¨×ª ×ª××¨×™×š × ×•×›×—×™ ××¤×•×¨××˜
        const now = new Date();
        const formattedDate = now.toLocaleDateString('he-IL') + ' ' + now.toLocaleTimeString('he-IL');
        
        // ××¦×™××ª × ×ª×™×‘ ×”×¤×œ×˜
        const outputPath = document.getElementById('mergeOutputPath').value || '/×”××™×§×•×/×©×œ×š/projects/';
        
        // ×™×¦×™×¨×ª ×¤×¨×•×™×§×˜×™× ×××•×–×’×™×
        for (const projectId of selectedProjectIds) {
            // ×—×™×¤×•×© ××™×“×¢ ×¢×œ ×”×¤×¨×•×™×§×˜ ×”××§×•×¨×™
            const originalProject = analyzedProjects.find(p => p.id === projectId);
            
            if (originalProject) {
                mergedProjects.push({
                    id: `merged-${projectId}-${Date.now()}`,
                    name: originalProject.name,
                    type: originalProject.type,
                    languages: originalProject.languages,
                    createdAt: formattedDate,
                    outputPath: outputPath + originalProject.name,
                    files: originalProject.files,
                    securityIssues: originalProject.securityIssues
                });
            }
        }
        
        return mergedProjects;
    }
});
APP_JS
# ×™×¦×™×¨×ª ×§×•×‘×¥ Service Worker ×¢×‘×•×¨ PWA
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ Service Worker..."
mkdir -p "$BASE_DIR/pwa"

cat > "$BASE_DIR/pwa/service-worker.js" << 'SERVICE_WORKER_JS'
/**
 * ×××—×“ ×§×•×“ ×—×›× Pro 2.0
 * Service Worker ×¢×‘×•×¨ PWA
 * 
 * ××—×‘×¨: Claude AI
 * ×’×¨×¡×”: 1.0.0
 * ×ª××¨×™×š: ×××™ 2025
 */

const CACHE_NAME = 'smart-code-merger-pro-cache-v1';
const ASSETS_TO_CACHE = [
    '/',
    '/index.html',
    '/assets/css/style.css',
    '/assets/js/app.js',
    '/assets/images/logo.svg',
    '/assets/images/favicon.png',
    '/assets/images/upload-icon.svg',
    '/assets/images/project-icon.svg',
    '/assets/images/file-icon.svg',
    '/assets/images/security-icon.svg',
    '/pwa/manifest.json'
];

// ×”×ª×§× ×ª Service Worker
self.addEventListener('install', event => {
    event.waitUntil(
        caches.open(CACHE_NAME)
            .then(cache => {
                console.log('×¤×ª×™×—×ª ××˜××•×Ÿ');
                return cache.addAll(ASSETS_TO_CACHE);
            })
            .then(() => self.skipWaiting())
    );
});

// ×”×¤×¢×œ×ª Service Worker
self.addEventListener('activate', event => {
    const cacheWhitelist = [CACHE_NAME];
    
    event.waitUntil(
        caches.keys().then(cacheNames => {
            return Promise.all(
                cacheNames.map(cacheName => {
                    if (cacheWhitelist.indexOf(cacheName) === -1) {
                        console.log('××•×—×§ ××˜××•×Ÿ ×™×©×Ÿ:', cacheName);
                        return caches.delete(cacheName);
                    }
                })
            );
        }).then(() => self.clients.claim())
    );
});

// ×˜×™×¤×•×œ ×‘×‘×§×©×•×ª ×¨×©×ª
self.addEventListener('fetch', event => {
    event.respondWith(
        caches.match(event.request)
            .then(response => {
                // ×”×—×–×¨×ª ×ª×©×•×‘×” ××”××˜××•×Ÿ ×× ×§×™×™××ª
                if (response) {
                    return response;
                }
                
                // ××—×¨×ª, ×¤× ×™×™×” ×œ×¨×©×ª
                return fetch(event.request)
                    .then(response => {
                        // ×‘×“×™×§×” ×©×”×ª×©×•×‘×” ×ª×§×™× ×”
                        if (!response || response.status !== 200 || response.type !== 'basic') {
                            return response;
                        }
                        
                        // ×©×›×¤×•×œ ×”×ª×©×•×‘×” (×›×™ ××™ ××¤×©×¨ ×œ×”×©×ª××© ×‘×” ×¤×¢××™×™×)
                        const responseToCache = response.clone();
                        
                        // ×©××™×¨×” ×‘××˜××•×Ÿ
                        caches.open(CACHE_NAME)
                            .then(cache => {
                                cache.put(event.request, responseToCache);
                            });
                        
                        return response;
                    });
            })
    );
});
SERVICE_WORKER_JS

# ×™×¦×™×¨×ª ×§×•×‘×¥ Manifest ×¢×‘×•×¨ PWA
cat > "$BASE_DIR/pwa/manifest.json" << 'MANIFEST_JSON'
{
    "name": "×××—×“ ×§×•×“ ×—×›× Pro",
    "short_name": "×§×•×“ ×—×›× Pro",
    "description": "×›×œ×™ ××ª×§×“× ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP",
    "start_url": "/index.html",
    "display": "standalone",
    "background_color": "#f5f5f5",
    "theme_color": "#2196f3",
    "orientation": "any",
    "icons": [
        {
            "src": "/assets/images/icon-72x72.png",
            "sizes": "72x72",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-96x96.png",
            "sizes": "96x96",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-128x128.png",
            "sizes": "128x128",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-144x144.png",
            "sizes": "144x144",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-152x152.png",
            "sizes": "152x152",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-192x192.png",
            "sizes": "192x192",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-384x384.png",
            "sizes": "384x384",
            "type": "image/png"
        },
        {
            "src": "/assets/images/icon-512x512.png",
            "sizes": "512x512",
            "type": "image/png"
        }
    ]
}
MANIFEST_JSON

# ×™×¦×™×¨×ª ×ª×™×§×™×™×ª ×ª××•× ×•×ª
echo "ğŸ“ ×™×•×¦×¨ ×§×‘×¦×™ SVG ×•××™×™×§×•× ×™×..."
mkdir -p "$BASE_DIR/assets/images"

# ×œ×•×’×•
cat > "$BASE_DIR/assets/images/logo.svg" << 'LOGO_SVG'
<svg xmlns="http://www.w3.org/2000/svg" width="240" height="60" viewBox="0 0 240 60">
  <rect width="240" height="60" rx="8" fill="#1976d2" />
  <path d="M30,15 L50,15 L50,45 L30,45 Z" fill="#ffffff" />
  <path d="M10,15 L25,15 L25,45 L10,45 Z" fill="#bbdefb" />
  <path d="M55,15 L70,15 L70,45 L55,45 Z" fill="#bbdefb" />
  <path d="M75,20 L80,15 L95,30 L80,45 L75,40 L85,30 L75,20 Z" fill="#ffffff" />
  <text x="110" y="35" font-family="Arial" font-size="16" font-weight="bold" fill="#ffffff">×××—×“ ×§×•×“ ×—×›× Pro</text>
</svg>
LOGO_SVG

# ××™×™×§×•×Ÿ ×”×¢×œ××”
cat > "$BASE_DIR/assets/images/upload-icon.svg" << 'UPLOAD_ICON_SVG'
<svg xmlns="http://www.w3.org/2000/svg" width="64" height="64" viewBox="0 0 64 64">
  <circle cx="32" cy="32" r="30" fill="#bbdefb" />
  <path d="M32,12 L44,24 L36,24 L36,44 L28,44 L28,24 L20,24 L32,12 Z" fill="#1976d2" />
  <path d="M16,48 L48,48 L48,52 L16,52 Z" fill="#1976d2" />
</svg>
UPLOAD_ICON_SVG

# ××™×™×§×•×Ÿ ×¤×¨×•×™×§×˜
cat > "$BASE_DIR/assets/images/project-icon.svg" << 'PROJECT_ICON_SVG'
<svg xmlns="http://www.w3.org/2000/svg" width="64" height="64" viewBox="0 0 64 64">
  <rect x="8" y="12" width="48" height="40" rx="4" fill="#bbdefb" />
  <rect x="16" y="20" width="32" height="8" rx="2" fill="#1976d2" />
  <rect x="16" y="32" width="32" height="4" rx="1" fill="#1976d2" />
  <rect x="16" y="40" width="20" height="4" rx="1" fill="#1976d2" />
</svg>
PROJECT_ICON_SVG

# ××™×™×§×•×Ÿ ×§×•×‘×¥
cat > "$BASE_DIR/assets/images/file-icon.svg" << 'FILE_ICON_SVG'
<svg xmlns="http://www.w3.org/2000/svg" width="64" height="64" viewBox="0 0 64 64">
  <path d="M16,8 L38,8 L48,18 L48,56 L16,56 Z" fill="#bbdefb" />
  <path d="M38,8 L38,18 L48,18 Z" fill="#1976d2" />
  <rect x="22" y="28" width="20" height="2" rx="1" fill="#1976d2" />
  <rect x="22" y="34" width="20" height="2" rx="1" fill="#1976d2" />
  <rect x="22" y="40" width="20" height="2" rx="1" fill="#1976d2" />
</svg>
FILE_ICON_SVG

# ××™×™×§×•×Ÿ ××‘×˜×—×”
cat > "$BASE_DIR/assets/images/security-icon.svg" << 'SECURITY_ICON_SVG'
<svg xmlns="http://www.w3.org/2000/svg" width="64" height="64" viewBox="0 0 64 64">
  <path d="M32,8 L56,20 L56,34 C56,45 45,54 32,58 C19,54 8,45 8,34 L8,20 L32,8 Z" fill="#bbdefb" />
  <path d="M32,14 L48,22 L48,34 C48,42 41,48 32,52 C23,48 16,42 16,34 L16,22 L32,14 Z" fill="#1976d2" />
  <path d="M32,20 L40,24 L40,34 C40,38 36,42 32,44 C28,42 24,38 24,34 L24,24 L32,20 Z" fill="#ffffff" />
</svg>
SECURITY_ICON_SVG

# ××™×™×§×•×Ÿ Favicon
cat > "$BASE_DIR/assets/images/favicon.png" << 'FAVICON_PNG'
iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAHISURBVFhHvZfBTsMwDIZbdQMBBwQcQNw5wRNw4A3gEXiPPRNvwoEDcEXilkOBJYzPtRs5tasuy5A8Kdpq/98dx3aS1mqEvj6j5dv7lT+KZY3xcr+VrbgQ5HbzbGRJ6gWwoCzAP50CrzLs5U7WsaWl7NzLu60nlfdhAaF8FHDzVvJw7WrTzOZyu9zI4mTl9UVDgFo+C0D5q+5NdhRIGhLQyksBJAOLnwQ1rXwSQJGQDzfWKx8F9NWMYmJdAnIEtA13Mh4BLMKDvRFGdQlgvZpL0YeCh3sjfDFIjgCsUzLyOXVZVAGbNTXCLZZpWVQB7Dz0e6s0FfGVZMB6NUQBt7EzM0+FSU6J2WZpSwwCdtgxdoJjU9FbghII1jm+QmCIAqgV6Ke77VEWpSXuF0Ib2JlJC0gKCXgEYH6FPMlQwPnDw3VFLMBvOkq3pRRB1NLbktJyxIYHEbMAnInRgD49YKKUHCdnJoCHBY7AJIAnG04HzgT496OvZJyQXAbGhJwF/EsBKf8sIGdUj2HskNTyUcDQcdyHVt6NwsEBVUt75YMAtCzbTXQvyPB96GHFOdXKQ0C9G1zOzzJTdkNGUe6nlI8CnJxmF/ALA72Zlv58vn0AAAAASUVORK5CYII=
FAVICON_PNG

# ×™×¦×™×¨×ª ×§×•×‘×¥ README.md
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ README.md..."
cat > "$BASE_DIR/README.md" << 'README_MD'
# ×××—×“ ×§×•×“ ×—×›× Pro 2.0

××¢×¨×›×ª ××ª×§×“××ª ×œ× ×™×ª×•×—, ×–×™×”×•×™ ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP.

## ××˜×¨×•×ª ×”××¢×¨×›×ª

×××—×“ ×§×•×“ ×—×›× Pro 2.0 ×”×™× ××¢×¨×›×ª ××•×“×•×œ×¨×™×ª ×”×××¤×©×¨×ª:
- ×–×™×”×•×™ ×•× ×™×ª×•×— ××•×˜×•××˜×™ ×©×œ ×¤×¨×•×™×§×˜×™× ×‘×§×‘×¦×™ ZIP
- ××™×–×•×’ ×¤×¨×•×™×§×˜×™× ×“×•××™× ××• ×§×©×•×¨×™×
- × ×™×”×•×œ ×’×¨×¡××•×ª ×§×•×“
- ×¡×¨×™×§×ª ××‘×˜×—×”
- ×”×¨×¦×ª ×§×•×“ ×‘×¡×‘×™×‘×” ××‘×•×“×“×ª
- ×”×©×œ××ª ×§×•×“ ×—×¡×¨
- ×’×™×©×” ×œ××—×¡×•×Ÿ ××¨×•×—×§
- × ×™×”×•×œ ×•×¢×™×‘×•×“ ×§×‘×¦×™× ×™×¢×™×œ

## ×”×ª×§× ×”

### ×“×¨×™×©×•×ª ××¢×¨×›×ª

- Python 3.9 ×•××¢×œ×”
- Node.js 16 ×•××¢×œ×” (××•×¤×¦×™×•× ×œ×™, ×œ×—×œ×§ ××”×¤×•× ×§×¦×™×•×ª)
- 2GB RAM ×œ×¤×—×•×ª
- 500MB ×©×˜×— ×“×™×¡×§ ×¤× ×•×™

### ×”×•×¨××•×ª ×”×ª×§× ×”

1. ×”×•×¨×“ ××ª ×§×‘×¦×™ ×”××¢×¨×›×ª
2. ×”×¨×¥ ××ª ×¡×§×¨×™×¤×˜ ×”×”×ª×§× ×”:
   ```bash
   bash install.sh
   ```
3. ×”×ª×§×Ÿ ××ª ×”×ª×œ×•×™×•×ª ×”× ×“×¨×©×•×ª:
   ```bash
   pip install -r requirements.txt
   ```
4. ×”×¤×¢×œ ××ª ×”××¢×¨×›×ª:
   ```bash
   python module.py
   ```

## ××‘× ×” ×”××¢×¨×›×ª

×”××¢×¨×›×ª ×‘× ×•×™×” ×××•×“×•×œ×™× ×¢×™×§×¨×™×™×:
- **××•×“×•×œ ××¨×›×–×™** (`module.py`) - ×× ×”×œ ××ª ×”×ª×”×œ×™×š ×”×›×•×œ×œ
- **× ×™×”×•×œ ×’×¨×¡××•×ª** (`core/version_manager.py`) - ××—×¨××™ ×¢×œ ×©××™×¨×”, ×©×—×–×•×¨ ×•×”×©×•×•××” ×©×œ ×’×¨×¡××•×ª
- **×¡×¨×™×§×•×ª ××‘×˜×—×”** (`core/security_scanner.py`) - ××–×”×” ×¤×’×™×¢×•×™×•×ª ××‘×˜×—×” ×‘×§×•×“
- **×”×¨×¦×ª ×§×•×“** (`core/code_runner.py`) - ××¨×™×¥ ×§×•×“ ×‘×¡×‘×™×‘×” ××‘×•×“×“×ª
- **×”×©×œ××ª ×§×•×“** (`core/code_completer.py`) - ××©×œ×™× ×§×•×“ ×—×¡×¨ ××• ×©×’×•×™
- **××—×¡×•×Ÿ ××¨×•×—×§** (`utils/remote_storage.py`) - ×××¤×©×¨ ×’×™×©×” ×œ××¢×¨×›×•×ª ×§×‘×¦×™× ××¨×•×—×§×•×ª

## ×©×™××•×© ×‘××¢×¨×›×ª

### ××”×©×•×¨×ª ×”×¤×§×•×“×”

```bash
python module.py [files...] -o [output_dir] [options]
```

### ×“×•×’×××•×ª

```bash
# × ×™×ª×•×— ×•×–×™×”×•×™ ×¤×¨×•×™×§×˜×™× ××§×•×‘×¥ ZIP
python module.py project.zip -o output/

# ××™×–×•×’ ××¡×¤×¨ ×§×‘×¦×™ ZIP
python module.py project1.zip project2.zip -o merged_output/

# × ×™×ª×•×— ×¢× ×¡×¨×™×§×ª ××‘×˜×—×”
python module.py project.zip -o output/ --security
```

### ×××©×§ ××©×ª××©

×”××¢×¨×›×ª ×›×•×œ×œ×ª ×××©×§ ××©×ª××© ×’×¨×¤×™ (PWA) ×©× ×’×™×© ×“×¨×š ×”×“×¤×“×¤×Ÿ. ×œ×”×¤×¢×œ×ª ×”×××©×§:

1. ×”×¤×¢×œ ××ª ×”×©×¨×ª:
   ```bash
   python -m http.server
   ```
2. ×¤×ª×— ××ª ×”×“×¤×“×¤×Ÿ ×‘×›×ª×•×‘×ª: `http://localhost:8000`

## ×¨×™×©×™×•×Ÿ

××¢×¨×›×ª ×–×• ××•×¤×¦×ª ×ª×—×ª ×¨×™×©×™×•×Ÿ MIT.

## ××¤×ª×—×™ ×”××¢×¨×›×ª

××¤×•×ª×— ×¢×œ ×™×“×™ Claude AI, ×××™ 2025.

## ×“×™×•×•×— ×¢×œ ×‘××’×™× ×•×©×™×¤×•×¨×™×

×œ×“×™×•×•×— ×¢×œ ×‘××’×™× ××• ×”×¦×¢×•×ª ×œ×©×™×¤×•×¨×™×, ×× × ×¤× ×• ××œ ××¤×ª×—×™ ×”××¢×¨×›×ª.
README_MD

# ×™×¦×™×¨×ª ×§×•×‘×¥ metadata.json
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ metadata.json..."
cat > "$BASE_DIR/metadata.json" << 'METADATA_JSON'
{
  "name": "×××—×“ ×§×•×“ ×—×›× Pro",
  "version": "2.0.0",
  "description": "××¢×¨×›×ª ××ª×§×“××ª ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP",
  "author": "Claude AI",
  "license": "MIT",
  "main": "module.py",
  "module_dependencies": [],
  "dependencies": {
    "python_packages": [
      "paramiko>=2.7.2",
      "boto3>=1.18.0",
      "webdavclient3>=3.14.6",
      "pysmb>=1.2.7"
    ]
  },
  "ui_components": {
    "settings_tab": true,
    "main_tab": true
  }
}
METADATA_JSON

# ×™×¦×™×¨×ª ×§×•×‘×¥ config.json
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ config.json..."
cat > "$BASE_DIR/config.json" << 'CONFIG_JSON'
{
  "project_detection": {
    "min_file_count": 5,
    "detection_methods": ["file_structure", "dependency_analysis", "signature_matching"],
    "project_types": ["nodejs", "python", "java", "web", "cpp", "android", "ios"],
    "detection_confidence_threshold": 0.7
  },
  "merger": {
    "create_zip": true,
    "overwrite_existing": false,
    "ignore_patterns": [
      "**/.git/**",
      "**/.svn/**",
      "**/node_modules/**",
      "**/__pycache__/**",
      "**/.DS_Store"
    ],
    "merge_strategy": "smart",
    "conflict_resolution": "prompt",
    "keep_original_timestamps": true
  },
  "file_handling": {
    "max_file_size_mb": 100,
    "excluded_extensions": [
      ".exe", ".dll", ".so", ".pyc", ".pyo", 
      ".obj", ".o", ".class", ".jar", ".war",
      ".mp3", ".mp4", ".avi", ".mov", ".mkv",
      ".7z", ".rar", ".tar", ".gz", ".pdf"
    ],
    "binary_detection": true,
    "encoding_detection": true,
    "default_encoding": "utf-8"
  },
  "version_management": {
    "enabled": true,
    "storage_path": "versions",
    "max_versions": 10,
    "compression": "gzip",
    "include_metadata": true,
    "branch_tracking": true
  },
  "security_scanning": {
    "enabled": true,
    "scan_level": "medium",
    "report_path": "security_reports",
    "excluded_patterns": ["node_modules", "venv", "__pycache__", ".git"],
    "vulnerability_db_update": true
  },
  "code_running": {
    "enabled": true,
    "sandbox_enabled": true,
    "supported_languages": ["python", "javascript", "bash"],
    "timeout_seconds": 30,
    "memory_limit_mb": 512,
    "sandboxes_dir": "sandboxes"
  },
  "code_completion": {
    "enabled": true,
    "suggestions_limit": 5,
    "context_lines": 10,
    "supported_languages": ["python", "javascript", "java", "c", "cpp"]
  },
  "remote_storage": {
    "enabled": false,
    "types": ["local", "ssh", "s3", "ftp", "webdav", "smb", "nfs"],
    "timeout_seconds": 30,
    "cache_enabled": true,
    "cache_expiry_seconds": 3600,
    "cache_dir": "remote_cache"
  },
  "ui": {
    "theme": "light",
    "language": "he",
    "enable_animations": true,
    "show_advanced_options": false,
    "auto_refresh": true,
    "refresh_interval_seconds": 10
  }
}
CONFIG_JSON

# ×™×¦×™×¨×ª ×§×•×‘×¥ languages_config.json
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ languages_config.json..."
cat > "$BASE_DIR/languages_config.json" << 'LANGUAGES_CONFIG_JSON'
{
  "python": {
    "extension": ".py",
    "command": "python",
    "args": ["-u", "{file}"],
    "version_command": ["python", "--version"],
    "env": {
      "PYTHONPATH": "."
    }
  },
  "javascript": {
    "extension": ".js",
    "command": "node",
    "args": ["{file}"],
    "version_command": ["node", "--version"],
    "env": {
      "NODE_PATH": "node_modules"
    }
  },
  "bash": {
    "extension": ".sh",
    "command": "bash",
    "args": ["{file}"],
    "version_command": ["bash", "--version"],
    "file_position": "last",
    "env": {}
  },
  "java": {
    "extension": ".java",
    "compile_command": "javac",
    "compile_args": ["{file}"],
    "command": "java",
    "args": ["{class}"],
    "version_command": ["java", "--version"],
    "env": {
      "CLASSPATH": "."
    }
  },
  "c": {
    "extension": ".c",
    "compile_command": "gcc",
    "compile_args": ["-o", "{output}", "{file}"],
    "command": "./{output}",
    "args": [],
    "version_command": ["gcc", "--version"],
    "env": {}
  },
  "cpp": {
    "extension": ".cpp",
    "compile_command": "g++",
    "compile_args": ["-o", "{output}", "{file}"],
    "command": "./{output}",
    "args": [],
    "version_command": ["g++", "--version"],
    "env": {}
  }
}
LANGUAGES_CONFIG_JSON

# ×™×¦×™×¨×ª ×§×•×‘×¥ requirements.txt
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ requirements.txt..."
cat > "$BASE_DIR/requirements.txt" << 'REQUIREMENTS_TXT'
# ×ª×œ×•×™×•×ª ×‘×¡×™×¡×™×•×ª
setuptools>=58.0.0
wheel>=0.37.0
pip>=21.2.4

# ×›×œ×™× ××¨×›×–×™×™×
tqdm>=4.62.3
python-dateutil>=2.8.2
PyYAML>=6.0
colorama>=0.4.4

# × ×™×ª×•×— ×§×‘×¦×™× ×•×§×•×“
chardet>=4.0.0
pygments>=2.10.0
pytype>=2022.5.19
pylint>=2.12.0
mypy>=0.910
bandit>=1.7.0
safety>=1.10.3

# ××—×¡×•×Ÿ ××¨×•×—×§ ×•×¡× ×›×¨×•×Ÿ
paramiko>=2.7.2
boto3>=1.18.0
webdavclient3>=3.14.6
pysmb>=1.2.7
requests>=2.26.0

# × ×™×ª×•×— ×¤×¨×•×™×§×˜×™×
virtualenv>=20.8.0
pipreqs>=0.4.11
requirementslib>=1.6.1
REQUIREMENTS_TXT

# ×™×¦×™×¨×ª ×§×•×‘×¥ package.json
echo "ğŸ“ ×™×•×¦×¨ ×§×•×‘×¥ package.json..."
cat > "$BASE_DIR/package.json" << 'PACKAGE_JSON'
{
  "name": "smart-code-merger-pro",
  "version": "2.0.0",
  "description": "××¢×¨×›×ª ××ª×§×“××ª ×œ×–×™×”×•×™, × ×™×ª×•×— ×•××™×–×•×’ ×¤×¨×•×™×§×˜×™× ××§×‘×¦×™ ZIP",
  "main": "assets/js/app.js",
  "scripts": {
    "start": "python -m http.server",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "Claude AI",
  "license": "MIT",
  "dependencies": {
    "chart.js": "^3.7.0",
    "codemirror": "^5.65.0",
    "dompurify": "^2.3.4",
    "highlight.js": "^11.3.1",
    "marked": "^4.0.10"
  },
  "devDependencies": {
    "eslint": "^8.6.0",
    "prettier": "^2.5.1"
  },
  "engines": {
    "node": ">=16.0.0"
  },
  "private": true
}
PACKAGE_JSON

# ×™×¦×™×¨×ª ×•×”×’×“×¨×ª ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª
echo "ğŸ”§ ××’×“×™×¨ ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª ×•××ª×§×™×Ÿ ×ª×œ×•×™×•×ª..."
echo "============================================="

# ×‘×“×™×§×ª ×”×ª×§× ×ª Python
if ! command -v python3 &> /dev/null; then
    echo "âŒ ×©×’×™××”: Python 3 ××™× ×• ××•×ª×§×Ÿ ×‘××¢×¨×›×ª. ×× × ×”×ª×§×Ÿ Python 3 ×•× ×¡×” ×©×•×‘."
    exit 1
fi

# ×‘×“×™×§×ª ×”×ª×§× ×ª pip
if ! command -v pip3 &> /dev/null; then
    echo "âŒ ×©×’×™××”: pip3 ××™× ×• ××•×ª×§×Ÿ ×‘××¢×¨×›×ª. ×× × ×”×ª×§×Ÿ pip ×•× ×¡×” ×©×•×‘."
    exit 1
fi

# ×‘×“×™×§×ª ×”×ª×§× ×ª virtualenv
if ! command -v virtualenv &> /dev/null; then
    echo "ğŸ“¦ ××ª×§×™×Ÿ virtualenv..."
    pip3 install virtualenv
fi

# ××™×§×•× ×”×¡×‘×™×‘×” ×”×•×™×¨×˜×•××œ×™×ª
VENV_DIR="$BASE_DIR/venv"

# ×™×¦×™×¨×ª ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª
echo "ğŸ—ï¸ ×™×•×¦×¨ ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª ×‘: $VENV_DIR"
virtualenv "$VENV_DIR"

# ×”×¤×¢×œ×ª ×”×¡×‘×™×‘×” ×”×•×™×¨×˜×•××œ×™×ª ×•×”×ª×§× ×ª ×ª×œ×•×™×•×ª
echo "ğŸ“¦ ××ª×§×™×Ÿ ×ª×œ×•×™×•×ª ×‘×¡×‘×™×‘×” ×”×•×™×¨×˜×•××œ×™×ª..."
source "$VENV_DIR/bin/activate"

# ×”×ª×§× ×ª ×ª×œ×•×™×•×ª ××§×•×‘×¥ requirements.txt
pip install -r "$BASE_DIR/requirements.txt"

# ×™×¦×™×¨×ª ×¡×§×¨×™×¤×˜ ×”×¤×¢×œ×”
echo "ğŸ“ ×™×•×¦×¨ ×¡×§×¨×™×¤×˜ ×”×¤×¢×œ×”..."
cat > "$BASE_DIR/run.sh" << 'RUN_SH'
#!/bin/bash

# ×¡×§×¨×™×¤×˜ ×”×¤×¢×œ×” ×¢× ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
VENV_DIR="$SCRIPT_DIR/venv"

# ×”×¤×¢×œ×ª ×”×¡×‘×™×‘×” ×”×•×™×¨×˜×•××œ×™×ª
source "$VENV_DIR/bin/activate"

# ×‘×“×™×§×ª ×¤×¨××˜×¨×™×
if [ "$1" == "--ui" ] || [ "$1" == "-u" ]; then
    echo "ğŸš€ ××¤×¢×™×œ ×××©×§ ××©×ª××©..."
    cd "$SCRIPT_DIR"
    python -m http.server
    echo "×¤×ª×— ××ª ×”×“×¤×“×¤×Ÿ ×‘×›×ª×•×‘×ª: http://localhost:8000/ui/templates/index.html"
else
    echo "ğŸš€ ××¤×¢×™×œ ×××—×“ ×§×•×“ ×—×›× Pro 2.0..."
    cd "$SCRIPT_DIR"
    python module.py "$@"
fi
RUN_SH

# ×”×¤×™×›×ª ×¡×§×¨×™×¤×˜ ×”×”×¤×¢×œ×” ×œ× ×™×ª×Ÿ ×œ×”×¨×¦×”
chmod +x "$BASE_DIR/run.sh"

# ×—×–×¨×” ×œ××¦×‘ ×¨×’×™×œ (×™×¦×™××” ××”×¡×‘×™×‘×” ×”×•×™×¨×˜×•××œ×™×ª)
deactivate

echo "âœ… ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª ×”×•×’×“×¨×” ×•×ª×œ×•×™×•×ª ×”×•×ª×§× ×• ×‘×”×¦×œ×—×”!"

# ×”×•×“×¢×ª ×¡×™×•× ××¢×•×“×›× ×ª
echo "âœ… ×”×ª×§× ×ª ×××—×“ ×§×•×“ ×—×›× Pro 2.0 ×”×•×©×œ××”!"
echo "============================================="
echo "×›×“×™ ×œ×”×¤×¢×™×œ ××ª ×”××¢×¨×›×ª, ×”×©×ª××© ×‘×¡×§×¨×™×¤×˜ ×”×”×¤×¢×œ×”:"
echo ""
echo "cd \"$BASE_DIR\""
echo "./run.sh        # ×œ×”×¤×¢×œ×ª ×”××•×“×•×œ"
echo ""
echo "××• ×œ×”×¤×¢×œ×ª ×××©×§ ×”××©×ª××© (PWA):"
echo ""
echo "cd \"$BASE_DIR\""
echo "./run.sh --ui   # ×œ×”×¤×¢×œ×ª ×××©×§ ×”××©×ª××©"
echo "×¤×ª×— ××ª ×”×“×¤×“×¤×Ÿ ×‘×›×ª×•×‘×ª: http://localhost:8000/ui/templates/index.html"
echo "============================================="